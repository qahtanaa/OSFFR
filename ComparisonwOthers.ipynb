{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qahtanaa/OnSubGroupFairness/blob/main/ComparisonwOthers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "1hMRy18r0HQ1"
      },
      "outputs": [],
      "source": [
        "%reset -f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CiFgy-I18iF",
        "outputId": "361160c4-d54e-4291-cb29-250a09855ee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aif360 in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.11.4)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from aif360) (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (3.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install aif360"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "yWGEcYZ52Bk5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from aif360.metrics import utils\n",
        "from scipy.sparse import issparse\n",
        "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import random\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sympy import Symbol\n",
        "from sympy.solvers import solve\n",
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "from aif360.algorithms.preprocessing import *\n",
        "from aif360.algorithms.preprocessing.optim_preproc_helpers import distortion_functions, opt_tools\n",
        "from aif360.algorithms.inprocessing import *\n",
        "from aif360.algorithms.postprocessing import *\n",
        "import math\n",
        "import itertools\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhI-ZkuE5XQP"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "X8Qh_A6g2HLn"
      },
      "outputs": [],
      "source": [
        "def preprocess_dataset(dataset_path, dataset_type, model):\n",
        "    if dataset_type == 'German':\n",
        "        df = pd.read_csv(dataset_path)\n",
        "        df['age'] = df['age'].apply(lambda age: 1 if age >= 25 else 0)\n",
        "        df['personal_status'] = df['personal_status'].apply(lambda sex: 1 if sex == 'male' else 0)\n",
        "        print(\"German dataset:\")\n",
        "        print(df.head())\n",
        "        sensitive_attributes = ['personal_status','age']\n",
        "        label = 'credit'\n",
        "        privileged = [1, 1]\n",
        "        unprivileged = [0, 0]\n",
        "        favorable_label = 1\n",
        "        unfavorable_label = 2\n",
        "        groups = [\n",
        "                  {'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}},\n",
        "                  {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}},\n",
        "                  {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}},\n",
        "                  {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}}\n",
        "              ]\n",
        "        model = model\n",
        "\n",
        "    elif dataset_type == 'COMPAS':\n",
        "        df = pd.read_csv(dataset_path)\n",
        "        selected_columns = ['sex', 'age_cat', 'race', 'juv_fel_count', 'juv_misd_count',\n",
        "                            'juv_other_count', 'priors_count', 'c_charge_degree',\n",
        "                            'c_charge_desc', 'two_year_recid']\n",
        "        df = df[selected_columns]\n",
        "        df = df[(df['race'] == 'Caucasian') | (df['race'] == 'African-American')].reset_index(drop=True)\n",
        "        print(\"COMPAS dataset:\")\n",
        "        print(df.head())\n",
        "        sensitive_attributes = ['race','sex']\n",
        "        label = 'two_year_recid'\n",
        "        privileged = ['Caucasian', 'Female']\n",
        "        unprivileged = ['African-American', 'Male']\n",
        "        favorable_label = 0\n",
        "        unfavorable_label = 1\n",
        "        groups = [\n",
        "                  {'name': 'Caucasian Female', 'attributes': {'race': 1, 'sex': 1}},\n",
        "                  {'name': 'Black Female', 'attributes': {'race': 0, 'sex': 1}},\n",
        "                  {'name': 'Causasian Male', 'attributes': {'race': 1, 'sex': 0}},\n",
        "                  {'name': 'Black Male', 'attributes': {'race': 0, 'sex': 0}}\n",
        "              ]\n",
        "        model = model\n",
        "\n",
        "    elif dataset_type == 'Adult':\n",
        "        df = pd.read_csv('/content/raw_adult_dataset.csv', delimiter=';')\n",
        "        df['income'] = df['income'].str.strip().replace({'>50K.': '>50K', '<=50K.': '<=50K'})\n",
        "        df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "        df.replace('?', np.nan, inplace=True)\n",
        "        df = df.drop(columns=['fnlwgt', 'education-num'])\n",
        "        df = df[(df['race'] == 'White') | (df['race'] == 'Black')].reset_index(drop=True)\n",
        "        print(\"Adult dataset:\")\n",
        "        print(df.head())\n",
        "        sensitive_attributes = ['race','sex']\n",
        "        label = 'income'\n",
        "        privileged = ['White', 'Male']\n",
        "        unprivileged = ['Black', 'Female']\n",
        "        favorable_label = '>50K'\n",
        "        unfavorable_label = '<=50K'\n",
        "        groups = [\n",
        "                  {'name': 'White Male', 'attributes': {'race': 1, 'sex': 1}},\n",
        "                  {'name': 'Black Male', 'attributes': {'race': 0, 'sex': 1}},\n",
        "                  {'name': 'White Female', 'attributes': {'race': 1, 'sex': 0}},\n",
        "                  {'name': 'Black Female', 'attributes': {'race': 0, 'sex': 0}}\n",
        "              ]\n",
        "        model = model\n",
        "\n",
        "    return df, sensitive_attributes, label, privileged, unprivileged, favorable_label, unfavorable_label, groups, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8ELKv_6OK_T",
        "outputId": "95a09729-09e3-400b-af1a-1633c2ac2bf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "German dataset:\n",
            "  status  month credit_history purpose  credit_amount savings employment  \\\n",
            "0    A11      6            A34     A43           1169     A65        A75   \n",
            "1    A12     48            A32     A43           5951     A61        A73   \n",
            "2    A14     12            A34     A46           2096     A61        A74   \n",
            "3    A11     42            A32     A42           7882     A61        A74   \n",
            "4    A11     24            A33     A40           4870     A61        A73   \n",
            "\n",
            "   investment_as_income_percentage  personal_status other_debtors  ...  \\\n",
            "0                                4                1          A101  ...   \n",
            "1                                2                0          A101  ...   \n",
            "2                                2                1          A101  ...   \n",
            "3                                2                1          A103  ...   \n",
            "4                                3                1          A101  ...   \n",
            "\n",
            "   property age  installment_plans housing number_of_credits  skill_level  \\\n",
            "0      A121   1               A143    A152                 2         A173   \n",
            "1      A121   0               A143    A152                 1         A173   \n",
            "2      A121   1               A143    A152                 1         A172   \n",
            "3      A122   1               A143    A153                 1         A173   \n",
            "4      A124   1               A143    A153                 2         A173   \n",
            "\n",
            "  people_liable_for  telephone foreign_worker credit  \n",
            "0                 1       A192           A201      1  \n",
            "1                 1       A191           A201      2  \n",
            "2                 2       A191           A201      1  \n",
            "3                 2       A191           A201      1  \n",
            "4                 2       A191           A201      2  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ],
      "source": [
        "##################################################################################\n",
        "df, sensitive_attributes, label, privileged, unprivileged, favorable_label, unfavorable_label, groups, model = preprocess_dataset('/content/raw_german_dataset.csv', 'German', 'Logistic Regression')\n",
        "# = '/content/raw_german_dataset.csv', 'German'\n",
        "# = preprocess_dataset('/content/raw_compas_dataset.csv', 'COMPAS')\n",
        "# = preprocess_dataset('/content/raw_adult_dataset.csv', 'Adult')\n",
        "\n",
        "#model == 'Logistic Regression':\n",
        "#model == 'Random Forest':\n",
        "#model == 'Gradient Boosting':"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoswG-Vi5rwA"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "DATA PREPARATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "E1ltkHTL61td"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "class DataPreparation():\n",
        "    \"\"\"\n",
        "    ........\n",
        "    \"\"\"\n",
        "    def __init__(self, df, sensitive, label, priv, unpriv, fav, unfav, categorical=[]):\n",
        "        \"\"\"\n",
        "        Construct all necessary attributes for the data preparation.\n",
        "\n",
        "        df : (pandas DataFrame) containing the data\n",
        "        sensitive : (list(str)) specifying the column names of all sensitive features\n",
        "        label : (str) specifying the label column\n",
        "        priv : (list(dicts)) representation of the privileged groups\n",
        "        unpriv : (list(dicts)) representation of the unprivileged groups\n",
        "        fav : (str/int/..) value representing the favorable label\n",
        "        unfav : (str/int/..) value representing the unfavorable label\n",
        "        categorical : (list(str)) (optional) specifying column names of categorical features\n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        self.sensitive = sensitive\n",
        "        self.label = label\n",
        "        self.priv = priv\n",
        "        self.unpriv = unpriv\n",
        "        self.fav = fav\n",
        "        self.unfav = unfav\n",
        "        self.categorical = categorical\n",
        "\n",
        "    def detect_missing_values(self):\n",
        "        \"\"\"\n",
        "        Detect rows with missing values and remove them from the DataFrame.\n",
        "        \"\"\"\n",
        "        initial_rows = len(self.df)\n",
        "        self.df = self.df.dropna()\n",
        "        removed_rows = initial_rows - len(self.df)\n",
        "\n",
        "        if removed_rows > 0:\n",
        "            print(f\"Detected {removed_rows} rows with missing values. Removed them.\")\n",
        "        else:\n",
        "            print(\"No missing values detected.\")  # pass\n",
        "\n",
        "    def binary_label(self):\n",
        "        \"\"\"\n",
        "        Ensure the decision label and sensitive attributes are encoded as binary, where:\n",
        "        - Favorable label and privileged groups are encoded as 1.\n",
        "        - Unfavorable label and unprivileged groups are encoded as 0.\n",
        "        \"\"\"\n",
        "        if len(self.priv) != 2 or len(self.unpriv) != 2:\n",
        "            raise ValueError(\"Both 'priv' and 'unpriv' must contain exactly two values.\")\n",
        "\n",
        "        number_label_values = self.df[self.label].nunique()\n",
        "        if number_label_values == 2:\n",
        "            print(f\"The '{self.label}' column has only two unique values.\")\n",
        "            self.df.loc[:, self.label] = self.df[self.label].replace([self.unfav, self.fav], [0, 1])\n",
        "        else:\n",
        "            print(f\"The '{self.label}' column does not have exactly two unique values, as it should.\")\n",
        "\n",
        "        # Create mappings for each sensitive attribute\n",
        "        race_mapping = {self.priv[0]: 1, self.unpriv[0]: 0}\n",
        "        sex_mapping = {self.priv[1]: 1, self.unpriv[1]: 0}\n",
        "\n",
        "        # Apply the mappings to the respective columns\n",
        "        self.df.loc[:, self.sensitive[0]] = self.df[self.sensitive[0]].replace(race_mapping)\n",
        "        self.df.loc[:, self.sensitive[1]] = self.df[self.sensitive[1]].replace(sex_mapping)\n",
        "\n",
        "    def find_categorical_attributes(self):\n",
        "        \"\"\"\n",
        "        Identify categorical attributes and encode.\n",
        "        \"\"\"\n",
        "        self.attribute_types = {}\n",
        "\n",
        "        for column in self.df.columns:\n",
        "            if column == 'Group':\n",
        "                continue  # Skip the 'Group' column\n",
        "            elif column in self.categorical:\n",
        "                self.attribute_types[column] = 'Categorical'\n",
        "            elif self.df[column].nunique() == 2:\n",
        "                self.attribute_types[column] = 'Categorical'\n",
        "            else:\n",
        "                num_float = 0\n",
        "                num_text = 0\n",
        "                thresh = 0.99\n",
        "                num_att_in_column = len(self.df[column])\n",
        "\n",
        "                for value in self.df[column]:\n",
        "                    try:\n",
        "                        float(value)\n",
        "                        num_float += 1\n",
        "                    except ValueError:\n",
        "                        num_text += 1\n",
        "\n",
        "                if num_float / num_att_in_column > thresh:\n",
        "                    self.attribute_types[column] = 'Numerical'\n",
        "                else:\n",
        "                    self.attribute_types[column] = 'Categorical'\n",
        "        # Boolean\n",
        "        self.cat_features = []\n",
        "        for attr in self.attribute_types:\n",
        "            self.cat_features.append(self.attribute_types[attr] == 'Categorical')\n",
        "\n",
        "        encoder_dict = dict()\n",
        "        self.columns_categorical = self.df.columns[self.cat_features]\n",
        "\n",
        "        for column in self.columns_categorical:\n",
        "            le = LabelEncoder()\n",
        "            self.df.loc[:, column] = le.fit_transform(self.df[column].values)\n",
        "            mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
        "            encoder_dict[column] = mapping\n",
        "        print(encoder_dict, 'encoder dict')\n",
        "        self.numerical_features = [not feature for feature in self.cat_features]\n",
        "        self.columns_numerical = self.df.columns[self.numerical_features]\n",
        "\n",
        "        for column in self.columns_numerical:\n",
        "            self.df.loc[:, column] = self.df[column].astype(float)\n",
        "\n",
        "        return self.attribute_types, self.cat_features, self.numerical_features\n",
        "\n",
        "    def create_group_column(self):\n",
        "        \"\"\"\n",
        "        Create a 'Group' column in the DataFrame based on protected attributes, privileged/unprivileged conditions, and label.\n",
        "        \"\"\"\n",
        "        group_combinations = pd.MultiIndex.from_product([self.df[sensitive].unique() for sensitive in self.sensitive] + [self.df[self.label].unique()], names=self.sensitive + [self.label])\n",
        "        print(list(enumerate(group_combinations)))\n",
        "        # Create a mapping between group combinations and their corresponding numbers\n",
        "        group_mapping = {group: idx for idx, group in enumerate(group_combinations)}\n",
        "        reverse_group_mapping = {idx: group for group, idx in group_mapping.items()}\n",
        "        self.df['Group'] = pd.MultiIndex.from_frame(self.df[self.sensitive + [self.label]]).map(group_mapping)\n",
        "\n",
        "        return reverse_group_mapping\n",
        "\n",
        "    def train_test_split(self):\n",
        "        X = self.df.loc[:, self.df.columns != self.label]\n",
        "        y = self.df[self.label]\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.3, shuffle=True, stratify=self.df['Group'])  # , random_state=42\n",
        "\n",
        "        return self.X_train, self.y_train, self.X_test, self.y_test\n",
        "\n",
        "    def standardization_numerical(self):\n",
        "        train_dataset_numerical = self.X_train[self.columns_numerical]\n",
        "        test_dataset_numerical = self.X_test[self.columns_numerical]\n",
        "\n",
        "        scaler = StandardScaler().fit(train_dataset_numerical)\n",
        "        train_dataset_scaled_numerical = scaler.transform(train_dataset_numerical)\n",
        "        test_dataset_scaled_numerical = scaler.transform(test_dataset_numerical)\n",
        "\n",
        "        self.X_train.loc[:, self.columns_numerical] = train_dataset_scaled_numerical\n",
        "        self.X_test.loc[:, self.columns_numerical] = test_dataset_scaled_numerical\n",
        "\n",
        "        self.X_train = pd.concat([self.X_train, self.y_train], axis=1)\n",
        "        self.X_test = pd.concat([self.X_test, self.y_test], axis=1)\n",
        "        return self.X_train, self.X_test\n",
        "\n",
        "    def prepare(self):\n",
        "        \"\"\"\n",
        "        Perform all preprocessing steps.\n",
        "        \"\"\"\n",
        "        self.detect_missing_values()\n",
        "        self.binary_label()\n",
        "        self.find_categorical_attributes()\n",
        "        self.create_group_column()\n",
        "        self.train_test_split()\n",
        "        self.standardization_numerical()\n",
        "        return self\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ACoThBWMK29",
        "outputId": "e706574e-6130-40d6-e546-fc6e5250189f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No missing values detected.\n",
            "The 'credit' column has only two unique values.\n",
            "{'status': {'A11': 0, 'A12': 1, 'A13': 2, 'A14': 3}, 'credit_history': {'A30': 0, 'A31': 1, 'A32': 2, 'A33': 3, 'A34': 4}, 'purpose': {'A40': 0, 'A41': 1, 'A410': 2, 'A42': 3, 'A43': 4, 'A44': 5, 'A45': 6, 'A46': 7, 'A48': 8, 'A49': 9}, 'savings': {'A61': 0, 'A62': 1, 'A63': 2, 'A64': 3, 'A65': 4}, 'employment': {'A71': 0, 'A72': 1, 'A73': 2, 'A74': 3, 'A75': 4}, 'personal_status': {0: 0, 1: 1}, 'other_debtors': {'A101': 0, 'A102': 1, 'A103': 2}, 'property': {'A121': 0, 'A122': 1, 'A123': 2, 'A124': 3}, 'age': {0: 0, 1: 1}, 'installment_plans': {'A141': 0, 'A142': 1, 'A143': 2}, 'housing': {'A151': 0, 'A152': 1, 'A153': 2}, 'skill_level': {'A171': 0, 'A172': 1, 'A173': 2, 'A174': 3}, 'people_liable_for': {1: 0, 2: 1}, 'telephone': {'A191': 0, 'A192': 1}, 'foreign_worker': {'A201': 0, 'A202': 1}, 'credit': {0: 0, 1: 1}} encoder dict\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "  status     month credit_history purpose  credit_amount savings employment  \\\n",
            "0      0  0.253548              3       4      -0.573091       0          1   \n",
            "1      0  0.253548              1       3      -0.283857       2          2   \n",
            "2      2  0.253548              2       3      -0.479722       0          2   \n",
            "3      0  0.253548              2       3       0.255649       0          2   \n",
            "4      3  0.253548              4       1       0.202295       0          4   \n",
            "\n",
            "   investment_as_income_percentage  personal_status other_debtors  ...  age  \\\n",
            "0                         0.950121                0             0  ...    1   \n",
            "1                         0.950121                1             0  ...    0   \n",
            "2                        -0.869536                1             0  ...    1   \n",
            "3                        -0.869536                1             0  ...    1   \n",
            "4                         0.950121                0             0  ...    1   \n",
            "\n",
            "  installment_plans  housing number_of_credits skill_level  people_liable_for  \\\n",
            "0                 2        0         -0.698276           1                  0   \n",
            "1                 1        1         -0.698276           2                  0   \n",
            "2                 2        1         -0.698276           2                  0   \n",
            "3                 1        1         -0.698276           2                  0   \n",
            "4                 2        0          1.004836           3                  0   \n",
            "\n",
            "  telephone  foreign_worker Group credit  \n",
            "0         1               0     5      0  \n",
            "1         1               0     2      1  \n",
            "2         0               0     0      1  \n",
            "3         0               0     0      1  \n",
            "4         1               0     4      1  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ],
      "source": [
        "##################################################################################\n",
        "#use the DataPreparation class to preprocess the dataframe\n",
        "data_prep = DataPreparation(df, sensitive_attributes, label, privileged, unprivileged, favorable_label, unfavorable_label)\n",
        "data_prep.prepare()\n",
        "data_prep.df = data_prep.df.reset_index(drop=True)\n",
        "X_train, X_test = data_prep.X_train, data_prep.X_test\n",
        "attribute_types = data_prep.attribute_types\n",
        "cat_features = data_prep.cat_features\n",
        "numerical_features = data_prep.numerical_features\n",
        "reverse_group_mapping = data_prep.create_group_column()\n",
        "#theoretical_num_groups = len(reverse_group_mapping)\n",
        "X_train = X_train.reset_index(drop=True)\n",
        "\n",
        "print(X_train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOdPHQH7OsWh",
        "outputId": "7e6ba8e2-4908-4cb8-aa68-8227cd7e6bd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ratio of most privileged class: 2.7672413793103448\n"
          ]
        }
      ],
      "source": [
        "#################################################################################\n",
        "num_privileged_ones = X_train[(X_train[sensitive_attributes[0]] == 1) &\n",
        "                              (X_train[sensitive_attributes[1]] == 1) &\n",
        "                              (X_train[label] == 1)].shape[0]\n",
        "\n",
        "num_privileged_zeros = X_train[(X_train[sensitive_attributes[0]] == 1) &\n",
        "                               (X_train[sensitive_attributes[1]] == 1) &\n",
        "                               (X_train[label] == 0)].shape[0]\n",
        "\n",
        "# Calculating the ratio of the most privileged class\n",
        "total_ratio = num_privileged_ones / num_privileged_zeros if num_privileged_zeros != 0 else float('inf')  # Avoid division by zero\n",
        "\n",
        "print(f\"Ratio of most privileged class: {total_ratio}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define sensitive attribute and label columns\n",
        "sensitive_attr_0 = sensitive_attributes[0]\n",
        "sensitive_attr_1 = sensitive_attributes[1]\n",
        "\n",
        "# Calculate the number of ones and zeros for each group\n",
        "num_group_11_ones = X_train[(X_train[sensitive_attr_0] == 1) &\n",
        "                            (X_train[sensitive_attr_1] == 1) &\n",
        "                            (X_train[label] == 1)].shape[0]\n",
        "\n",
        "num_group_11_zeros = X_train[(X_train[sensitive_attr_0] == 1) &\n",
        "                             (X_train[sensitive_attr_1] == 1) &\n",
        "                             (X_train[label] == 0)].shape[0]\n",
        "\n",
        "num_group_10_ones = X_train[(X_train[sensitive_attr_0] == 1) &\n",
        "                            (X_train[sensitive_attr_1] == 0) &\n",
        "                            (X_train[label] == 1)].shape[0]\n",
        "\n",
        "num_group_10_zeros = X_train[(X_train[sensitive_attr_0] == 1) &\n",
        "                             (X_train[sensitive_attr_1] == 0) &\n",
        "                             (X_train[label] == 0)].shape[0]\n",
        "\n",
        "num_group_01_ones = X_train[(X_train[sensitive_attr_0] == 0) &\n",
        "                            (X_train[sensitive_attr_1] == 1) &\n",
        "                            (X_train[label] == 1)].shape[0]\n",
        "\n",
        "num_group_01_zeros = X_train[(X_train[sensitive_attr_0] == 0) &\n",
        "                             (X_train[sensitive_attr_1] == 1) &\n",
        "                             (X_train[label] == 0)].shape[0]\n",
        "\n",
        "num_group_00_ones = X_train[(X_train[sensitive_attr_0] == 0) &\n",
        "                            (X_train[sensitive_attr_1] == 0) &\n",
        "                            (X_train[label] == 1)].shape[0]\n",
        "\n",
        "num_group_00_zeros = X_train[(X_train[sensitive_attr_0] == 0) &\n",
        "                             (X_train[sensitive_attr_1] == 0) &\n",
        "                             (X_train[label] == 0)].shape[0]\n",
        "\n",
        "# Calculate imbalance ratios\n",
        "imbalance_ratio_11 = num_group_11_ones / num_group_11_zeros if num_group_11_zeros != 0 else float('inf')\n",
        "imbalance_ratio_10 = num_group_10_ones / num_group_10_zeros if num_group_10_zeros != 0 else float('inf')\n",
        "imbalance_ratio_01 = num_group_01_ones / num_group_01_zeros if num_group_01_zeros != 0 else float('inf')\n",
        "imbalance_ratio_00 = num_group_00_ones / num_group_00_zeros if num_group_00_zeros != 0 else float('inf')\n",
        "\n",
        "# Print imbalance ratios\n",
        "print(f\"Imbalance ratio for group (1, 1): {imbalance_ratio_11}\")\n",
        "print(f\"Imbalance ratio for group (1, 0): {imbalance_ratio_10}\")\n",
        "print(f\"Imbalance ratio for group (0, 1): {imbalance_ratio_01}\")\n",
        "print(f\"Imbalance ratio for group (0, 0): {imbalance_ratio_00}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2MYY-OV6Cca",
        "outputId": "ff858163-1d67-4b0e-c544-b39358cc4028"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imbalance ratio for group (1, 1): 2.7672413793103448\n",
            "Imbalance ratio for group (1, 0): 1.5555555555555556\n",
            "Imbalance ratio for group (0, 1): 2.0980392156862746\n",
            "Imbalance ratio for group (0, 0): 1.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "hXw5qtFrP3iv"
      },
      "outputs": [],
      "source": [
        "#################################################################################\n",
        "## Save the 'Group' column from X_train\n",
        "subgroup_column_train = X_train['Group']\n",
        "subgroup_column_test = X_test['Group']\n",
        "\n",
        "# Drop the 'Group' column from X_train\n",
        "X_train = X_train.drop(columns=['Group'])\n",
        "X_test = X_test.drop(columns=['Group'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyH39ocAQbMu"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "DBSCAN\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1TcP085Qfji",
        "outputId": "8e73779e-4141-4e87-be4b-4f94513c314f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gower in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gower) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from gower) (1.11.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install gower"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "qi2VPp3KRiLo"
      },
      "outputs": [],
      "source": [
        "# find the eps\n",
        "from gower import gower_matrix\n",
        "from sklearn.cluster import DBSCAN\n",
        "import math\n",
        "\n",
        "# # Filter the dataset for one specific combination of sensitive attributes and labels\n",
        "# filtered_data = X_train[(X_train[sensitive_attributes[0]] == 1) & (X_train[sensitive_attributes[1]] == 0) & (X_train[label] == 1)]\n",
        "\n",
        "# # Calculate Gower distance matrix\n",
        "# distance_matrix = gower_matrix(filtered_data, cat_features=cat_features)\n",
        "\n",
        "# eps = 0.1\n",
        "# # DBSCAN clustering\n",
        "# dbscan = DBSCAN(eps=eps, min_samples=round(math.log(len(filtered_data))), metric='precomputed')  # Set appropriate values for eps and min_samples\n",
        "# clusters = dbscan.fit_predict(distance_matrix)\n",
        "\n",
        "# # Assign cluster labels to dataframe\n",
        "# filtered_data['cluster'] = clusters\n",
        "\n",
        "# print(round(math.log(len(filtered_data))))\n",
        "# # Display the number of samples in each cluster\n",
        "# cluster_counts = filtered_data.groupby(['cluster']).size()\n",
        "# print(\"Number of samples in each cluster:\")\n",
        "# print(cluster_counts)\n",
        "\n",
        "# # Get cluster labels\n",
        "# labels = dbscan.labels_\n",
        "\n",
        "# # Get core samples\n",
        "# core_samples_mask = np.zeros_like(labels, dtype=bool)\n",
        "# core_samples_mask[dbscan.core_sample_indices_] = True\n",
        "\n",
        "# # Identify core, border, and noise points\n",
        "# core_points = filtered_data[core_samples_mask]\n",
        "# border_points = filtered_data[~core_samples_mask & (labels != -1)]\n",
        "# noise_points = filtered_data[labels == -1]\n",
        "\n",
        "# # For example, you can print the number of points in each category\n",
        "# print(\"Number of core points:\", len(core_points))\n",
        "# print(\"Number of border points:\", len(border_points))\n",
        "# print(\"Number of noise points:\", len(noise_points))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "YWL3k2HpQt3w"
      },
      "outputs": [],
      "source": [
        "from gower import gower_matrix\n",
        "from sklearn.cluster import DBSCAN\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# # Compute distances to nearest neighbors\n",
        "# k = round(math.log(len(filtered_data)))\n",
        "# nbrs = NearestNeighbors(n_neighbors=k, metric='precomputed').fit(distance_matrix)\n",
        "# distances, _ = nbrs.kneighbors(distance_matrix)\n",
        "\n",
        "# # Compute reachability distances\n",
        "# reachability_distances = np.mean(distances[:, 1:], axis=1)\n",
        "\n",
        "# # Sort reachability distances in ascending order\n",
        "# sorted_distances = np.sort(reachability_distances)\n",
        "\n",
        "# # Plot reachability distances\n",
        "# plt.figure(figsize=(6, 4))\n",
        "# plt.plot(sorted_distances)\n",
        "# plt.title('Reachability Plot')\n",
        "# plt.xlabel('Data Points (Sorted)')\n",
        "# plt.ylabel('Reachability Distance')\n",
        "# plt.grid(True)\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "eceoSCDSIlPa"
      },
      "outputs": [],
      "source": [
        "# Compute distances to K-nearest neighbors\n",
        "# k = round(math.log(len(filtered_data))) # Choose the value of K\n",
        "# nbrs = NearestNeighbors(n_neighbors=k, metric='precomputed').fit(distance_matrix)\n",
        "# distances, _ = nbrs.kneighbors(distance_matrix)\n",
        "\n",
        "# # Sort distances\n",
        "# sorted_distances = np.sort(distances[:, -1])\n",
        "\n",
        "# # Plot K-distance graph\n",
        "# plt.plot(range(len(filtered_data)), sorted_distances)\n",
        "# plt.xlabel('Data Points')\n",
        "# plt.ylabel('Distance to Kth Nearest Neighbor')\n",
        "# plt.title('K-distance Graph')\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "opqaAkN-It8M"
      },
      "outputs": [],
      "source": [
        "# def custom_smote_dbscan(X_train, cat_features, pu_ix, nu_ix, group_column_train, total_ratio):\n",
        "#     \"\"\"\n",
        "#     X_train is the training dataset preprocessed, subgroup_column_train is a column containing the subgroup of each\n",
        "#     instance in X_train\n",
        "#     \"\"\"\n",
        "#     cat_attr_ix = [i for i, value in enumerate(cat_features) if value]\n",
        "\n",
        "#     X2_df = X_train[group_column_train == pu_ix]\n",
        "#     X2 = X2_df.values\n",
        "#     X3_df = X_train[group_column_train == nu_ix]\n",
        "#     X3 = X3_df.values\n",
        "\n",
        "#     PU = len(X2)\n",
        "#     NU = len(X3)\n",
        "\n",
        "#     # Determine the oversampling target based on a given total_ratio\n",
        "#     if (PU / NU) > total_ratio:\n",
        "#         oversampling_target = (PU / total_ratio) - NU\n",
        "#         os_df = X3_df\n",
        "#         os_ix = nu_ix\n",
        "#     elif (PU / NU) == total_ratio:\n",
        "#         print(\"The ratio of PU to NU is within the acceptable range of total_ratio.\")\n",
        "#         return [], 0, pu_ix\n",
        "#     else:\n",
        "#         oversampling_target = (total_ratio * NU) - PU\n",
        "#         os_df = X2_df\n",
        "#         os_ix = pu_ix\n",
        "#     os_df = os_df.reset_index(drop=True)\n",
        "\n",
        "#     # Calculate Gower distance matrix\n",
        "#     distance_matrix = gower_matrix(os_df, cat_features=cat_features)\n",
        "\n",
        "#     # group 0 : eps = 0.23\n",
        "#     # group 1 : eps = 0.275\n",
        "#     # group 2 : eps = 0.26\n",
        "#     # group 3 : eps = 0.26\n",
        "#     # group 4 : eps = 0.26\n",
        "#     # group 5 : eps = 0.28\n",
        "#     # group 6 : eps = 0.28\n",
        "#     # group 7 : eps = 0.265\n",
        "#     # DBSCAN parameters per group\n",
        "#     eps = {0: 0.1, 1: 0.1, 2: 0.1, 3: 0.1, 4: 0.1, 5: 0.1, 6: 0.1, 7: 0.1}\n",
        "#     #eps = {0: 0.225, 1: 0.26, 2: 0.22, 3: 0.255, 4: 0.255, 5: 0.275, 6: 0.27, 7: 0.25}\n",
        "#     k = round(math.log(len(os_df)))\n",
        "#     dbscan = DBSCAN(eps=eps[os_ix], min_samples=k, metric='precomputed')\n",
        "#     clusters = dbscan.fit_predict(distance_matrix)\n",
        "\n",
        "#     # Get cluster labels\n",
        "#     labels = dbscan.labels_\n",
        "\n",
        "#     # Get core samples\n",
        "#     core_samples_mask = np.zeros_like(labels, dtype=bool)\n",
        "#     core_samples_mask[dbscan.core_sample_indices_] = True\n",
        "\n",
        "#     # Identify core, border, and noise points\n",
        "#     core_points = os_df[core_samples_mask]\n",
        "#     border_points = os_df[~core_samples_mask & (labels != -1)]\n",
        "#     noise_points = os_df[labels == -1]\n",
        "\n",
        "#     if len(border_points) == 0:\n",
        "#         border_points = core_points\n",
        "\n",
        "#     # Initialize synthetic samples list\n",
        "#     synthetic_samples = []\n",
        "\n",
        "#     border_indices = border_points.index.tolist()\n",
        "#     random.shuffle(border_indices)\n",
        "#     current_index = 0\n",
        "\n",
        "#     while len(synthetic_samples) < oversampling_target:\n",
        "#         idx_A = border_indices[current_index % len(border_indices)]\n",
        "#         #idx_A = core_indices[current_index % len(core_indices)]\n",
        "#         #print(idx_A, 'indice A')\n",
        "#         current_index += 1\n",
        "#         point_A = os_df.loc[idx_A]\n",
        "\n",
        "#         # Ensure point B is not a noise point\n",
        "#         distances_to_A = distance_matrix[idx_A]\n",
        "#         neighbors = np.argsort(distances_to_A)[1:k+1]  # Exclude the point itself\n",
        "#         valid_neighbors = [idx for idx in neighbors if labels[idx] != -1]  # Exclude noise points\n",
        "\n",
        "#         if not valid_neighbors:\n",
        "#             continue  # Skip if no valid neighbors are found\n",
        "\n",
        "#         idx_B = np.random.choice(valid_neighbors)\n",
        "#         point_B = os_df.loc[idx_B]\n",
        "\n",
        "#         synthetic_point = {}\n",
        "#         for i, col in enumerate(os_df.columns):\n",
        "#             if cat_features[i]:\n",
        "#                 neighbor_values = os_df.iloc[valid_neighbors][col].tolist()\n",
        "#                 synthetic_point[col] = max(set(neighbor_values), key=neighbor_values.count)\n",
        "#             else:\n",
        "#                 alpha = np.random.rand()\n",
        "#                 synthetic_point[col] = point_A[col] + alpha * (point_B[col] - point_A[col])\n",
        "\n",
        "#         synthetic_samples.append(synthetic_point)\n",
        "\n",
        "#     return pd.DataFrame(synthetic_samples), len(synthetic_samples), os_ix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "e2XnJtBX5D8G"
      },
      "outputs": [],
      "source": [
        "def find_optimal_epsilon(filtered_data, cat_features, min_samples, distance_matrix, eps_step=0.001, eps_min=0.01, eps_max=1.1):\n",
        "\n",
        "    def cluster_count(eps):\n",
        "        dbscan = DBSCAN(eps=eps, min_samples=min_samples, metric='precomputed')\n",
        "        labels = dbscan.fit_predict(distance_matrix)\n",
        "        unique_labels = np.unique(labels)\n",
        "        n_clusters = len(unique_labels)  # - (1 if -1 in unique_labels else 0)\n",
        "        return n_clusters, unique_labels\n",
        "\n",
        "    # Binary search for optimal epsilon\n",
        "    while eps_max - eps_min > eps_step:\n",
        "        eps_mid = (eps_min + eps_max) / 2\n",
        "        n_clusters_mid, labels_mid = cluster_count(eps_mid)\n",
        "        print(eps_mid, n_clusters_mid, labels_mid, 'mids')\n",
        "\n",
        "        if n_clusters_mid == 1:\n",
        "            if -1 in labels_mid:\n",
        "                eps_min = eps_mid  # Only noise points, increase epsilon\n",
        "            else:\n",
        "                eps_max = eps_mid  # Only core points, decrease epsilon\n",
        "        elif n_clusters_mid > 2:\n",
        "            eps_min = eps_mid  # More than two clusters, increase epsilon\n",
        "        else:\n",
        "            eps_max = eps_mid  # Exactly two clusters, continue search to fine-tune\n",
        "        print(eps_min, eps_max, 'min, max')\n",
        "    return eps_max\n",
        "\n",
        "# Custom SMOTE-DBSCAN function\n",
        "def custom_smote_dbscan(X_train, cat_features, pu_ix, nu_ix, group_column_train, total_ratio):\n",
        "    \"\"\"\n",
        "    X_train is the training dataset preprocessed, group_column_train is a column containing the group of each\n",
        "    instance in X_train\n",
        "    \"\"\"\n",
        "    cat_attr_ix = [i for i, value in enumerate(cat_features) if value]\n",
        "\n",
        "    X2_df = X_train[group_column_train == pu_ix]\n",
        "    X2 = X2_df.values\n",
        "    X3_df = X_train[group_column_train == nu_ix]\n",
        "    X3 = X3_df.values\n",
        "\n",
        "    PU = len(X2)\n",
        "    NU = len(X3)\n",
        "\n",
        "    # Determine the oversampling target based on a given total_ratio\n",
        "    if (PU / NU) > total_ratio:\n",
        "        oversampling_target = (PU / total_ratio) - NU\n",
        "        os_df = X3_df\n",
        "        os_ix = nu_ix\n",
        "    elif (PU / NU) == total_ratio:\n",
        "        print(\"The ratio of PU to NU is within the acceptable range of total_ratio.\")\n",
        "        return [], 0, pu_ix\n",
        "    else:\n",
        "        oversampling_target = (total_ratio * NU) - PU\n",
        "        os_df = X2_df\n",
        "        os_ix = pu_ix\n",
        "    os_df = os_df.reset_index(drop=True)\n",
        "\n",
        "    # Calculate min_samples\n",
        "    min_samples = round(math.log(len(os_df)))\n",
        "    distance_matrix = gower_matrix(os_df, cat_features=cat_features)\n",
        "\n",
        "    # Find the optimal epsilon for os_df\n",
        "    optimal_eps = find_optimal_epsilon(os_df, cat_features, min_samples, distance_matrix)\n",
        "\n",
        "    # DBSCAN clustering with the optimal epsilon\n",
        "    dbscan = DBSCAN(eps=optimal_eps, min_samples=min_samples, metric='precomputed')\n",
        "    clusters = dbscan.fit_predict(distance_matrix)\n",
        "\n",
        "    # Get cluster labels\n",
        "    labels = dbscan.labels_\n",
        "\n",
        "    # Get core samples\n",
        "    core_samples_mask = np.zeros_like(labels, dtype=bool)\n",
        "    core_samples_mask[dbscan.core_sample_indices_] = True\n",
        "\n",
        "    # Identify core, border, and noise points\n",
        "    core_points = os_df[core_samples_mask]\n",
        "    border_points = os_df[~core_samples_mask & (labels != -1)]\n",
        "    noise_points = os_df[labels == -1]\n",
        "\n",
        "    if len(border_points) == 0:\n",
        "        border_points = core_points\n",
        "\n",
        "    # Initialize synthetic samples list\n",
        "    synthetic_samples = []\n",
        "\n",
        "    border_indices = border_points.index.tolist()\n",
        "    random.shuffle(border_indices)\n",
        "    current_index = 0\n",
        "\n",
        "    while len(synthetic_samples) < oversampling_target:\n",
        "        idx_A = border_indices[current_index % len(border_indices)]\n",
        "        current_index += 1\n",
        "        point_A = os_df.loc[idx_A]\n",
        "\n",
        "        # Ensure point B is not a noise point\n",
        "        distances_to_A = distance_matrix[idx_A]\n",
        "        neighbors = np.argsort(distances_to_A)[1:min_samples+1]  # Exclude the point itself\n",
        "        valid_neighbors = [idx for idx in neighbors if labels[idx] != -1]  # Exclude noise points\n",
        "\n",
        "        if not valid_neighbors:\n",
        "            continue  # Skip if no valid neighbors are found\n",
        "\n",
        "        idx_B = np.random.choice(valid_neighbors)\n",
        "        point_B = os_df.loc[idx_B]\n",
        "\n",
        "        synthetic_point = {}\n",
        "        for i, col in enumerate(os_df.columns):\n",
        "            if cat_features[i]:\n",
        "                neighbor_values = os_df.iloc[valid_neighbors][col].tolist()\n",
        "                synthetic_point[col] = max(set(neighbor_values), key=neighbor_values.count)\n",
        "            else:\n",
        "                alpha = np.random.rand()\n",
        "                synthetic_point[col] = point_A[col] + alpha * (point_B[col] - point_A[col])\n",
        "\n",
        "        synthetic_samples.append(synthetic_point)\n",
        "\n",
        "    return pd.DataFrame(synthetic_samples), len(synthetic_samples), os_ix\n",
        "\n",
        "# Example usage (assuming you have defined X_train, cat_features, etc.):\n",
        "# synthetic_samples, num_samples, oversampled_index = custom_smote_dbscan(X_train, cat_features, pu_ix, nu_ix, group_column_train, total_ratio)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "623NfOVPIxqg"
      },
      "outputs": [],
      "source": [
        "def oversample_groups(X_train, cat_features, custom_smote, group_column_train, total_ratio, reverse_group_mapping):\n",
        "    \"\"\"\n",
        "    Function to oversample multiple groups automatically based on group labels.\n",
        "\n",
        "    Parameters:\n",
        "    - X_train: Preprocessed training dataset.\n",
        "    - cat_features: List indicating categorical features.\n",
        "    - custom_smote: Custom SMOTE function to be used.\n",
        "    - group_column_train: Column containing the group label for each instance.\n",
        "    - total_ratio: Desired ratio of positive to negative labels.\n",
        "    - reverse_group_mapping: Mapping of groups to sensitive attributes and labels.\n",
        "\n",
        "    Returns:\n",
        "    - synthetic_samples_matrix: Matrix containing all generated synthetic samples.\n",
        "    - synthetic_samples_group: Array of group labels for the synthetic samples.\n",
        "    \"\"\"\n",
        "\n",
        "    synthetic_samples = []\n",
        "    synthetic_samples_group = []\n",
        "\n",
        "    groups = sorted(group_column_train.unique())\n",
        "    paired_groups = [(groups[i], groups[i+1]) for i in range(0, len(groups), 2)]\n",
        "\n",
        "    for group1, group2 in paired_groups:\n",
        "        ########## Determine pu_ix and nu_ix using reverse_group_mapping ##########\n",
        "        if reverse_group_mapping[group1][2] == 1:\n",
        "            pu_ix = group1\n",
        "            nu_ix = group2\n",
        "        else:\n",
        "            pu_ix = group2\n",
        "            nu_ix = group1\n",
        "        ##########################################################################\n",
        "\n",
        "        group_df_pu = X_train[group_column_train == pu_ix]\n",
        "        group_df_nu = X_train[group_column_train == nu_ix]\n",
        "        positive_count = group_df_pu[group_df_pu[label] == 1].shape[0]\n",
        "        negative_count = group_df_nu[group_df_nu[label] == 0].shape[0]\n",
        "\n",
        "        if positive_count == 0 or negative_count == 0:\n",
        "            continue\n",
        "\n",
        "        current_ratio = positive_count / negative_count\n",
        "\n",
        "        if current_ratio == total_ratio:\n",
        "            continue  # Skip the most privileged group\n",
        "\n",
        "        synthetic_points, synthetic_count, os_ix = custom_smote(X_train, cat_features, pu_ix, nu_ix, group_column_train, total_ratio=total_ratio)\n",
        "        pu_column = np.full((len(synthetic_points), 1), os_ix)\n",
        "        synthetic_samples.append(synthetic_points)\n",
        "        synthetic_samples_group.append(pu_column)\n",
        "        print(f\"Oversampling for group pair ({pu_ix}, {nu_ix}): Added {synthetic_count} synthetic samples in {os_ix}.\")\n",
        "\n",
        "    synthetic_samples_matrix = pd.concat(synthetic_samples, ignore_index=True)\n",
        "    synthetic_samples_group = np.concatenate(synthetic_samples_group)\n",
        "\n",
        "    return synthetic_samples_matrix, synthetic_samples_group\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpLZboUcIxSM",
        "outputId": "4c2a8af5-e42c-47fb-f64a-6e9b3a6c2082"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 2 [-1  0] mids\n",
            "0.01 0.14625000000000002 min, max\n",
            "0.07812500000000001 1 [-1] mids\n",
            "0.07812500000000001 0.14625000000000002 min, max\n",
            "0.11218750000000002 1 [-1] mids\n",
            "0.11218750000000002 0.14625000000000002 min, max\n",
            "0.12921875000000002 1 [-1] mids\n",
            "0.12921875000000002 0.14625000000000002 min, max\n",
            "0.13773437500000002 2 [-1  0] mids\n",
            "0.12921875000000002 0.13773437500000002 min, max\n",
            "0.1334765625 2 [-1  0] mids\n",
            "0.12921875000000002 0.1334765625 min, max\n",
            "0.13134765625 1 [-1] mids\n",
            "0.13134765625 0.1334765625 min, max\n",
            "0.132412109375 2 [-1  0] mids\n",
            "0.13134765625 0.132412109375 min, max\n",
            "0.13187988281250002 1 [-1] mids\n",
            "0.13187988281250002 0.132412109375 min, max\n",
            "Oversampling for group pair (2, 3): Added 22 synthetic samples in 2.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 3 [-1  0  1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.18031250000000004 min, max\n",
            "0.16328125000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.16328125000000004 min, max\n",
            "0.15476562500000002 3 [-1  0  1] mids\n",
            "0.15476562500000002 0.16328125000000004 min, max\n",
            "0.15902343750000003 2 [-1  0] mids\n",
            "0.15476562500000002 0.15902343750000003 min, max\n",
            "0.15689453125000002 2 [-1  0] mids\n",
            "0.15476562500000002 0.15689453125000002 min, max\n",
            "0.15583007812500002 2 [-1  0] mids\n",
            "0.15476562500000002 0.15583007812500002 min, max\n",
            "0.15529785156250003 3 [-1  0  1] mids\n",
            "0.15529785156250003 0.15583007812500002 min, max\n",
            "Oversampling for group pair (4, 5): Added 35 synthetic samples in 4.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 1 [-1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 3 [-1  0  1] mids\n",
            "0.18031250000000004 0.21437500000000004 min, max\n",
            "0.19734375000000004 2 [-1  0] mids\n",
            "0.18031250000000004 0.19734375000000004 min, max\n",
            "0.18882812500000004 3 [-1  0  1] mids\n",
            "0.18882812500000004 0.19734375000000004 min, max\n",
            "0.19308593750000003 3 [-1  0  1] mids\n",
            "0.19308593750000003 0.19734375000000004 min, max\n",
            "0.19521484375000003 2 [-1  0] mids\n",
            "0.19308593750000003 0.19521484375000003 min, max\n",
            "0.19415039062500003 3 [-1  0  1] mids\n",
            "0.19415039062500003 0.19521484375000003 min, max\n",
            "0.19468261718750002 2 [-1  0] mids\n",
            "0.19415039062500003 0.19468261718750002 min, max\n",
            "Oversampling for group pair (6, 7): Added 36 synthetic samples in 6.\n"
          ]
        }
      ],
      "source": [
        "synthetic_samples_matrix_dbscan, synthetic_samples_group_dbscan = oversample_groups(X_train, cat_features, custom_smote_dbscan, subgroup_column_train, total_ratio, reverse_group_mapping)\n",
        "\n",
        "# Concatenate the original dataset with the synthetic samples\n",
        "X_train_resampled_dbscan = pd.concat([X_train, pd.DataFrame(synthetic_samples_matrix_dbscan, columns=X_train.columns)], ignore_index=True)\n",
        "#subgroup_column_resampled_tax = pd.concat([X_train[group_column_train], pd.Series(synthetic_samples_group_tax.flatten())], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNrDlY5mbMy9"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "CLASSIFICATION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "kl1ed1oebRQq"
      },
      "outputs": [],
      "source": [
        "def evaluate_model_performance(X_train, X_test, protected_attributes, label_name, groups, model, weights=None):\n",
        "    favorable_label = 1.0\n",
        "    unfavorable_label = 0.0\n",
        "    X_train[label_name] = X_train[label_name].astype(float)\n",
        "    X_test[label_name] = X_test[label_name].astype(float)\n",
        "    # If weights is not provided, create an array of ones with the same length as X_train\n",
        "    if weights is None:\n",
        "        weights = np.ones(len(X_train))\n",
        "\n",
        "    # Create BinaryLabelDatasets\n",
        "    binary_ds_train = BinaryLabelDataset(df=X_train, label_names=[label_name],\n",
        "                                         protected_attribute_names=protected_attributes,\n",
        "                                         favorable_label=favorable_label, unfavorable_label=unfavorable_label)\n",
        "    binary_ds_test = BinaryLabelDataset(df=X_test, label_names=[label_name],\n",
        "                                        protected_attribute_names=protected_attributes,\n",
        "                                        favorable_label=favorable_label, unfavorable_label=unfavorable_label)\n",
        "    if model == 'Logistic Regression':\n",
        "        classifier = LogisticRegression(max_iter = 500)\n",
        "    elif model == 'Random Forest':\n",
        "        classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    elif model == 'Gradient Boosting':\n",
        "        classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "    else:\n",
        "        raise ValueError('Choose one classification algorithm between Logistic Regression, Random Forest, Gradient Boosting')\n",
        "\n",
        "    classifier.fit(X_train.drop(columns=[label_name]), X_train[label_name], sample_weight=weights)\n",
        "    predicted_labels = classifier.predict(X_test.drop(columns=[label_name]))\n",
        "\n",
        "    X_test_with_predictions = pd.concat([X_test.drop(columns=[label_name]), pd.Series(predicted_labels, name=label_name, index=X_test.index)], axis=1)\n",
        "\n",
        "    binary_ds_test_pred = BinaryLabelDataset(df=X_test_with_predictions, label_names=[label_name],\n",
        "                                             protected_attribute_names=protected_attributes,\n",
        "                                             favorable_label=favorable_label, unfavorable_label=unfavorable_label)\n",
        "\n",
        "    all_results = {}\n",
        "    for (group1, group2) in itertools.combinations(groups, 2):\n",
        "        print(group1, group2, 'gruppi')\n",
        "        pair_key = f\"{group1['name']} vs {group2['name']}\"\n",
        "        all_results[pair_key] = evaluate(\n",
        "            binary_ds_test, binary_ds_test_pred,\n",
        "            [group1['attributes']], [group2['attributes']])\n",
        "        #print([group1['attributes']], [group2['attributes']])\n",
        "\n",
        "\n",
        "    return all_results, predicted_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "_47PB6wD5AAl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "NSao9wLoemq1"
      },
      "outputs": [],
      "source": [
        "def evaluate(test_data, pred, priv_group, unpriv_group):\n",
        "    cm = ClassificationMetric(test_data, pred,\n",
        "                              unprivileged_groups=unpriv_group,\n",
        "                              privileged_groups=priv_group)\n",
        "    dm = BinaryLabelDatasetMetric(pred,\n",
        "                                  unprivileged_groups=unpriv_group,\n",
        "                                  privileged_groups=priv_group)\n",
        "\n",
        "    measure_scores = {\n",
        "        'Balanced Accuracy': balanced_accuracy_score(test_data.labels, pred.labels),\n",
        "        'Accuracy': cm.accuracy(),\n",
        "        'F1 Score': f1_score(test_data.labels.ravel(), pred.labels.ravel()),  # Ensure labels are flat\n",
        "        'Disparate Impact Ratio': dm.disparate_impact(),\n",
        "        #'Demographic Parity Difference': cm.statistical_parity_difference(),\n",
        "        #'Predictive Parity Difference': cm.positive_predictive_value(privileged=True) - cm.positive_predictive_value(privileged=False),\n",
        "        'Average Odds Difference': cm.average_odds_difference(),\n",
        "        'Equal Opportunity Difference': cm.equal_opportunity_difference(),\n",
        "        #'Equalized Odds Difference': cm.average_abs_odds_difference(),\n",
        "        'Consistency': dm.consistency(),\n",
        "        #'TPR Difference': cm.true_positive_rate_difference(),\n",
        "        #'FPR Difference': cm.false_positive_rate_difference(),\n",
        "        #'TNR Difference': cm.true_negative_rate(privileged=True) - cm.true_negative_rate(privileged=False),\n",
        "        #'FNR Difference': cm.false_negative_rate_difference(),\n",
        "    }\n",
        "\n",
        "    return measure_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "pa6opOu1e25S"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(df, actual_labels, predicted_labels):\n",
        "    \"\"\"Compute fairness and performance metrics.\"\"\"\n",
        "    cm = confusion_matrix(actual_labels, predicted_labels)\n",
        "    TN, FP, FN, TP = cm.ravel()\n",
        "    metrics = {\n",
        "        'Accuracy': accuracy_score(actual_labels, predicted_labels),\n",
        "        'Precision': precision_score(actual_labels, predicted_labels),\n",
        "        'Recall': recall_score(actual_labels, predicted_labels),\n",
        "        'F1 Score': f1_score(actual_labels, predicted_labels),\n",
        "        'TPR': TP / (TP + FN),\n",
        "        'FPR': FP / (FP + TN),\n",
        "        'TNR': TN / (TN + FP),\n",
        "        'FNR': FN / (FN + TP),\n",
        "        'TP': TP,\n",
        "        'FP': FP,\n",
        "        'TN': TN,\n",
        "        'FN': FN\n",
        "    }\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rssckrJfJ45",
        "outputId": "c4d535ae-05a0-4e2f-f577-24057bcbf15f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "                              Balanced Accuracy  Accuracy  F1 Score  \\\n",
            "Comparison                                                            \n",
            "Male Adult vs Female Adult             0.663492      0.76  0.840708   \n",
            "Male Adult vs Male Young               0.663492      0.76  0.840708   \n",
            "Male Adult vs Female Young             0.663492      0.76  0.840708   \n",
            "Female Adult vs Male Young             0.663492      0.76  0.840708   \n",
            "Female Adult vs Female Young           0.663492      0.76  0.840708   \n",
            "Male Young vs Female Young             0.663492      0.76  0.840708   \n",
            "\n",
            "                              Disparate Impact Ratio  Average Odds Difference  \\\n",
            "Comparison                                                                      \n",
            "Male Adult vs Female Adult                  0.939291                -0.038142   \n",
            "Male Adult vs Male Young                    1.078273                 0.100621   \n",
            "Male Adult vs Female Young                  0.771282                -0.136392   \n",
            "Female Adult vs Male Young                  1.147964                 0.138763   \n",
            "Female Adult vs Female Young                0.821132                -0.098250   \n",
            "Male Young vs Female Young                  0.715294                -0.237013   \n",
            "\n",
            "                              Equal Opportunity Difference  \\\n",
            "Comparison                                                   \n",
            "Male Adult vs Female Adult                       -0.021739   \n",
            "Male Adult vs Male Young                          0.086957   \n",
            "Male Adult vs Female Young                       -0.127329   \n",
            "Female Adult vs Male Young                        0.108696   \n",
            "Female Adult vs Female Young                     -0.105590   \n",
            "Male Young vs Female Young                       -0.214286   \n",
            "\n",
            "                                       Consistency  \n",
            "Comparison                                          \n",
            "Male Adult vs Female Adult    [0.8680000000000001]  \n",
            "Male Adult vs Male Young      [0.8680000000000001]  \n",
            "Male Adult vs Female Young    [0.8680000000000001]  \n",
            "Female Adult vs Male Young    [0.8680000000000001]  \n",
            "Female Adult vs Female Young  [0.8680000000000001]  \n",
            "Male Young vs Female Young    [0.8680000000000001]  \n"
          ]
        }
      ],
      "source": [
        "##################################################################################\n",
        "results_orig, pred_labels_orig = evaluate_model_performance(X_train, X_test, sensitive_attributes, label,\n",
        "                                                            groups, model=model)\n",
        "#model = 'Random Forest'\n",
        "#model = 'Gradient Boosting'\n",
        "\n",
        "# Initialize a list to hold DataFrames\n",
        "data_frames = []\n",
        "\n",
        "# Populate the list with DataFrames, each having a unique row index\n",
        "for key, values in results_orig.items():\n",
        "    df_part = pd.DataFrame([values], index=[key])\n",
        "    data_frames.append(df_part)\n",
        "\n",
        "# Concatenate all DataFrames into a single DataFrame\n",
        "results_orig_df = pd.concat(data_frames)\n",
        "results_orig_df.index.name = 'Comparison'\n",
        "\n",
        "# Print the results DataFrame\n",
        "print(results_orig_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAn82UJohXFR",
        "outputId": "d24dc932-448c-4a51-a4b8-e2ad8350de19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "                              Balanced Accuracy  Accuracy  F1 Score  \\\n",
            "Comparison                                                            \n",
            "Male Adult vs Female Adult             0.634127      0.75  0.838013   \n",
            "Male Adult vs Male Young               0.634127      0.75  0.838013   \n",
            "Male Adult vs Female Young             0.634127      0.75  0.838013   \n",
            "Female Adult vs Male Young             0.634127      0.75  0.838013   \n",
            "Female Adult vs Female Young           0.634127      0.75  0.838013   \n",
            "Male Young vs Female Young             0.634127      0.75  0.838013   \n",
            "\n",
            "                              Disparate Impact Ratio  Average Odds Difference  \\\n",
            "Comparison                                                                      \n",
            "Male Adult vs Female Adult                  1.003747                 0.037286   \n",
            "Male Adult vs Male Young                    1.071405                 0.096998   \n",
            "Male Adult vs Female Young                  1.053758                 0.113232   \n",
            "Female Adult vs Male Young                  1.067405                 0.059712   \n",
            "Female Adult vs Female Young                1.049825                 0.075946   \n",
            "Male Young vs Female Young                  0.983529                 0.016234   \n",
            "\n",
            "                              Equal Opportunity Difference Consistency  \n",
            "Comparison                                                              \n",
            "Male Adult vs Female Adult                       -0.007246      [0.89]  \n",
            "Male Adult vs Male Young                          0.079710      [0.89]  \n",
            "Male Adult vs Female Young                        0.008282      [0.89]  \n",
            "Female Adult vs Male Young                        0.086957      [0.89]  \n",
            "Female Adult vs Female Young                      0.015528      [0.89]  \n",
            "Male Young vs Female Young                       -0.071429      [0.89]  \n"
          ]
        }
      ],
      "source": [
        "##################################################################################\n",
        "results_dbscan, pred_labels_dbscan = evaluate_model_performance(X_train_resampled_dbscan, X_test, sensitive_attributes, label,\n",
        "                                                            groups, model=model)\n",
        "\n",
        "# Initialize a list to hold DataFrames\n",
        "data_frames = []\n",
        "\n",
        "# Populate the list with DataFrames, each having a unique row index\n",
        "for key, values in results_dbscan.items():\n",
        "    df_part = pd.DataFrame([values], index=[key])\n",
        "    data_frames.append(df_part)\n",
        "\n",
        "# Concatenate all DataFrames into a single DataFrame\n",
        "results_dbscan_df = pd.concat(data_frames)\n",
        "results_dbscan_df.index.name = 'Comparison'\n",
        "\n",
        "# Print the results DataFrame\n",
        "print(results_dbscan_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yI6EQv5kqjo"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "OTHER MITIGATION ALGORITHMS - FAIR-SMOTE, REWEIGHING, GERRYFAIR, REMEDY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CASoKKWPo5qU"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "FAIR-SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En16zriFkzRM",
        "outputId": "0bd8b864-64c9-43b8-f45a-6bb0145b2b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Fair-SMOTE' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/joymallyac/Fair-SMOTE.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YZ7hS2-k_gV",
        "outputId": "def6a2ec-f173-4e70-839e-dced13ad7b92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/Fair-SMOTE']\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "# Define the new list of directories\n",
        "new_path = ['/content/Fair-SMOTE']  # Adjust the path as needed\n",
        "\n",
        "# Replace sys.path with the new list\n",
        "sys.path = new_path\n",
        "print(sys.path)\n",
        "\n",
        "from Generate_Samples import generate_samples\n",
        "from Measure import measure_final_score, calculate_recall, calculate_far, calculate_precision, calculate_accuracy\n",
        "from SMOTE import smote\n",
        "import warnings\n",
        "\n",
        "# Suppress specific warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names, but NearestNeighbors was fitted with feature names\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "0jNkdmOwlCG3"
      },
      "outputs": [],
      "source": [
        "def oversample_fair_smote(X_train, sensitive_attributes, label):\n",
        "    # Extracting group counts\n",
        "    zero_zero_zero = len(X_train[(X_train[label] == 0) & (X_train[sensitive_attributes[0]] == 0)\n",
        "                                & (X_train[sensitive_attributes[1]] == 0)])\n",
        "    zero_zero_one = len(X_train[(X_train[label] == 0) & (X_train[sensitive_attributes[0]] == 0)\n",
        "                                & (X_train[sensitive_attributes[1]] == 1)])\n",
        "    zero_one_zero = len(X_train[(X_train[label] == 0) & (X_train[sensitive_attributes[0]] == 1)\n",
        "                                & (X_train[sensitive_attributes[1]] == 0)])\n",
        "    zero_one_one = len(X_train[(X_train[label] == 0) & (X_train[sensitive_attributes[0]] == 1)\n",
        "                                & (X_train[sensitive_attributes[1]] == 1)])\n",
        "    one_zero_zero = len(X_train[(X_train[label] == 1) & (X_train[sensitive_attributes[0]] == 0)\n",
        "                                & (X_train[sensitive_attributes[1]] == 0)])\n",
        "    one_zero_one = len(X_train[(X_train[label] == 1) & (X_train[sensitive_attributes[0]] == 0)\n",
        "                                & (X_train[sensitive_attributes[1]] == 1)])\n",
        "    one_one_zero = len(X_train[(X_train[label] == 1) & (X_train[sensitive_attributes[0]] == 1)\n",
        "                                & (X_train[sensitive_attributes[1]] == 0)])\n",
        "    one_one_one = len(X_train[(X_train[label] == 1) & (X_train[sensitive_attributes[0]] == 1)\n",
        "                                & (X_train[sensitive_attributes[1]] == 1)])\n",
        "\n",
        "    # Finding maximum\n",
        "    maximum = max(zero_zero_zero, zero_zero_one, zero_one_zero, zero_one_one, one_zero_zero, one_zero_one, one_one_zero, one_one_one)\n",
        "    print(f\"Maximum count: {maximum}\")\n",
        "\n",
        "    # Printing which group has maximum count\n",
        "    if maximum == zero_zero_zero:\n",
        "        print(\"zero_zero_zero is maximum\")\n",
        "    elif maximum == zero_zero_one:\n",
        "        print(\"zero_zero_one is maximum\")\n",
        "    elif maximum == zero_one_zero:\n",
        "        print(\"zero_one_zero is maximum\")\n",
        "    elif maximum == zero_one_one:\n",
        "        print(\"zero_one_one is maximum\")\n",
        "    elif maximum == one_zero_zero:\n",
        "        print(\"one_zero_zero is maximum\")\n",
        "    elif maximum == one_zero_one:\n",
        "        print(\"one_zero_one is maximum\")\n",
        "    elif maximum == one_one_zero:\n",
        "        print(\"one_one_zero is maximum\")\n",
        "    elif maximum == one_one_one:\n",
        "        print(\"one_one_one is maximum\")\n",
        "\n",
        "    # Calculating number of samples to be increased for each group\n",
        "    zero_zero_zero_to_be_increased = maximum - zero_zero_zero\n",
        "    zero_zero_one_to_be_increased = maximum - zero_zero_one\n",
        "    zero_one_zero_to_be_increased = maximum - zero_one_zero\n",
        "    zero_one_one_to_be_increased = maximum - zero_one_one\n",
        "    one_zero_zero_to_be_increased = maximum - one_zero_zero\n",
        "    one_zero_one_to_be_increased = maximum - one_zero_one\n",
        "    one_one_zero_to_be_increased = maximum - one_one_zero\n",
        "    one_one_one_to_be_increased = maximum - one_one_one\n",
        "\n",
        "    print(f\"Counts to be increased for each group:\")\n",
        "    print(f\"zero_zero_zero: {zero_zero_zero_to_be_increased}\")\n",
        "    print(f\"zero_zero_one: {zero_zero_one_to_be_increased}\")\n",
        "    print(f\"zero_one_zero: {zero_one_zero_to_be_increased}\")\n",
        "    print(f\"zero_one_one: {zero_one_one_to_be_increased}\")\n",
        "    print(f\"one_zero_zero: {one_zero_zero_to_be_increased}\")\n",
        "    print(f\"one_zero_one: {one_zero_one_to_be_increased}\")\n",
        "    print(f\"one_one_zero: {one_one_zero_to_be_increased}\")\n",
        "    print(f\"one_one_one: {one_one_one_to_be_increased}\")\n",
        "\n",
        "    df_zero_zero_zero = X_train[(X_train[label] == 0) & (X_train[sensitive_attributes[0]] == 0)\n",
        "                                & (X_train[sensitive_attributes[1]] == 0)].copy()\n",
        "    df_zero_zero_one = X_train[(X_train[label] == 0) & (X_train[sensitive_attributes[0]] == 0)\n",
        "                                & (X_train[sensitive_attributes[1]] == 1)].copy()\n",
        "    df_zero_one_zero = X_train[(X_train[label] == 0) & (X_train[sensitive_attributes[0]] == 1)\n",
        "                                & (X_train[sensitive_attributes[1]] == 0)].copy()\n",
        "    df_zero_one_one = X_train[(X_train[label] == 0) & (X_train[sensitive_attributes[0]] == 1)\n",
        "                                & (X_train[sensitive_attributes[1]] == 1)].copy()\n",
        "    df_one_zero_zero = X_train[(X_train[label] == 1) & (X_train[sensitive_attributes[0]] == 0)\n",
        "                                & (X_train[sensitive_attributes[1]] == 0)].copy()\n",
        "    df_one_zero_one = X_train[(X_train[label] == 1) & (X_train[sensitive_attributes[0]] == 0)\n",
        "                                & (X_train[sensitive_attributes[1]] == 1)].copy()\n",
        "    df_one_one_zero = X_train[(X_train[label] == 1) & (X_train[sensitive_attributes[0]] == 1)\n",
        "                                & (X_train[sensitive_attributes[1]] == 0)].copy()\n",
        "    df_one_one_one = X_train[(X_train[label] == 1) & (X_train[sensitive_attributes[0]] == 1)\n",
        "                                & (X_train[sensitive_attributes[1]] == 1)].copy()\n",
        "\n",
        "\n",
        "    df_zero_zero_zero.loc[:, sensitive_attributes[0]] = df_zero_zero_zero[sensitive_attributes[0]].astype(str)\n",
        "    df_zero_zero_zero.loc[:, sensitive_attributes[1]] = df_zero_zero_zero[sensitive_attributes[1]].astype(str)\n",
        "\n",
        "    df_zero_zero_one.loc[:, sensitive_attributes[0]] = df_zero_zero_one[sensitive_attributes[0]].astype(str)\n",
        "    df_zero_zero_one.loc[:, sensitive_attributes[1]] = df_zero_zero_one[sensitive_attributes[1]].astype(str)\n",
        "\n",
        "    df_zero_one_zero.loc[:, sensitive_attributes[0]] = df_zero_one_zero[sensitive_attributes[0]].astype(str)\n",
        "    df_zero_one_zero.loc[:, sensitive_attributes[1]] = df_zero_one_zero[sensitive_attributes[1]].astype(str)\n",
        "\n",
        "    df_zero_one_one.loc[:, sensitive_attributes[0]] = df_zero_one_one[sensitive_attributes[0]].astype(str)\n",
        "    df_zero_one_one.loc[:, sensitive_attributes[1]] = df_zero_one_one[sensitive_attributes[1]].astype(str)\n",
        "\n",
        "    df_one_zero_zero.loc[:, sensitive_attributes[0]] = df_one_zero_zero[sensitive_attributes[0]].astype(str)\n",
        "    df_one_zero_zero.loc[:, sensitive_attributes[1]] = df_one_zero_zero[sensitive_attributes[1]].astype(str)\n",
        "\n",
        "    df_one_zero_one.loc[:, sensitive_attributes[0]] = df_one_zero_one[sensitive_attributes[0]].astype(str)\n",
        "    df_one_zero_one.loc[:, sensitive_attributes[1]] = df_one_zero_one[sensitive_attributes[1]].astype(str)\n",
        "\n",
        "    df_one_one_zero.loc[:, sensitive_attributes[0]] = df_one_one_zero[sensitive_attributes[0]].astype(str)\n",
        "    df_one_one_zero.loc[:, sensitive_attributes[1]] = df_one_one_zero[sensitive_attributes[1]].astype(str)\n",
        "\n",
        "    df_one_one_one.loc[:, sensitive_attributes[0]] = df_one_one_one[sensitive_attributes[0]].astype(str)\n",
        "    df_one_one_one.loc[:, sensitive_attributes[1]] = df_one_one_one[sensitive_attributes[1]].astype(str)\n",
        "\n",
        "    # Generating samples for each group\n",
        "    df_zero_zero_zero = generate_samples(zero_zero_zero_to_be_increased, df_zero_zero_zero, 'Germann')\n",
        "    df_zero_zero_one = generate_samples(zero_zero_one_to_be_increased, df_zero_zero_one, 'Germann')\n",
        "    df_zero_one_zero = generate_samples(zero_one_zero_to_be_increased, df_zero_one_zero, 'Germann')\n",
        "    df_zero_one_one = generate_samples(zero_one_one_to_be_increased, df_zero_one_one, 'Germann')\n",
        "    df_one_zero_zero = generate_samples(one_zero_zero_to_be_increased, df_one_zero_zero, 'Germann')\n",
        "    df_one_zero_one = generate_samples(one_zero_one_to_be_increased, df_one_zero_one, 'Germann')\n",
        "    df_one_one_zero = generate_samples(one_one_zero_to_be_increased, df_one_one_zero, 'Germann')\n",
        "    df_one_one_one = generate_samples(one_one_one_to_be_increased, df_one_one_one, 'Germann')\n",
        "\n",
        "    # Concatenating dataframes\n",
        "    X_train_resampled_fair_smote = pd.concat([df_zero_zero_zero, df_zero_zero_one, df_zero_one_zero, df_zero_one_one,\n",
        "                                              df_one_zero_zero, df_one_zero_one, df_one_one_zero, df_one_one_one])\n",
        "    X_train_resampled_fair_smote.columns = X_train.columns\n",
        "\n",
        "    return X_train_resampled_fair_smote\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZaTy4BRoZkG",
        "outputId": "ddfa001f-71c0-432f-e218-54aeaf9ad236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum count: 321\n",
            "one_one_one is maximum\n",
            "Counts to be increased for each group:\n",
            "zero_zero_zero: 296\n",
            "zero_zero_one: 270\n",
            "zero_one_zero: 303\n",
            "zero_one_one: 205\n",
            "one_zero_zero: 287\n",
            "one_zero_one: 214\n",
            "one_one_zero: 293\n",
            "one_one_one: 0\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "                              Balanced Accuracy  Accuracy  F1 Score  \\\n",
            "Comparison                                                            \n",
            "Male Adult vs Female Adult             0.661905      0.74  0.821918   \n",
            "Male Adult vs Male Young               0.661905      0.74  0.821918   \n",
            "Male Adult vs Female Young             0.661905      0.74  0.821918   \n",
            "Female Adult vs Male Young             0.661905      0.74  0.821918   \n",
            "Female Adult vs Female Young           0.661905      0.74  0.821918   \n",
            "Male Young vs Female Young             0.661905      0.74  0.821918   \n",
            "\n",
            "                              Disparate Impact Ratio  Average Odds Difference  \\\n",
            "Comparison                                                                      \n",
            "Male Adult vs Female Adult                  0.992958                 0.065573   \n",
            "Male Adult vs Male Young                    1.045219                 0.089265   \n",
            "Male Adult vs Female Young                  1.059155                 0.137425   \n",
            "Female Adult vs Male Young                  1.052632                 0.023692   \n",
            "Female Adult vs Female Young                1.066667                 0.071852   \n",
            "Male Young vs Female Young                  1.013333                 0.048160   \n",
            "\n",
            "                              Equal Opportunity Difference  \\\n",
            "Comparison                                                   \n",
            "Male Adult vs Female Adult                       -0.065217   \n",
            "Male Adult vs Male Young                          0.047101   \n",
            "Male Adult vs Female Young                       -0.012422   \n",
            "Female Adult vs Male Young                        0.112319   \n",
            "Female Adult vs Female Young                      0.052795   \n",
            "Male Young vs Female Young                       -0.059524   \n",
            "\n",
            "                                       Consistency  \n",
            "Comparison                                          \n",
            "Male Adult vs Female Adult    [0.8500000000000001]  \n",
            "Male Adult vs Male Young      [0.8500000000000001]  \n",
            "Male Adult vs Female Young    [0.8500000000000001]  \n",
            "Female Adult vs Male Young    [0.8500000000000001]  \n",
            "Female Adult vs Female Young  [0.8500000000000001]  \n",
            "Male Young vs Female Young    [0.8500000000000001]  \n"
          ]
        }
      ],
      "source": [
        "###################################################################################\n",
        "X_train_resampled_fair_smote = oversample_fair_smote(X_train, sensitive_attributes, label)\n",
        "# Evaluate model performance\n",
        "results_fair_smote, pred_labels_fair_smote = evaluate_model_performance(X_train_resampled_fair_smote, X_test, sensitive_attributes, label,\n",
        "                                                            groups, model=model)\n",
        "# Initialize a list to hold DataFrames\n",
        "data_frames = []\n",
        "\n",
        "# Populate the list with DataFrames, each having a unique row index\n",
        "for key, values in results_fair_smote.items():\n",
        "    df_part = pd.DataFrame([values], index=[key])\n",
        "    data_frames.append(df_part)\n",
        "\n",
        "# Concatenate all DataFrames into a single DataFrame\n",
        "results_fair_smote_df = pd.concat(data_frames)\n",
        "results_fair_smote_df.index.name = 'Comparison'\n",
        "\n",
        "# Print the results DataFrame\n",
        "print(results_fair_smote_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR4Qa0eIpAeB"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "REWEIGHTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo8GOaJZpC0W",
        "outputId": "85b876e5-cbd2-48be-c257-85d6f14f6039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'AIF360' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/IBM/AIF360.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "H-pTMWRmpEpZ"
      },
      "outputs": [],
      "source": [
        "new_path = ['/content']\n",
        "sys.path = new_path\n",
        "from reweighing_cust import Reweighing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "02XzPl4UpMsB"
      },
      "outputs": [],
      "source": [
        "class CustomDataset:\n",
        "    def __init__(self, data, sensitive_attributes, label):\n",
        "        self.data = data\n",
        "        self.protected_attribute_names = sensitive_attributes\n",
        "        self.protected_attributes = np.column_stack([data[sensitive_attributes[0]], data[sensitive_attributes[1]]])\n",
        "        self.labels = data[label].astype(float).values.reshape(-1, 1)\n",
        "        self.favorable_label = 1.0\n",
        "        self.unfavorable_label = 0.0\n",
        "        self.instance_weights = np.ones(len(data))\n",
        "        self.privileged_protected_attributes = [np.array([1.]), np.array([1.])]\n",
        "        self.unprivileged_protected_attributes = [np.array([0.]), np.array([0.])]\n",
        "        self.feature_names = data.columns[data.columns != label].tolist()\n",
        "\n",
        "custom_data = CustomDataset(X_train, sensitive_attributes, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "rbIQSjt8v0qs"
      },
      "outputs": [],
      "source": [
        "privileged_groups = [{sensitive_attributes[0]: 1, sensitive_attributes[1]: 1}]\n",
        "unprivileged_groups = [{sensitive_attributes[0]: 0, sensitive_attributes[1]: 0}]\n",
        "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
        "               privileged_groups=privileged_groups)\n",
        "\n",
        "RW.fit(custom_data)\n",
        "dataset_transf_train = RW.transform(custom_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaAbAzdWxNec",
        "outputId": "37aabd6c-5cc5-492a-ffe3-f0f3c3f0f939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "                              Balanced Accuracy  Accuracy  F1 Score  \\\n",
            "Comparison                                                            \n",
            "Male Adult vs Female Adult              0.67381      0.77  0.847682   \n",
            "Male Adult vs Male Young                0.67381      0.77  0.847682   \n",
            "Male Adult vs Female Young              0.67381      0.77  0.847682   \n",
            "Female Adult vs Male Young              0.67381      0.77  0.847682   \n",
            "Female Adult vs Female Young            0.67381      0.77  0.847682   \n",
            "Male Young vs Female Young              0.67381      0.77  0.847682   \n",
            "\n",
            "                              Disparate Impact Ratio  Average Odds Difference  \\\n",
            "Comparison                                                                      \n",
            "Male Adult vs Female Adult                  0.964009                 0.001858   \n",
            "Male Adult vs Male Young                    1.106648                 0.140621   \n",
            "Male Adult vs Female Young                  1.038947                 0.111400   \n",
            "Female Adult vs Male Young                  1.147964                 0.138763   \n",
            "Female Adult vs Female Young                1.077736                 0.109543   \n",
            "Male Young vs Female Young                  0.938824                -0.029221   \n",
            "\n",
            "                              Equal Opportunity Difference  \\\n",
            "Comparison                                                   \n",
            "Male Adult vs Female Adult                       -0.021739   \n",
            "Male Adult vs Male Young                          0.086957   \n",
            "Male Adult vs Female Young                        0.015528   \n",
            "Female Adult vs Male Young                        0.108696   \n",
            "Female Adult vs Female Young                      0.037267   \n",
            "Male Young vs Female Young                       -0.071429   \n",
            "\n",
            "                                       Consistency  \n",
            "Comparison                                          \n",
            "Male Adult vs Female Adult    [0.8766666666666667]  \n",
            "Male Adult vs Male Young      [0.8766666666666667]  \n",
            "Male Adult vs Female Young    [0.8766666666666667]  \n",
            "Female Adult vs Male Young    [0.8766666666666667]  \n",
            "Female Adult vs Female Young  [0.8766666666666667]  \n",
            "Male Young vs Female Young    [0.8766666666666667]  \n"
          ]
        }
      ],
      "source": [
        "results_reweighing, pred_labels_reweighing = evaluate_model_performance(X_train, X_test, sensitive_attributes, label,\n",
        "                                                                        groups, model = model,\n",
        "                                                                        weights=custom_data.instance_weights)\n",
        "# Initialize a list to hold DataFrames\n",
        "data_frames = []\n",
        "\n",
        "# Populate the list with DataFrames, each having a unique row index\n",
        "for key, values in results_reweighing.items():\n",
        "    df_part = pd.DataFrame([values], index=[key])\n",
        "    data_frames.append(df_part)\n",
        "\n",
        "# Concatenate all DataFrames into a single DataFrame\n",
        "results_reweighing_df = pd.concat(data_frames)\n",
        "results_reweighing_df.index.name = 'Comparison'\n",
        "\n",
        "# Print the results DataFrame\n",
        "print(results_reweighing_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWsRiQtkzpD2"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "REMEDY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "b5hG3RtNzqlx"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content')  # Add the directory containing remedy_cust.py to the Python path\n",
        "from remedy_cust import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "id": "pbTbeelCz1gD"
      },
      "outputs": [],
      "source": [
        "columns_all = X_train.drop(columns=[label])\n",
        "label_y = label\n",
        "columns_protected = sensitive_attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJRey0igz_8Y",
        "outputId": "9a39d8d8-0d8c-4055-9fd3-087332d3da34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['personal_status', 'age', 'credit']\n",
            "   personal_status  age  credit  cnt\n",
            "0                0    0     0.0   25\n",
            "1                0    0     1.0   34\n",
            "2                0    1     0.0   51\n",
            "3                0    1     1.0  107\n",
            "4                1    0     0.0   18\n",
            "5                1    0     1.0   28\n",
            "6                1    1     0.0  116\n",
            "7                1    1     1.0  321 ['personal_status', 'age']\n",
            "[] [] ['personal_status', 'age'] {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 2, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ],
      "source": [
        "#names = [\"Output of get_temp function, all of the attributes for given group\"]\n",
        "#temp2 = [\"Output of get_temp function, sum count by group\"]\n",
        "temp2, names = get_temp(X_train, columns_protected, label_y)\n",
        "print(temp2, names)\n",
        "#temp2 counts the number of instances for each combination of sensitive attr and label (like my group count)\n",
        "#names is the list of sensit attr\n",
        "unfair_group, unfair_names, skew_candidates, unfair_dict = get_unfair_group(columns_protected, [])\n",
        "#all empty beside skew candidates that is the list of sensitive attr\n",
        "print(unfair_group, unfair_names, skew_candidates, unfair_dict)\n",
        "#all_names is a dict that has 0:[], 1:sens attr1, 2:sens attr2, 3:sens attr1, sens attr2. So for each key (number) it\n",
        "#associates all possible combinations of sens attr\n",
        "all_names = candidate_groups(skew_candidates, unfair_dict, columns_protected, unfair_names)\n",
        "#name values is a dict with sens attrib: possible values\n",
        "names_values = name_val_dict(X_train, names)\n",
        "\n",
        "all_names_lst = list(all_names.keys())[1:] # CHANGED HERE\n",
        "all_names_lst.reverse()\n",
        "#all_names_lst is a list of the keys of the dict all_names, so numbers [3,2,1]\n",
        "all_names_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMOwrEHO0Gf1",
        "outputId": "6e006ab1-fd36-4fab-cf5d-da3f7f2bf16a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "700\n",
            "?????/////\n",
            "3\n",
            "['personal_status', 'age', 'credit']\n",
            "   personal_status  age  credit  cnt\n",
            "0                0    0     0.0   25\n",
            "1                0    0     1.0   34\n",
            "2                0    1     0.0   51\n",
            "3                0    1     1.0  107\n",
            "4                1    0     0.0   18\n",
            "5                1    0     1.0   28\n",
            "6                1    1     0.0  116\n",
            "7                1    1     1.0  321 \n",
            " ['personal_status', 'age'] temp2,names \n",
            "\n",
            "     personal_status  age  credit  cnt\n",
            "0                  0    1     0.0    0\n",
            "1                  1    0     1.0    0\n",
            "2                  1    1     1.0    0\n",
            "3                  1    1     1.0    0\n",
            "4                  0    1     1.0    0\n",
            "..               ...  ...     ...  ...\n",
            "695                1    1     1.0    0\n",
            "696                0    1     1.0    0\n",
            "697                0    1     0.0    0\n",
            "698                0    1     0.0    0\n",
            "699                1    1     1.0    0\n",
            "\n",
            "[700 rows x 4 columns] \n",
            "    personal_status  age  cnt\n",
            "0                0    0   59\n",
            "1                0    1  158\n",
            "2                1    0   46\n",
            "3                1    1  437 temp,temp_g \n",
            "\n",
            "[age  credit\n",
            "0    0.0        43\n",
            "     1.0        62\n",
            "1    0.0       167\n",
            "     1.0       428\n",
            "Name: cnt, dtype: int64, personal_status  credit\n",
            "0                0.0        76\n",
            "                 1.0       141\n",
            "1                0.0       134\n",
            "                 1.0       349\n",
            "Name: cnt, dtype: int64] listof counts \n",
            "\n",
            "The sets of need pos and neg are\n",
            "[[0, 0], [0, 1], [1, 0]]\n",
            "[[1, 1]]\n",
            "started duplication\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "Adding 15 positive records\n",
            "names  ['personal_status', 'age'] [0, 0]\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "Adding 21 positive records\n",
            "names  ['personal_status', 'age'] [0, 1]\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "Adding 17 positive records\n",
            "names  ['personal_status', 'age'] [1, 0]\n",
            "1.9565217391304348 321 116 48.0666666666667\n",
            "Adding 48 negative records\n",
            "names  ['personal_status', 'age'] [1, 1]\n",
            "801\n",
            "label y  credit\n",
            "1.0    543\n",
            "0.0    258\n",
            "Name: count, dtype: int64\n",
            "?????/////\n",
            "2\n",
            "['age', 'credit']\n",
            "   age  credit  cnt\n",
            "0    0     0.0   43\n",
            "1    0     1.0   94\n",
            "2    1     0.0  215\n",
            "3    1     1.0  449 \n",
            " ['age'] temp2,names \n",
            "\n",
            "     age  credit  cnt\n",
            "0      1     0.0    0\n",
            "1      0     1.0    0\n",
            "2      1     1.0    0\n",
            "3      1     1.0    0\n",
            "4      1     1.0    0\n",
            "..   ...     ...  ...\n",
            "796    1     0.0    0\n",
            "797    1     0.0    0\n",
            "798    1     0.0    0\n",
            "799    1     0.0    0\n",
            "800    1     0.0    0\n",
            "\n",
            "[801 rows x 3 columns] \n",
            "    age  cnt\n",
            "0    0  137\n",
            "1    1  664 temp,temp_g \n",
            "\n",
            "[credit\n",
            "0.0    258\n",
            "1.0    543\n",
            "Name: cnt, dtype: int64] listof counts \n",
            "\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "801\n",
            "label y  credit\n",
            "1.0    543\n",
            "0.0    258\n",
            "Name: count, dtype: int64\n",
            "?????/////\n",
            "1\n",
            "['personal_status', 'credit']\n",
            "   personal_status  credit  cnt\n",
            "0                0     0.0   76\n",
            "1                0     1.0  177\n",
            "2                1     0.0  182\n",
            "3                1     1.0  366 \n",
            " ['personal_status'] temp2,names \n",
            "\n",
            "     personal_status  credit  cnt\n",
            "0                  0     0.0    0\n",
            "1                  1     1.0    0\n",
            "2                  1     1.0    0\n",
            "3                  1     1.0    0\n",
            "4                  0     1.0    0\n",
            "..               ...     ...  ...\n",
            "796                1     0.0    0\n",
            "797                1     0.0    0\n",
            "798                1     0.0    0\n",
            "799                1     0.0    0\n",
            "800                1     0.0    0\n",
            "\n",
            "[801 rows x 3 columns] \n",
            "    personal_status  cnt\n",
            "0                0  253\n",
            "1                1  548 temp,temp_g \n",
            "\n",
            "[credit\n",
            "0.0    258\n",
            "1.0    543\n",
            "Name: cnt, dtype: int64] listof counts \n",
            "\n",
            "The sets of need pos and neg are\n",
            "[]\n",
            "[]\n",
            "started duplication\n",
            "801\n",
            "label y  credit\n",
            "1.0    543\n",
            "0.0    258\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#get all of the candidate groups possible with the combos and names\n",
        "filter_count = 30\n",
        "#copy of the dataset\n",
        "new_train_data = copy.deepcopy(X_train)\n",
        "print(new_train_data.shape[0])\n",
        "\n",
        "#iterate over all the names to get the temp2 df for each name\n",
        "for a in all_names_lst:\n",
        "  print(\"?????/////\")\n",
        "  print(a)\n",
        "  #temp2 counts the number of instances for each combination of sensitive attr and label (like my group count)\n",
        "  #names is the list of sensit attr\n",
        "  temp2, names = get_temp(new_train_data, all_names[a], label_y)\n",
        "  print(temp2, '\\n', names, 'temp2,names \\n')\n",
        "  #temp is a df with the entire columns, where the columns are in the first iteration all sens attr and the label\n",
        "  # in the second iteration are one sens attrib and the label\n",
        "  # temp_g counts the instances considering only the sens attrib (first iteration both sens attr, then only one at the time)\n",
        "  temp, temp_g = get_temp_g(new_train_data, names, label_y)\n",
        "  print(temp,'\\n', temp_g, 'temp,temp_g \\n')\n",
        "  temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "  #lst_of_counts is a list of df, the first df have first sens attr and the credit + count, the second is second sens attr\n",
        "  #and the credit + count\n",
        "  lst_of_counts = compute_lst_of_counts(temp, names, label_y)\n",
        "  print(lst_of_counts, 'listof counts \\n')\n",
        "\n",
        "  need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, label_y, lst_of_counts)\n",
        "  print(\"The sets of need pos and neg are\")\n",
        "  print(need_pos)\n",
        "  print(need_neg)\n",
        "  new_train_data['skewed'] = 0\n",
        "  new_train_data[\"diff\"] = 0\n",
        "  print(\"started duplication\")\n",
        "  new_train_data = naive_duplicate(new_train_data, temp2, names, need_pos, need_neg, label_y)\n",
        "  print(new_train_data.shape[0])\n",
        "  print(\"label y \", new_train_data[label_y].value_counts())\n",
        "#new_train_x = pd.DataFrame(new_train_data, columns = columns_all)\n",
        "new_train_label = pd.DataFrame(new_train_data, columns = [label_y])\n",
        "new_train_label = new_train_label[label_y]\n",
        "new_train_label = new_train_label.astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL-XHiK30NyD",
        "outputId": "0a6e352d-e9b9-4a56-9f2e-eab76b3b0f62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n"
          ]
        }
      ],
      "source": [
        "X_train_resampled_remedy = new_train_data.drop(columns= ['skewed', 'diff'])\n",
        "# Evaluate model performance\n",
        "results_remedy, pred_labels_remedy = evaluate_model_performance(X_train_resampled_remedy, X_test, sensitive_attributes,\n",
        "                                                                label, groups, model= model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpTpkLgs0rIK",
        "outputId": "23366f6b-275e-4fde-8f6b-63fd4b4000c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              Balanced Accuracy  Accuracy  F1 Score  \\\n",
            "Comparison                                                            \n",
            "Male Adult vs Female Adult             0.666667      0.76      0.84   \n",
            "Male Adult vs Male Young               0.666667      0.76      0.84   \n",
            "Male Adult vs Female Young             0.666667      0.76      0.84   \n",
            "Female Adult vs Male Young             0.666667      0.76      0.84   \n",
            "Female Adult vs Female Young           0.666667      0.76      0.84   \n",
            "Male Young vs Female Young             0.666667      0.76      0.84   \n",
            "\n",
            "                              Disparate Impact Ratio  Average Odds Difference  \\\n",
            "Comparison                                                                      \n",
            "Male Adult vs Female Adult                  0.983419                 0.012727   \n",
            "Male Adult vs Male Young                    1.128930                 0.151491   \n",
            "Male Adult vs Female Young                  1.059866                 0.122270   \n",
            "Female Adult vs Male Young                  1.147964                 0.138763   \n",
            "Female Adult vs Female Young                1.077736                 0.109543   \n",
            "Male Young vs Female Young                  0.938824                -0.029221   \n",
            "\n",
            "                              Equal Opportunity Difference  \\\n",
            "Comparison                                                   \n",
            "Male Adult vs Female Adult                        0.000000   \n",
            "Male Adult vs Male Young                          0.108696   \n",
            "Male Adult vs Female Young                        0.037267   \n",
            "Female Adult vs Male Young                        0.108696   \n",
            "Female Adult vs Female Young                      0.037267   \n",
            "Male Young vs Female Young                       -0.071429   \n",
            "\n",
            "                                       Consistency  \n",
            "Comparison                                          \n",
            "Male Adult vs Female Adult    [0.8673333333333334]  \n",
            "Male Adult vs Male Young      [0.8673333333333334]  \n",
            "Male Adult vs Female Young    [0.8673333333333334]  \n",
            "Female Adult vs Male Young    [0.8673333333333334]  \n",
            "Female Adult vs Female Young  [0.8673333333333334]  \n",
            "Male Young vs Female Young    [0.8673333333333334]  \n"
          ]
        }
      ],
      "source": [
        "# Initialize a list to hold DataFrames\n",
        "data_frames = []\n",
        "\n",
        "# Populate the list with DataFrames, each having a unique row index\n",
        "for key, values in results_remedy.items():\n",
        "    df_part = pd.DataFrame([values], index=[key])\n",
        "    data_frames.append(df_part)\n",
        "\n",
        "# Concatenate all DataFrames into a single DataFrame\n",
        "results_remedy_df = pd.concat(data_frames)\n",
        "results_remedy_df.index.name = 'Comparison'\n",
        "\n",
        "# Print the results DataFrame\n",
        "print(results_remedy_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYDvyuah0wV8"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "COMPARE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "u2NOGD4T01MT"
      },
      "outputs": [],
      "source": [
        "class ModelEvaluator:\n",
        "    def __init__(self, df, protected_attributes, label_name, privileged, unprivileged, fav, unfav, groups, num_iterations=10, oversampling_methods=None):\n",
        "        self.df = df\n",
        "        self.protected_attributes = protected_attributes\n",
        "        self.label_name = label_name\n",
        "        self.privileged = privileged\n",
        "        self.unprivileged = unprivileged\n",
        "        self.fav = fav\n",
        "        self.unfav = unfav\n",
        "        self.groups = groups\n",
        "        self.num_iterations = num_iterations\n",
        "        self.oversampling_methods = oversampling_methods if oversampling_methods is not None else ['none']\n",
        "\n",
        "    def evaluate_model_performance_mean(self):\n",
        "        results_dict = {method: [] for method in self.oversampling_methods}\n",
        "\n",
        "        for _ in range(self.num_iterations):\n",
        "            data_prep = DataPreparation(self.df, self.protected_attributes, self.label_name,\n",
        "                                        self.privileged, self.unprivileged, self.fav, self.unfav)\n",
        "            data_prep.prepare()\n",
        "            data_prep.df = data_prep.df.reset_index(drop=True)\n",
        "            X_train, X_test = data_prep.X_train, data_prep.X_test\n",
        "            X_train = X_train.reset_index(drop=True)\n",
        "            cat_features = data_prep.cat_features\n",
        "            numerical_features = data_prep.numerical_features\n",
        "            reverse_group_mapping = data_prep.create_group_column()\n",
        "            group_counts_train = X_train['Group'].value_counts().sort_index()\n",
        "            subgroup_column_train = X_train['Group']\n",
        "            subgroup_column_test = X_test['Group']\n",
        "            X_train = X_train.drop(columns=['Group'])\n",
        "            X_test = X_test.drop(columns=['Group'])\n",
        "\n",
        "            num_privileged_ones = X_train[(X_train[self.protected_attributes[0]] == 1) &\n",
        "                                          (X_train[self.protected_attributes[1]] == 1) &\n",
        "                                          (X_train[self.label_name] == 1)].shape[0]\n",
        "            num_privileged_zeros = X_train[(X_train[self.protected_attributes[0]] == 1) &\n",
        "                                          (X_train[self.protected_attributes[1]] == 1) &\n",
        "                                          (X_train[self.label_name] == 0)].shape[0]\n",
        "            total_ratio = num_privileged_ones / num_privileged_zeros if num_privileged_zeros != 0 else float('inf')\n",
        "\n",
        "            for method in self.oversampling_methods:\n",
        "                X_train_method = X_train.copy()\n",
        "                if method == 'none':\n",
        "                    results, pred_labels = evaluate_model_performance(X_train_method, X_test, self.protected_attributes, self.label_name,\n",
        "                                                                      self.groups, model=model)\n",
        "                elif method == 'custom_smote_km':\n",
        "                    X_train_no_sens = X_train_method.drop(columns=[self.protected_attributes[0], self.protected_attributes[1], self.label_name])\n",
        "                    X_reduced = X_train_no_sens\n",
        "\n",
        "                    kmeans = KMeans(n_clusters=5, init='k-means++', n_init=10, max_iter=300, random_state=42)\n",
        "                    clusters = kmeans.fit_predict(X_reduced)\n",
        "                    X_train_method['Cluster_Labels'] = clusters\n",
        "\n",
        "                    all_synthetic_samples_km = oversample_clusters(X_train_method, 'Cluster_Labels', self.protected_attributes,\n",
        "                                                                   self.label_name, total_ratio, cat_features)\n",
        "                    X_train_method = X_train_method.drop(columns=['Cluster_Labels'])\n",
        "                    X_train_resampled_km = pd.concat([X_train_method, all_synthetic_samples_km], ignore_index=True)\n",
        "                    results, pred_labels = evaluate_model_performance(X_train_resampled_km, X_test, self.protected_attributes,\n",
        "                                                                      self.label_name, self.groups, model=model)\n",
        "                elif method == 'custom_smote_dbscan':\n",
        "                    synthetic_samples_matrix_dbscan, synthetic_samples_group_dbscan = oversample_groups(X_train_method, cat_features, custom_smote_dbscan, subgroup_column_train, total_ratio, reverse_group_mapping)\n",
        "                    X_train_resampled_dbscan = pd.concat([X_train_method, pd.DataFrame(synthetic_samples_matrix_dbscan, columns=X_train.columns)], ignore_index=True)\n",
        "                    results, pred_labels = evaluate_model_performance(X_train_resampled_dbscan, X_test, self.protected_attributes,\n",
        "                                                                      self.label_name, self.groups, model=model)\n",
        "                elif method == 'custom_smote_tax':\n",
        "                    synthetic_samples_matrix_tax, synthetic_samples_group_tax = oversample_groups(X_train_method, cat_features, custom_smote_tax, subgroup_column_train, total_ratio, reverse_group_mapping)\n",
        "                    X_train_resampled_tax = pd.concat([X_train_method, pd.DataFrame(synthetic_samples_matrix_tax, columns=X_train.columns)], ignore_index=True)\n",
        "                    results, pred_labels = evaluate_model_performance(X_train_resampled_tax, X_test, self.protected_attributes,\n",
        "                                                                      self.label_name, self.groups, model=model)\n",
        "                elif method == 'Fair-SMOTE':\n",
        "                    X_train_resampled_fair_smote = oversample_fair_smote(X_train_method, self.protected_attributes, self.label_name)\n",
        "                    results, pred_labels = evaluate_model_performance(X_train_resampled_fair_smote, X_test, self.protected_attributes,\n",
        "                                                                      self.label_name, self.groups, model=model)\n",
        "                elif method == 'Reweighing':\n",
        "                    custom_data = CustomDataset(X_train_method, self.protected_attributes, self.label_name)\n",
        "                    privileged_groups = [{self.protected_attributes[0]: 1, self.protected_attributes[1]: 1}]\n",
        "                    unprivileged_groups = [{self.protected_attributes[0]: 0, self.protected_attributes[1]: 0}]\n",
        "                    RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
        "                                    privileged_groups=privileged_groups)\n",
        "                    RW.fit(custom_data)\n",
        "                    dataset_transf_train = RW.transform(custom_data)\n",
        "\n",
        "                    results, pred_labels = evaluate_model_performance(X_train_method, X_test, self.protected_attributes, self.label_name,\n",
        "                                                                      self.groups, model=model, weights=custom_data.instance_weights)\n",
        "                elif method == 'Remedy':\n",
        "                    columns_all = X_train_method.drop(columns=[self.label_name])\n",
        "                    label_y = self.label_name\n",
        "                    columns_protected = self.protected_attributes\n",
        "                    temp2, names = get_temp(X_train_method, columns_protected, label_y)\n",
        "                    unfair_group, unfair_names, skew_candidates, unfair_dict = get_unfair_group(columns_protected, [])\n",
        "                    print(unfair_group, unfair_names, skew_candidates, unfair_dict)\n",
        "                    all_names = candidate_groups(skew_candidates, unfair_dict, columns_protected, unfair_names)\n",
        "                    names_values = name_val_dict(X_train_method, names)\n",
        "\n",
        "                    all_names_lst = list(all_names.keys())[1:]\n",
        "                    all_names_lst.reverse()\n",
        "                    filter_count = 30\n",
        "                    new_train_data = copy.deepcopy(X_train_method)\n",
        "\n",
        "                    for a in all_names_lst:\n",
        "                        temp2, names = get_temp(new_train_data, all_names[a], label_y)\n",
        "                        temp, temp_g = get_temp_g(new_train_data, names, label_y)\n",
        "                        temp_g = temp_g[temp_g['cnt'] > filter_count]\n",
        "                        lst_of_counts = compute_lst_of_counts(temp, names, label_y)\n",
        "                        need_pos, need_neg = compute_problematic_opt(temp2, temp_g, names, label_y, lst_of_counts)\n",
        "                        new_train_data['skewed'] = 0\n",
        "                        new_train_data[\"diff\"] = 0\n",
        "                        new_train_data = naive_duplicate(new_train_data, temp2, names, need_pos, need_neg, label_y)\n",
        "                    new_train_label = pd.DataFrame(new_train_data, columns=[label_y])\n",
        "                    new_train_label = new_train_label[label_y]\n",
        "                    new_train_label = new_train_label.astype('int')\n",
        "\n",
        "                    X_train_resampled_remedy = new_train_data.drop(columns=['skewed', 'diff'])\n",
        "\n",
        "                    results, pred_labels = evaluate_model_performance(X_train_resampled_remedy, X_test, self.protected_attributes,\n",
        "                                                                      self.label_name, self.groups, model=model)\n",
        "\n",
        "                data_frames = []\n",
        "                for key, values in results.items():\n",
        "                    df_part = pd.DataFrame([values], index=[key])\n",
        "                    data_frames.append(df_part)\n",
        "\n",
        "                results_df = pd.concat(data_frames)\n",
        "                results_df.index.name = 'Comparison'\n",
        "                results_dict[method].append(results_df)\n",
        "\n",
        "        combined_results = {method: pd.concat(results_dict[method]).groupby(level=0).mean() for method in self.oversampling_methods}\n",
        "        return combined_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBQURESW6xuo",
        "outputId": "dd935aec-cc6e-4f38-ea1a-a3b974ee3859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No missing values detected.\n",
            "The 'credit' column has only two unique values.\n",
            "{'status': {'A11': 0, 'A12': 1, 'A13': 2, 'A14': 3}, 'credit_history': {'A30': 0, 'A31': 1, 'A32': 2, 'A33': 3, 'A34': 4}, 'purpose': {'A40': 0, 'A41': 1, 'A410': 2, 'A42': 3, 'A43': 4, 'A44': 5, 'A45': 6, 'A46': 7, 'A48': 8, 'A49': 9}, 'savings': {'A61': 0, 'A62': 1, 'A63': 2, 'A64': 3, 'A65': 4}, 'employment': {'A71': 0, 'A72': 1, 'A73': 2, 'A74': 3, 'A75': 4}, 'personal_status': {0: 0, 1: 1}, 'other_debtors': {'A101': 0, 'A102': 1, 'A103': 2}, 'property': {'A121': 0, 'A122': 1, 'A123': 2, 'A124': 3}, 'age': {0: 0, 1: 1}, 'installment_plans': {'A141': 0, 'A142': 1, 'A143': 2}, 'housing': {'A151': 0, 'A152': 1, 'A153': 2}, 'skill_level': {'A171': 0, 'A172': 1, 'A173': 2, 'A174': 3}, 'people_liable_for': {1: 0, 2: 1}, 'telephone': {'A191': 0, 'A192': 1}, 'foreign_worker': {'A201': 0, 'A202': 1}, 'credit': {0: 0, 1: 1}} encoder dict\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 2 [-1  0] mids\n",
            "0.01 0.14625000000000002 min, max\n",
            "0.07812500000000001 1 [-1] mids\n",
            "0.07812500000000001 0.14625000000000002 min, max\n",
            "0.11218750000000002 1 [-1] mids\n",
            "0.11218750000000002 0.14625000000000002 min, max\n",
            "0.12921875000000002 1 [-1] mids\n",
            "0.12921875000000002 0.14625000000000002 min, max\n",
            "0.13773437500000002 2 [-1  0] mids\n",
            "0.12921875000000002 0.13773437500000002 min, max\n",
            "0.1334765625 2 [-1  0] mids\n",
            "0.12921875000000002 0.1334765625 min, max\n",
            "0.13134765625 1 [-1] mids\n",
            "0.13134765625 0.1334765625 min, max\n",
            "0.132412109375 2 [-1  0] mids\n",
            "0.13134765625 0.132412109375 min, max\n",
            "0.13187988281250002 1 [-1] mids\n",
            "0.13187988281250002 0.132412109375 min, max\n",
            "Oversampling for group pair (2, 3): Added 22 synthetic samples in 2.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 3 [-1  0  1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.18031250000000004 min, max\n",
            "0.16328125000000004 3 [-1  0  1] mids\n",
            "0.16328125000000004 0.18031250000000004 min, max\n",
            "0.17179687500000004 2 [-1  0] mids\n",
            "0.16328125000000004 0.17179687500000004 min, max\n",
            "0.16753906250000006 2 [-1  0] mids\n",
            "0.16328125000000004 0.16753906250000006 min, max\n",
            "0.16541015625000005 3 [-1  0  1] mids\n",
            "0.16541015625000005 0.16753906250000006 min, max\n",
            "0.16647460937500005 2 [-1  0] mids\n",
            "0.16541015625000005 0.16647460937500005 min, max\n",
            "0.16594238281250007 2 [-1  0] mids\n",
            "0.16541015625000005 0.16594238281250007 min, max\n",
            "Oversampling for group pair (4, 5): Added 35 synthetic samples in 4.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 1 [-1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 3 [-1  0  1] mids\n",
            "0.18031250000000004 0.21437500000000004 min, max\n",
            "0.19734375000000004 2 [-1  0] mids\n",
            "0.18031250000000004 0.19734375000000004 min, max\n",
            "0.18882812500000004 3 [-1  0  1] mids\n",
            "0.18882812500000004 0.19734375000000004 min, max\n",
            "0.19308593750000003 2 [-1  0] mids\n",
            "0.18882812500000004 0.19308593750000003 min, max\n",
            "0.19095703125000002 3 [-1  0  1] mids\n",
            "0.19095703125000002 0.19308593750000003 min, max\n",
            "0.19202148437500002 3 [-1  0  1] mids\n",
            "0.19202148437500002 0.19308593750000003 min, max\n",
            "0.1925537109375 2 [-1  0] mids\n",
            "0.19202148437500002 0.1925537109375 min, max\n",
            "Oversampling for group pair (6, 7): Added 36 synthetic samples in 6.\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "Maximum count: 321\n",
            "one_one_one is maximum\n",
            "Counts to be increased for each group:\n",
            "zero_zero_zero: 296\n",
            "zero_zero_one: 270\n",
            "zero_one_zero: 303\n",
            "zero_one_one: 205\n",
            "one_zero_zero: 287\n",
            "one_zero_one: 214\n",
            "one_one_zero: 293\n",
            "one_one_one: 0\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "['personal_status', 'age', 'credit']\n",
            "[] [] ['personal_status', 'age'] {}\n",
            "['personal_status', 'age', 'credit']\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "Adding 15 positive records\n",
            "names  ['personal_status', 'age'] [0, 0]\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "Adding 21 positive records\n",
            "names  ['personal_status', 'age'] [0, 1]\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "Adding 17 positive records\n",
            "names  ['personal_status', 'age'] [1, 0]\n",
            "1.9565217391304348 321 116 48.0666666666667\n",
            "Adding 48 negative records\n",
            "names  ['personal_status', 'age'] [1, 1]\n",
            "['age', 'credit']\n",
            "['personal_status', 'credit']\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "No missing values detected.\n",
            "The 'credit' column has only two unique values.\n",
            "{'status': {'A11': 0, 'A12': 1, 'A13': 2, 'A14': 3}, 'credit_history': {'A30': 0, 'A31': 1, 'A32': 2, 'A33': 3, 'A34': 4}, 'purpose': {'A40': 0, 'A41': 1, 'A410': 2, 'A42': 3, 'A43': 4, 'A44': 5, 'A45': 6, 'A46': 7, 'A48': 8, 'A49': 9}, 'savings': {'A61': 0, 'A62': 1, 'A63': 2, 'A64': 3, 'A65': 4}, 'employment': {'A71': 0, 'A72': 1, 'A73': 2, 'A74': 3, 'A75': 4}, 'personal_status': {0: 0, 1: 1}, 'other_debtors': {'A101': 0, 'A102': 1, 'A103': 2}, 'property': {'A121': 0, 'A122': 1, 'A123': 2, 'A124': 3}, 'age': {0: 0, 1: 1}, 'installment_plans': {'A141': 0, 'A142': 1, 'A143': 2}, 'housing': {'A151': 0, 'A152': 1, 'A153': 2}, 'skill_level': {'A171': 0, 'A172': 1, 'A173': 2, 'A174': 3}, 'people_liable_for': {1: 0, 2: 1}, 'telephone': {'A191': 0, 'A192': 1}, 'foreign_worker': {'A201': 0, 'A202': 1}, 'credit': {0: 0, 1: 1}} encoder dict\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 2 [-1  0] mids\n",
            "0.01 0.14625000000000002 min, max\n",
            "0.07812500000000001 1 [-1] mids\n",
            "0.07812500000000001 0.14625000000000002 min, max\n",
            "0.11218750000000002 1 [-1] mids\n",
            "0.11218750000000002 0.14625000000000002 min, max\n",
            "0.12921875000000002 1 [-1] mids\n",
            "0.12921875000000002 0.14625000000000002 min, max\n",
            "0.13773437500000002 2 [-1  0] mids\n",
            "0.12921875000000002 0.13773437500000002 min, max\n",
            "0.1334765625 2 [-1  0] mids\n",
            "0.12921875000000002 0.1334765625 min, max\n",
            "0.13134765625 1 [-1] mids\n",
            "0.13134765625 0.1334765625 min, max\n",
            "0.132412109375 2 [-1  0] mids\n",
            "0.13134765625 0.132412109375 min, max\n",
            "0.13187988281250002 1 [-1] mids\n",
            "0.13187988281250002 0.132412109375 min, max\n",
            "Oversampling for group pair (2, 3): Added 22 synthetic samples in 2.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 3 [-1  0  1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.18031250000000004 min, max\n",
            "0.16328125000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.16328125000000004 min, max\n",
            "0.15476562500000002 3 [-1  0  1] mids\n",
            "0.15476562500000002 0.16328125000000004 min, max\n",
            "0.15902343750000003 3 [-1  0  1] mids\n",
            "0.15902343750000003 0.16328125000000004 min, max\n",
            "0.16115234375000004 2 [-1  0] mids\n",
            "0.15902343750000003 0.16115234375000004 min, max\n",
            "0.16008789062500003 3 [-1  0  1] mids\n",
            "0.16008789062500003 0.16115234375000004 min, max\n",
            "0.16062011718750002 3 [-1  0  1] mids\n",
            "0.16062011718750002 0.16115234375000004 min, max\n",
            "Oversampling for group pair (4, 5): Added 35 synthetic samples in 4.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 1 [-1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.18031250000000004 min, max\n",
            "0.16328125000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.16328125000000004 min, max\n",
            "0.15476562500000002 1 [-1] mids\n",
            "0.15476562500000002 0.16328125000000004 min, max\n",
            "0.15902343750000003 2 [-1  0] mids\n",
            "0.15476562500000002 0.15902343750000003 min, max\n",
            "0.15689453125000002 2 [-1  0] mids\n",
            "0.15476562500000002 0.15689453125000002 min, max\n",
            "0.15583007812500002 1 [-1] mids\n",
            "0.15583007812500002 0.15689453125000002 min, max\n",
            "0.1563623046875 2 [-1  0] mids\n",
            "0.15583007812500002 0.1563623046875 min, max\n",
            "Oversampling for group pair (6, 7): Added 36 synthetic samples in 6.\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "Maximum count: 321\n",
            "one_one_one is maximum\n",
            "Counts to be increased for each group:\n",
            "zero_zero_zero: 296\n",
            "zero_zero_one: 270\n",
            "zero_one_zero: 303\n",
            "zero_one_one: 205\n",
            "one_zero_zero: 287\n",
            "one_zero_one: 214\n",
            "one_one_zero: 293\n",
            "one_one_one: 0\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "['personal_status', 'age', 'credit']\n",
            "[] [] ['personal_status', 'age'] {}\n",
            "['personal_status', 'age', 'credit']\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "Adding 15 positive records\n",
            "names  ['personal_status', 'age'] [0, 0]\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "Adding 21 positive records\n",
            "names  ['personal_status', 'age'] [0, 1]\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "Adding 17 positive records\n",
            "names  ['personal_status', 'age'] [1, 0]\n",
            "1.9565217391304348 321 116 48.0666666666667\n",
            "Adding 48 negative records\n",
            "names  ['personal_status', 'age'] [1, 1]\n",
            "['age', 'credit']\n",
            "['personal_status', 'credit']\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "No missing values detected.\n",
            "The 'credit' column has only two unique values.\n",
            "{'status': {'A11': 0, 'A12': 1, 'A13': 2, 'A14': 3}, 'credit_history': {'A30': 0, 'A31': 1, 'A32': 2, 'A33': 3, 'A34': 4}, 'purpose': {'A40': 0, 'A41': 1, 'A410': 2, 'A42': 3, 'A43': 4, 'A44': 5, 'A45': 6, 'A46': 7, 'A48': 8, 'A49': 9}, 'savings': {'A61': 0, 'A62': 1, 'A63': 2, 'A64': 3, 'A65': 4}, 'employment': {'A71': 0, 'A72': 1, 'A73': 2, 'A74': 3, 'A75': 4}, 'personal_status': {0: 0, 1: 1}, 'other_debtors': {'A101': 0, 'A102': 1, 'A103': 2}, 'property': {'A121': 0, 'A122': 1, 'A123': 2, 'A124': 3}, 'age': {0: 0, 1: 1}, 'installment_plans': {'A141': 0, 'A142': 1, 'A143': 2}, 'housing': {'A151': 0, 'A152': 1, 'A153': 2}, 'skill_level': {'A171': 0, 'A172': 1, 'A173': 2, 'A174': 3}, 'people_liable_for': {1: 0, 2: 1}, 'telephone': {'A191': 0, 'A192': 1}, 'foreign_worker': {'A201': 0, 'A202': 1}, 'credit': {0: 0, 1: 1}} encoder dict\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 2 [-1  0] mids\n",
            "0.01 0.14625000000000002 min, max\n",
            "0.07812500000000001 1 [-1] mids\n",
            "0.07812500000000001 0.14625000000000002 min, max\n",
            "0.11218750000000002 1 [-1] mids\n",
            "0.11218750000000002 0.14625000000000002 min, max\n",
            "0.12921875000000002 1 [-1] mids\n",
            "0.12921875000000002 0.14625000000000002 min, max\n",
            "0.13773437500000002 2 [-1  0] mids\n",
            "0.12921875000000002 0.13773437500000002 min, max\n",
            "0.1334765625 2 [-1  0] mids\n",
            "0.12921875000000002 0.1334765625 min, max\n",
            "0.13134765625 1 [-1] mids\n",
            "0.13134765625 0.1334765625 min, max\n",
            "0.132412109375 2 [-1  0] mids\n",
            "0.13134765625 0.132412109375 min, max\n",
            "0.13187988281250002 1 [-1] mids\n",
            "0.13187988281250002 0.132412109375 min, max\n",
            "Oversampling for group pair (2, 3): Added 22 synthetic samples in 2.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 3 [-1  0  1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.18031250000000004 min, max\n",
            "0.16328125000000004 3 [-1  0  1] mids\n",
            "0.16328125000000004 0.18031250000000004 min, max\n",
            "0.17179687500000004 2 [-1  0] mids\n",
            "0.16328125000000004 0.17179687500000004 min, max\n",
            "0.16753906250000006 2 [-1  0] mids\n",
            "0.16328125000000004 0.16753906250000006 min, max\n",
            "0.16541015625000005 2 [-1  0] mids\n",
            "0.16328125000000004 0.16541015625000005 min, max\n",
            "0.16434570312500005 2 [-1  0] mids\n",
            "0.16328125000000004 0.16434570312500005 min, max\n",
            "0.16381347656250006 2 [-1  0] mids\n",
            "0.16328125000000004 0.16381347656250006 min, max\n",
            "Oversampling for group pair (4, 5): Added 35 synthetic samples in 4.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 1 [-1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 3 [-1  0  1] mids\n",
            "0.21437500000000004 0.28250000000000003 min, max\n",
            "0.24843750000000003 2 [-1  0] mids\n",
            "0.21437500000000004 0.24843750000000003 min, max\n",
            "0.23140625000000004 2 [-1  0] mids\n",
            "0.21437500000000004 0.23140625000000004 min, max\n",
            "0.22289062500000004 3 [-1  0  1] mids\n",
            "0.22289062500000004 0.23140625000000004 min, max\n",
            "0.22714843750000002 3 [-1  0  1] mids\n",
            "0.22714843750000002 0.23140625000000004 min, max\n",
            "0.22927734375000003 3 [-1  0  1] mids\n",
            "0.22927734375000003 0.23140625000000004 min, max\n",
            "0.23034179687500003 2 [-1  0] mids\n",
            "0.22927734375000003 0.23034179687500003 min, max\n",
            "0.22980957031250004 3 [-1  0  1] mids\n",
            "0.22980957031250004 0.23034179687500003 min, max\n",
            "Oversampling for group pair (6, 7): Added 36 synthetic samples in 6.\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "Maximum count: 321\n",
            "one_one_one is maximum\n",
            "Counts to be increased for each group:\n",
            "zero_zero_zero: 296\n",
            "zero_zero_one: 270\n",
            "zero_one_zero: 303\n",
            "zero_one_one: 205\n",
            "one_zero_zero: 287\n",
            "one_zero_one: 214\n",
            "one_one_zero: 293\n",
            "one_one_one: 0\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "['personal_status', 'age', 'credit']\n",
            "[] [] ['personal_status', 'age'] {}\n",
            "['personal_status', 'age', 'credit']\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "Adding 15 positive records\n",
            "names  ['personal_status', 'age'] [0, 0]\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "Adding 21 positive records\n",
            "names  ['personal_status', 'age'] [0, 1]\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "Adding 17 positive records\n",
            "names  ['personal_status', 'age'] [1, 0]\n",
            "1.9565217391304348 321 116 48.0666666666667\n",
            "Adding 48 negative records\n",
            "names  ['personal_status', 'age'] [1, 1]\n",
            "['age', 'credit']\n",
            "['personal_status', 'credit']\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "No missing values detected.\n",
            "The 'credit' column has only two unique values.\n",
            "{'status': {'A11': 0, 'A12': 1, 'A13': 2, 'A14': 3}, 'credit_history': {'A30': 0, 'A31': 1, 'A32': 2, 'A33': 3, 'A34': 4}, 'purpose': {'A40': 0, 'A41': 1, 'A410': 2, 'A42': 3, 'A43': 4, 'A44': 5, 'A45': 6, 'A46': 7, 'A48': 8, 'A49': 9}, 'savings': {'A61': 0, 'A62': 1, 'A63': 2, 'A64': 3, 'A65': 4}, 'employment': {'A71': 0, 'A72': 1, 'A73': 2, 'A74': 3, 'A75': 4}, 'personal_status': {0: 0, 1: 1}, 'other_debtors': {'A101': 0, 'A102': 1, 'A103': 2}, 'property': {'A121': 0, 'A122': 1, 'A123': 2, 'A124': 3}, 'age': {0: 0, 1: 1}, 'installment_plans': {'A141': 0, 'A142': 1, 'A143': 2}, 'housing': {'A151': 0, 'A152': 1, 'A153': 2}, 'skill_level': {'A171': 0, 'A172': 1, 'A173': 2, 'A174': 3}, 'people_liable_for': {1: 0, 2: 1}, 'telephone': {'A191': 0, 'A192': 1}, 'foreign_worker': {'A201': 0, 'A202': 1}, 'credit': {0: 0, 1: 1}} encoder dict\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 1 [-1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.18031250000000004 min, max\n",
            "0.16328125000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.16328125000000004 min, max\n",
            "0.15476562500000002 2 [-1  0] mids\n",
            "0.14625000000000002 0.15476562500000002 min, max\n",
            "0.1505078125 2 [-1  0] mids\n",
            "0.14625000000000002 0.1505078125 min, max\n",
            "0.14837890625 2 [-1  0] mids\n",
            "0.14625000000000002 0.14837890625 min, max\n",
            "0.14731445312500002 1 [-1] mids\n",
            "0.14731445312500002 0.14837890625 min, max\n",
            "0.1478466796875 1 [-1] mids\n",
            "0.1478466796875 0.14837890625 min, max\n",
            "Oversampling for group pair (2, 3): Added 22 synthetic samples in 2.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 3 [-1  0  1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.18031250000000004 min, max\n",
            "0.16328125000000004 4 [-1  0  1  2] mids\n",
            "0.16328125000000004 0.18031250000000004 min, max\n",
            "0.17179687500000004 2 [-1  0] mids\n",
            "0.16328125000000004 0.17179687500000004 min, max\n",
            "0.16753906250000006 2 [-1  0] mids\n",
            "0.16328125000000004 0.16753906250000006 min, max\n",
            "0.16541015625000005 3 [-1  0  1] mids\n",
            "0.16541015625000005 0.16753906250000006 min, max\n",
            "0.16647460937500005 2 [-1  0] mids\n",
            "0.16541015625000005 0.16647460937500005 min, max\n",
            "0.16594238281250007 3 [-1  0  1] mids\n",
            "0.16594238281250007 0.16647460937500005 min, max\n",
            "Oversampling for group pair (4, 5): Added 35 synthetic samples in 4.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 1 [-1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 3 [-1  0  1] mids\n",
            "0.18031250000000004 0.21437500000000004 min, max\n",
            "0.19734375000000004 2 [-1  0] mids\n",
            "0.18031250000000004 0.19734375000000004 min, max\n",
            "0.18882812500000004 3 [-1  0  1] mids\n",
            "0.18882812500000004 0.19734375000000004 min, max\n",
            "0.19308593750000003 3 [-1  0  1] mids\n",
            "0.19308593750000003 0.19734375000000004 min, max\n",
            "0.19521484375000003 2 [-1  0] mids\n",
            "0.19308593750000003 0.19521484375000003 min, max\n",
            "0.19415039062500003 2 [-1  0] mids\n",
            "0.19308593750000003 0.19415039062500003 min, max\n",
            "0.19361816406250004 2 [-1  0] mids\n",
            "0.19308593750000003 0.19361816406250004 min, max\n",
            "Oversampling for group pair (6, 7): Added 36 synthetic samples in 6.\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "Maximum count: 321\n",
            "one_one_one is maximum\n",
            "Counts to be increased for each group:\n",
            "zero_zero_zero: 296\n",
            "zero_zero_one: 270\n",
            "zero_one_zero: 303\n",
            "zero_one_one: 205\n",
            "one_zero_zero: 287\n",
            "one_zero_one: 214\n",
            "one_one_zero: 293\n",
            "one_one_one: 0\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "['personal_status', 'age', 'credit']\n",
            "[] [] ['personal_status', 'age'] {}\n",
            "['personal_status', 'age', 'credit']\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "Adding 15 positive records\n",
            "names  ['personal_status', 'age'] [0, 0]\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "Adding 21 positive records\n",
            "names  ['personal_status', 'age'] [0, 1]\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "Adding 17 positive records\n",
            "names  ['personal_status', 'age'] [1, 0]\n",
            "1.9565217391304348 321 116 48.0666666666667\n",
            "Adding 48 negative records\n",
            "names  ['personal_status', 'age'] [1, 1]\n",
            "['age', 'credit']\n",
            "['personal_status', 'credit']\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "No missing values detected.\n",
            "The 'credit' column has only two unique values.\n",
            "{'status': {'A11': 0, 'A12': 1, 'A13': 2, 'A14': 3}, 'credit_history': {'A30': 0, 'A31': 1, 'A32': 2, 'A33': 3, 'A34': 4}, 'purpose': {'A40': 0, 'A41': 1, 'A410': 2, 'A42': 3, 'A43': 4, 'A44': 5, 'A45': 6, 'A46': 7, 'A48': 8, 'A49': 9}, 'savings': {'A61': 0, 'A62': 1, 'A63': 2, 'A64': 3, 'A65': 4}, 'employment': {'A71': 0, 'A72': 1, 'A73': 2, 'A74': 3, 'A75': 4}, 'personal_status': {0: 0, 1: 1}, 'other_debtors': {'A101': 0, 'A102': 1, 'A103': 2}, 'property': {'A121': 0, 'A122': 1, 'A123': 2, 'A124': 3}, 'age': {0: 0, 1: 1}, 'installment_plans': {'A141': 0, 'A142': 1, 'A143': 2}, 'housing': {'A151': 0, 'A152': 1, 'A153': 2}, 'skill_level': {'A171': 0, 'A172': 1, 'A173': 2, 'A174': 3}, 'people_liable_for': {1: 0, 2: 1}, 'telephone': {'A191': 0, 'A192': 1}, 'foreign_worker': {'A201': 0, 'A202': 1}, 'credit': {0: 0, 1: 1}} encoder dict\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 1 [0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 1 [-1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 3 [-1  0  1] mids\n",
            "0.21437500000000004 0.28250000000000003 min, max\n",
            "0.24843750000000003 2 [-1  0] mids\n",
            "0.21437500000000004 0.24843750000000003 min, max\n",
            "0.23140625000000004 2 [-1  0] mids\n",
            "0.21437500000000004 0.23140625000000004 min, max\n",
            "0.22289062500000004 2 [-1  0] mids\n",
            "0.21437500000000004 0.22289062500000004 min, max\n",
            "0.21863281250000005 3 [-1  0  1] mids\n",
            "0.21863281250000005 0.22289062500000004 min, max\n",
            "0.22076171875000006 3 [-1  0  1] mids\n",
            "0.22076171875000006 0.22289062500000004 min, max\n",
            "0.22182617187500003 2 [-1  0] mids\n",
            "0.22076171875000006 0.22182617187500003 min, max\n",
            "0.22129394531250005 3 [-1  0  1] mids\n",
            "0.22129394531250005 0.22182617187500003 min, max\n",
            "Oversampling for group pair (2, 3): Added 22 synthetic samples in 2.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 3 [-1  0  1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.18031250000000004 min, max\n",
            "0.16328125000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.16328125000000004 min, max\n",
            "0.15476562500000002 3 [-1  0  1] mids\n",
            "0.15476562500000002 0.16328125000000004 min, max\n",
            "0.15902343750000003 2 [-1  0] mids\n",
            "0.15476562500000002 0.15902343750000003 min, max\n",
            "0.15689453125000002 2 [-1  0] mids\n",
            "0.15476562500000002 0.15689453125000002 min, max\n",
            "0.15583007812500002 2 [-1  0] mids\n",
            "0.15476562500000002 0.15583007812500002 min, max\n",
            "0.15529785156250003 2 [-1  0] mids\n",
            "0.15476562500000002 0.15529785156250003 min, max\n",
            "Oversampling for group pair (4, 5): Added 35 synthetic samples in 4.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 1 [-1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 3 [-1  0  1] mids\n",
            "0.21437500000000004 0.28250000000000003 min, max\n",
            "0.24843750000000003 2 [-1  0] mids\n",
            "0.21437500000000004 0.24843750000000003 min, max\n",
            "0.23140625000000004 2 [-1  0] mids\n",
            "0.21437500000000004 0.23140625000000004 min, max\n",
            "0.22289062500000004 2 [-1  0] mids\n",
            "0.21437500000000004 0.22289062500000004 min, max\n",
            "0.21863281250000005 3 [-1  0  1] mids\n",
            "0.21863281250000005 0.22289062500000004 min, max\n",
            "0.22076171875000006 2 [-1  0] mids\n",
            "0.21863281250000005 0.22076171875000006 min, max\n",
            "0.21969726562500005 3 [-1  0  1] mids\n",
            "0.21969726562500005 0.22076171875000006 min, max\n",
            "0.22022949218750004 2 [-1  0] mids\n",
            "0.21969726562500005 0.22022949218750004 min, max\n",
            "Oversampling for group pair (6, 7): Added 36 synthetic samples in 6.\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "Maximum count: 321\n",
            "one_one_one is maximum\n",
            "Counts to be increased for each group:\n",
            "zero_zero_zero: 296\n",
            "zero_zero_one: 270\n",
            "zero_one_zero: 303\n",
            "zero_one_one: 205\n",
            "one_zero_zero: 287\n",
            "one_zero_one: 214\n",
            "one_one_zero: 293\n",
            "one_one_one: 0\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "['personal_status', 'age', 'credit']\n",
            "[] [] ['personal_status', 'age'] {}\n",
            "['personal_status', 'age', 'credit']\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "Adding 15 positive records\n",
            "names  ['personal_status', 'age'] [0, 0]\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "Adding 21 positive records\n",
            "names  ['personal_status', 'age'] [0, 1]\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "Adding 17 positive records\n",
            "names  ['personal_status', 'age'] [1, 0]\n",
            "1.9565217391304348 321 116 48.0666666666667\n",
            "Adding 48 negative records\n",
            "names  ['personal_status', 'age'] [1, 1]\n",
            "['age', 'credit']\n",
            "['personal_status', 'credit']\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "No missing values detected.\n",
            "The 'credit' column has only two unique values.\n",
            "{'status': {'A11': 0, 'A12': 1, 'A13': 2, 'A14': 3}, 'credit_history': {'A30': 0, 'A31': 1, 'A32': 2, 'A33': 3, 'A34': 4}, 'purpose': {'A40': 0, 'A41': 1, 'A410': 2, 'A42': 3, 'A43': 4, 'A44': 5, 'A45': 6, 'A46': 7, 'A48': 8, 'A49': 9}, 'savings': {'A61': 0, 'A62': 1, 'A63': 2, 'A64': 3, 'A65': 4}, 'employment': {'A71': 0, 'A72': 1, 'A73': 2, 'A74': 3, 'A75': 4}, 'personal_status': {0: 0, 1: 1}, 'other_debtors': {'A101': 0, 'A102': 1, 'A103': 2}, 'property': {'A121': 0, 'A122': 1, 'A123': 2, 'A124': 3}, 'age': {0: 0, 1: 1}, 'installment_plans': {'A141': 0, 'A142': 1, 'A143': 2}, 'housing': {'A151': 0, 'A152': 1, 'A153': 2}, 'skill_level': {'A171': 0, 'A172': 1, 'A173': 2, 'A174': 3}, 'people_liable_for': {1: 0, 2: 1}, 'telephone': {'A191': 0, 'A192': 1}, 'foreign_worker': {'A201': 0, 'A202': 1}, 'credit': {0: 0, 1: 1}} encoder dict\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 1 [-1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 3 [-1  0  1] mids\n",
            "0.18031250000000004 0.21437500000000004 min, max\n",
            "0.19734375000000004 2 [-1  0] mids\n",
            "0.18031250000000004 0.19734375000000004 min, max\n",
            "0.18882812500000004 2 [-1  0] mids\n",
            "0.18031250000000004 0.18882812500000004 min, max\n",
            "0.18457031250000006 2 [-1  0] mids\n",
            "0.18031250000000004 0.18457031250000006 min, max\n",
            "0.18244140625000005 3 [-1  0  1] mids\n",
            "0.18244140625000005 0.18457031250000006 min, max\n",
            "0.18350585937500005 2 [-1  0] mids\n",
            "0.18244140625000005 0.18350585937500005 min, max\n",
            "0.18297363281250006 2 [-1  0] mids\n",
            "0.18244140625000005 0.18297363281250006 min, max\n",
            "Oversampling for group pair (2, 3): Added 22 synthetic samples in 2.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 4 [-1  0  1  2] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.18031250000000004 min, max\n",
            "0.16328125000000004 3 [-1  0  1] mids\n",
            "0.16328125000000004 0.18031250000000004 min, max\n",
            "0.17179687500000004 3 [-1  0  1] mids\n",
            "0.17179687500000004 0.18031250000000004 min, max\n",
            "0.17605468750000003 2 [-1  0] mids\n",
            "0.17179687500000004 0.17605468750000003 min, max\n",
            "0.17392578125000002 2 [-1  0] mids\n",
            "0.17179687500000004 0.17392578125000002 min, max\n",
            "0.17286132812500005 2 [-1  0] mids\n",
            "0.17179687500000004 0.17286132812500005 min, max\n",
            "0.17232910156250003 2 [-1  0] mids\n",
            "0.17179687500000004 0.17232910156250003 min, max\n",
            "Oversampling for group pair (4, 5): Added 35 synthetic samples in 4.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 1 [-1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 3 [-1  0  1] mids\n",
            "0.18031250000000004 0.21437500000000004 min, max\n",
            "0.19734375000000004 2 [-1  0] mids\n",
            "0.18031250000000004 0.19734375000000004 min, max\n",
            "0.18882812500000004 3 [-1  0  1] mids\n",
            "0.18882812500000004 0.19734375000000004 min, max\n",
            "0.19308593750000003 2 [-1  0] mids\n",
            "0.18882812500000004 0.19308593750000003 min, max\n",
            "0.19095703125000002 3 [-1  0  1] mids\n",
            "0.19095703125000002 0.19308593750000003 min, max\n",
            "0.19202148437500002 3 [-1  0  1] mids\n",
            "0.19202148437500002 0.19308593750000003 min, max\n",
            "0.1925537109375 2 [-1  0] mids\n",
            "0.19202148437500002 0.1925537109375 min, max\n",
            "Oversampling for group pair (6, 7): Added 36 synthetic samples in 6.\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "Maximum count: 321\n",
            "one_one_one is maximum\n",
            "Counts to be increased for each group:\n",
            "zero_zero_zero: 296\n",
            "zero_zero_one: 270\n",
            "zero_one_zero: 303\n",
            "zero_one_one: 205\n",
            "one_zero_zero: 287\n",
            "one_zero_one: 214\n",
            "one_one_zero: 293\n",
            "one_one_one: 0\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "['personal_status', 'age', 'credit']\n",
            "[] [] ['personal_status', 'age'] {}\n",
            "['personal_status', 'age', 'credit']\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "Adding 15 positive records\n",
            "names  ['personal_status', 'age'] [0, 0]\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "Adding 21 positive records\n",
            "names  ['personal_status', 'age'] [0, 1]\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "Adding 17 positive records\n",
            "names  ['personal_status', 'age'] [1, 0]\n",
            "1.9565217391304348 321 116 48.0666666666667\n",
            "Adding 48 negative records\n",
            "names  ['personal_status', 'age'] [1, 1]\n",
            "['age', 'credit']\n",
            "['personal_status', 'credit']\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "No missing values detected.\n",
            "The 'credit' column has only two unique values.\n",
            "{'status': {'A11': 0, 'A12': 1, 'A13': 2, 'A14': 3}, 'credit_history': {'A30': 0, 'A31': 1, 'A32': 2, 'A33': 3, 'A34': 4}, 'purpose': {'A40': 0, 'A41': 1, 'A410': 2, 'A42': 3, 'A43': 4, 'A44': 5, 'A45': 6, 'A46': 7, 'A48': 8, 'A49': 9}, 'savings': {'A61': 0, 'A62': 1, 'A63': 2, 'A64': 3, 'A65': 4}, 'employment': {'A71': 0, 'A72': 1, 'A73': 2, 'A74': 3, 'A75': 4}, 'personal_status': {0: 0, 1: 1}, 'other_debtors': {'A101': 0, 'A102': 1, 'A103': 2}, 'property': {'A121': 0, 'A122': 1, 'A123': 2, 'A124': 3}, 'age': {0: 0, 1: 1}, 'installment_plans': {'A141': 0, 'A142': 1, 'A143': 2}, 'housing': {'A151': 0, 'A152': 1, 'A153': 2}, 'skill_level': {'A171': 0, 'A172': 1, 'A173': 2, 'A174': 3}, 'people_liable_for': {1: 0, 2: 1}, 'telephone': {'A191': 0, 'A192': 1}, 'foreign_worker': {'A201': 0, 'A202': 1}, 'credit': {0: 0, 1: 1}} encoder dict\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 3 [-1  0  1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.18031250000000004 min, max\n",
            "0.16328125000000004 3 [-1  0  1] mids\n",
            "0.16328125000000004 0.18031250000000004 min, max\n",
            "0.17179687500000004 3 [-1  0  1] mids\n",
            "0.17179687500000004 0.18031250000000004 min, max\n",
            "0.17605468750000003 3 [-1  0  1] mids\n",
            "0.17605468750000003 0.18031250000000004 min, max\n",
            "0.17818359375000004 2 [-1  0] mids\n",
            "0.17605468750000003 0.17818359375000004 min, max\n",
            "0.17711914062500003 2 [-1  0] mids\n",
            "0.17605468750000003 0.17711914062500003 min, max\n",
            "0.17658691406250004 2 [-1  0] mids\n",
            "0.17605468750000003 0.17658691406250004 min, max\n",
            "Oversampling for group pair (2, 3): Added 22 synthetic samples in 2.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 3 [-1  0  1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 3 [-1  0  1] mids\n",
            "0.18031250000000004 0.21437500000000004 min, max\n",
            "0.19734375000000004 2 [-1  0] mids\n",
            "0.18031250000000004 0.19734375000000004 min, max\n",
            "0.18882812500000004 3 [-1  0  1] mids\n",
            "0.18882812500000004 0.19734375000000004 min, max\n",
            "0.19308593750000003 3 [-1  0  1] mids\n",
            "0.19308593750000003 0.19734375000000004 min, max\n",
            "0.19521484375000003 3 [-1  0  1] mids\n",
            "0.19521484375000003 0.19734375000000004 min, max\n",
            "0.19627929687500004 2 [-1  0] mids\n",
            "0.19521484375000003 0.19627929687500004 min, max\n",
            "0.19574707031250005 2 [-1  0] mids\n",
            "0.19521484375000003 0.19574707031250005 min, max\n",
            "Oversampling for group pair (4, 5): Added 35 synthetic samples in 4.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 1 [-1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 3 [-1  0  1] mids\n",
            "0.21437500000000004 0.28250000000000003 min, max\n",
            "0.24843750000000003 2 [-1  0] mids\n",
            "0.21437500000000004 0.24843750000000003 min, max\n",
            "0.23140625000000004 2 [-1  0] mids\n",
            "0.21437500000000004 0.23140625000000004 min, max\n",
            "0.22289062500000004 2 [-1  0] mids\n",
            "0.21437500000000004 0.22289062500000004 min, max\n",
            "0.21863281250000005 2 [-1  0] mids\n",
            "0.21437500000000004 0.21863281250000005 min, max\n",
            "0.21650390625000004 2 [-1  0] mids\n",
            "0.21437500000000004 0.21650390625000004 min, max\n",
            "0.21543945312500004 2 [-1  0] mids\n",
            "0.21437500000000004 0.21543945312500004 min, max\n",
            "0.21490722656250005 2 [-1  0] mids\n",
            "0.21437500000000004 0.21490722656250005 min, max\n",
            "Oversampling for group pair (6, 7): Added 36 synthetic samples in 6.\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "Maximum count: 321\n",
            "one_one_one is maximum\n",
            "Counts to be increased for each group:\n",
            "zero_zero_zero: 296\n",
            "zero_zero_one: 270\n",
            "zero_one_zero: 303\n",
            "zero_one_one: 205\n",
            "one_zero_zero: 287\n",
            "one_zero_one: 214\n",
            "one_one_zero: 293\n",
            "one_one_one: 0\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "['personal_status', 'age', 'credit']\n",
            "[] [] ['personal_status', 'age'] {}\n",
            "['personal_status', 'age', 'credit']\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "Adding 15 positive records\n",
            "names  ['personal_status', 'age'] [0, 0]\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "Adding 21 positive records\n",
            "names  ['personal_status', 'age'] [0, 1]\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "Adding 17 positive records\n",
            "names  ['personal_status', 'age'] [1, 0]\n",
            "1.9565217391304348 321 116 48.0666666666667\n",
            "Adding 48 negative records\n",
            "names  ['personal_status', 'age'] [1, 1]\n",
            "['age', 'credit']\n",
            "['personal_status', 'credit']\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "No missing values detected.\n",
            "The 'credit' column has only two unique values.\n",
            "{'status': {'A11': 0, 'A12': 1, 'A13': 2, 'A14': 3}, 'credit_history': {'A30': 0, 'A31': 1, 'A32': 2, 'A33': 3, 'A34': 4}, 'purpose': {'A40': 0, 'A41': 1, 'A410': 2, 'A42': 3, 'A43': 4, 'A44': 5, 'A45': 6, 'A46': 7, 'A48': 8, 'A49': 9}, 'savings': {'A61': 0, 'A62': 1, 'A63': 2, 'A64': 3, 'A65': 4}, 'employment': {'A71': 0, 'A72': 1, 'A73': 2, 'A74': 3, 'A75': 4}, 'personal_status': {0: 0, 1: 1}, 'other_debtors': {'A101': 0, 'A102': 1, 'A103': 2}, 'property': {'A121': 0, 'A122': 1, 'A123': 2, 'A124': 3}, 'age': {0: 0, 1: 1}, 'installment_plans': {'A141': 0, 'A142': 1, 'A143': 2}, 'housing': {'A151': 0, 'A152': 1, 'A153': 2}, 'skill_level': {'A171': 0, 'A172': 1, 'A173': 2, 'A174': 3}, 'people_liable_for': {1: 0, 2: 1}, 'telephone': {'A191': 0, 'A192': 1}, 'foreign_worker': {'A201': 0, 'A202': 1}, 'credit': {0: 0, 1: 1}} encoder dict\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 2 [-1  0] mids\n",
            "0.01 0.14625000000000002 min, max\n",
            "0.07812500000000001 1 [-1] mids\n",
            "0.07812500000000001 0.14625000000000002 min, max\n",
            "0.11218750000000002 1 [-1] mids\n",
            "0.11218750000000002 0.14625000000000002 min, max\n",
            "0.12921875000000002 1 [-1] mids\n",
            "0.12921875000000002 0.14625000000000002 min, max\n",
            "0.13773437500000002 2 [-1  0] mids\n",
            "0.12921875000000002 0.13773437500000002 min, max\n",
            "0.1334765625 2 [-1  0] mids\n",
            "0.12921875000000002 0.1334765625 min, max\n",
            "0.13134765625 1 [-1] mids\n",
            "0.13134765625 0.1334765625 min, max\n",
            "0.132412109375 2 [-1  0] mids\n",
            "0.13134765625 0.132412109375 min, max\n",
            "0.13187988281250002 1 [-1] mids\n",
            "0.13187988281250002 0.132412109375 min, max\n",
            "Oversampling for group pair (2, 3): Added 22 synthetic samples in 2.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 2 [-1  0] mids\n",
            "0.01 0.14625000000000002 min, max\n",
            "0.07812500000000001 1 [-1] mids\n",
            "0.07812500000000001 0.14625000000000002 min, max\n",
            "0.11218750000000002 1 [-1] mids\n",
            "0.11218750000000002 0.14625000000000002 min, max\n",
            "0.12921875000000002 2 [-1  0] mids\n",
            "0.11218750000000002 0.12921875000000002 min, max\n",
            "0.12070312500000002 1 [-1] mids\n",
            "0.12070312500000002 0.12921875000000002 min, max\n",
            "0.12496093750000002 3 [-1  0  1] mids\n",
            "0.12496093750000002 0.12921875000000002 min, max\n",
            "0.12708984375000001 3 [-1  0  1] mids\n",
            "0.12708984375000001 0.12921875000000002 min, max\n",
            "0.12815429687500002 2 [-1  0] mids\n",
            "0.12708984375000001 0.12815429687500002 min, max\n",
            "0.1276220703125 2 [-1  0] mids\n",
            "0.12708984375000001 0.1276220703125 min, max\n",
            "Oversampling for group pair (4, 5): Added 35 synthetic samples in 4.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 1 [-1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 3 [-1  0  1] mids\n",
            "0.18031250000000004 0.21437500000000004 min, max\n",
            "0.19734375000000004 2 [-1  0] mids\n",
            "0.18031250000000004 0.19734375000000004 min, max\n",
            "0.18882812500000004 3 [-1  0  1] mids\n",
            "0.18882812500000004 0.19734375000000004 min, max\n",
            "0.19308593750000003 2 [-1  0] mids\n",
            "0.18882812500000004 0.19308593750000003 min, max\n",
            "0.19095703125000002 3 [-1  0  1] mids\n",
            "0.19095703125000002 0.19308593750000003 min, max\n",
            "0.19202148437500002 3 [-1  0  1] mids\n",
            "0.19202148437500002 0.19308593750000003 min, max\n",
            "0.1925537109375 3 [-1  0  1] mids\n",
            "0.1925537109375 0.19308593750000003 min, max\n",
            "Oversampling for group pair (6, 7): Added 36 synthetic samples in 6.\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "Maximum count: 321\n",
            "one_one_one is maximum\n",
            "Counts to be increased for each group:\n",
            "zero_zero_zero: 296\n",
            "zero_zero_one: 270\n",
            "zero_one_zero: 303\n",
            "zero_one_one: 205\n",
            "one_zero_zero: 287\n",
            "one_zero_one: 214\n",
            "one_one_zero: 293\n",
            "one_one_one: 0\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "['personal_status', 'age', 'credit']\n",
            "[] [] ['personal_status', 'age'] {}\n",
            "['personal_status', 'age', 'credit']\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "Adding 15 positive records\n",
            "names  ['personal_status', 'age'] [0, 0]\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "Adding 21 positive records\n",
            "names  ['personal_status', 'age'] [0, 1]\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "Adding 17 positive records\n",
            "names  ['personal_status', 'age'] [1, 0]\n",
            "1.9565217391304348 321 116 48.0666666666667\n",
            "Adding 48 negative records\n",
            "names  ['personal_status', 'age'] [1, 1]\n",
            "['age', 'credit']\n",
            "['personal_status', 'credit']\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "No missing values detected.\n",
            "The 'credit' column has only two unique values.\n",
            "{'status': {'A11': 0, 'A12': 1, 'A13': 2, 'A14': 3}, 'credit_history': {'A30': 0, 'A31': 1, 'A32': 2, 'A33': 3, 'A34': 4}, 'purpose': {'A40': 0, 'A41': 1, 'A410': 2, 'A42': 3, 'A43': 4, 'A44': 5, 'A45': 6, 'A46': 7, 'A48': 8, 'A49': 9}, 'savings': {'A61': 0, 'A62': 1, 'A63': 2, 'A64': 3, 'A65': 4}, 'employment': {'A71': 0, 'A72': 1, 'A73': 2, 'A74': 3, 'A75': 4}, 'personal_status': {0: 0, 1: 1}, 'other_debtors': {'A101': 0, 'A102': 1, 'A103': 2}, 'property': {'A121': 0, 'A122': 1, 'A123': 2, 'A124': 3}, 'age': {0: 0, 1: 1}, 'installment_plans': {'A141': 0, 'A142': 1, 'A143': 2}, 'housing': {'A151': 0, 'A152': 1, 'A153': 2}, 'skill_level': {'A171': 0, 'A172': 1, 'A173': 2, 'A174': 3}, 'people_liable_for': {1: 0, 2: 1}, 'telephone': {'A191': 0, 'A192': 1}, 'foreign_worker': {'A201': 0, 'A202': 1}, 'credit': {0: 0, 1: 1}} encoder dict\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 1 [-1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 3 [-1  0  1] mids\n",
            "0.18031250000000004 0.21437500000000004 min, max\n",
            "0.19734375000000004 3 [-1  0  1] mids\n",
            "0.19734375000000004 0.21437500000000004 min, max\n",
            "0.20585937500000004 2 [-1  0] mids\n",
            "0.19734375000000004 0.20585937500000004 min, max\n",
            "0.20160156250000005 2 [-1  0] mids\n",
            "0.19734375000000004 0.20160156250000005 min, max\n",
            "0.19947265625000005 3 [-1  0  1] mids\n",
            "0.19947265625000005 0.20160156250000005 min, max\n",
            "0.20053710937500005 3 [-1  0  1] mids\n",
            "0.20053710937500005 0.20160156250000005 min, max\n",
            "0.20106933593750004 3 [-1  0  1] mids\n",
            "0.20106933593750004 0.20160156250000005 min, max\n",
            "Oversampling for group pair (2, 3): Added 22 synthetic samples in 2.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 2 [-1  0] mids\n",
            "0.01 0.14625000000000002 min, max\n",
            "0.07812500000000001 1 [-1] mids\n",
            "0.07812500000000001 0.14625000000000002 min, max\n",
            "0.11218750000000002 2 [-1  0] mids\n",
            "0.07812500000000001 0.11218750000000002 min, max\n",
            "0.09515625000000003 1 [-1] mids\n",
            "0.09515625000000003 0.11218750000000002 min, max\n",
            "0.10367187500000002 1 [-1] mids\n",
            "0.10367187500000002 0.11218750000000002 min, max\n",
            "0.10792968750000002 1 [-1] mids\n",
            "0.10792968750000002 0.11218750000000002 min, max\n",
            "0.11005859375000002 2 [-1  0] mids\n",
            "0.10792968750000002 0.11005859375000002 min, max\n",
            "0.10899414062500001 2 [-1  0] mids\n",
            "0.10792968750000002 0.10899414062500001 min, max\n",
            "0.10846191406250003 2 [-1  0] mids\n",
            "0.10792968750000002 0.10846191406250003 min, max\n",
            "Oversampling for group pair (4, 5): Added 35 synthetic samples in 4.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 1 [-1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 3 [-1  0  1] mids\n",
            "0.18031250000000004 0.21437500000000004 min, max\n",
            "0.19734375000000004 2 [-1  0] mids\n",
            "0.18031250000000004 0.19734375000000004 min, max\n",
            "0.18882812500000004 3 [-1  0  1] mids\n",
            "0.18882812500000004 0.19734375000000004 min, max\n",
            "0.19308593750000003 2 [-1  0] mids\n",
            "0.18882812500000004 0.19308593750000003 min, max\n",
            "0.19095703125000002 3 [-1  0  1] mids\n",
            "0.19095703125000002 0.19308593750000003 min, max\n",
            "0.19202148437500002 3 [-1  0  1] mids\n",
            "0.19202148437500002 0.19308593750000003 min, max\n",
            "0.1925537109375 3 [-1  0  1] mids\n",
            "0.1925537109375 0.19308593750000003 min, max\n",
            "Oversampling for group pair (6, 7): Added 36 synthetic samples in 6.\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "Maximum count: 321\n",
            "one_one_one is maximum\n",
            "Counts to be increased for each group:\n",
            "zero_zero_zero: 296\n",
            "zero_zero_one: 270\n",
            "zero_one_zero: 303\n",
            "zero_one_one: 205\n",
            "one_zero_zero: 287\n",
            "one_zero_one: 214\n",
            "one_one_zero: 293\n",
            "one_one_one: 0\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "['personal_status', 'age', 'credit']\n",
            "[] [] ['personal_status', 'age'] {}\n",
            "['personal_status', 'age', 'credit']\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "Adding 15 positive records\n",
            "names  ['personal_status', 'age'] [0, 0]\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "Adding 21 positive records\n",
            "names  ['personal_status', 'age'] [0, 1]\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "Adding 17 positive records\n",
            "names  ['personal_status', 'age'] [1, 0]\n",
            "1.9565217391304348 321 116 48.0666666666667\n",
            "Adding 48 negative records\n",
            "names  ['personal_status', 'age'] [1, 1]\n",
            "['age', 'credit']\n",
            "['personal_status', 'credit']\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "No missing values detected.\n",
            "The 'credit' column has only two unique values.\n",
            "{'status': {'A11': 0, 'A12': 1, 'A13': 2, 'A14': 3}, 'credit_history': {'A30': 0, 'A31': 1, 'A32': 2, 'A33': 3, 'A34': 4}, 'purpose': {'A40': 0, 'A41': 1, 'A410': 2, 'A42': 3, 'A43': 4, 'A44': 5, 'A45': 6, 'A46': 7, 'A48': 8, 'A49': 9}, 'savings': {'A61': 0, 'A62': 1, 'A63': 2, 'A64': 3, 'A65': 4}, 'employment': {'A71': 0, 'A72': 1, 'A73': 2, 'A74': 3, 'A75': 4}, 'personal_status': {0: 0, 1: 1}, 'other_debtors': {'A101': 0, 'A102': 1, 'A103': 2}, 'property': {'A121': 0, 'A122': 1, 'A123': 2, 'A124': 3}, 'age': {0: 0, 1: 1}, 'installment_plans': {'A141': 0, 'A142': 1, 'A143': 2}, 'housing': {'A151': 0, 'A152': 1, 'A153': 2}, 'skill_level': {'A171': 0, 'A172': 1, 'A173': 2, 'A174': 3}, 'people_liable_for': {1: 0, 2: 1}, 'telephone': {'A191': 0, 'A192': 1}, 'foreign_worker': {'A201': 0, 'A202': 1}, 'credit': {0: 0, 1: 1}} encoder dict\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "[(0, (1, 1, 1)), (1, (1, 1, 0)), (2, (1, 0, 1)), (3, (1, 0, 0)), (4, (0, 1, 1)), (5, (0, 1, 0)), (6, (0, 0, 1)), (7, (0, 0, 0))]\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 2 [-1  0] mids\n",
            "0.01 0.14625000000000002 min, max\n",
            "0.07812500000000001 1 [-1] mids\n",
            "0.07812500000000001 0.14625000000000002 min, max\n",
            "0.11218750000000002 1 [-1] mids\n",
            "0.11218750000000002 0.14625000000000002 min, max\n",
            "0.12921875000000002 1 [-1] mids\n",
            "0.12921875000000002 0.14625000000000002 min, max\n",
            "0.13773437500000002 1 [-1] mids\n",
            "0.13773437500000002 0.14625000000000002 min, max\n",
            "0.14199218750000003 2 [-1  0] mids\n",
            "0.13773437500000002 0.14199218750000003 min, max\n",
            "0.13986328125000003 2 [-1  0] mids\n",
            "0.13773437500000002 0.13986328125000003 min, max\n",
            "0.13879882812500002 2 [-1  0] mids\n",
            "0.13773437500000002 0.13879882812500002 min, max\n",
            "0.13826660156250004 1 [-1] mids\n",
            "0.13826660156250004 0.13879882812500002 min, max\n",
            "Oversampling for group pair (2, 3): Added 22 synthetic samples in 2.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 3 [-1  0  1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 3 [-1  0  1] mids\n",
            "0.18031250000000004 0.21437500000000004 min, max\n",
            "0.19734375000000004 2 [-1  0] mids\n",
            "0.18031250000000004 0.19734375000000004 min, max\n",
            "0.18882812500000004 3 [-1  0  1] mids\n",
            "0.18882812500000004 0.19734375000000004 min, max\n",
            "0.19308593750000003 2 [-1  0] mids\n",
            "0.18882812500000004 0.19308593750000003 min, max\n",
            "0.19095703125000002 2 [-1  0] mids\n",
            "0.18882812500000004 0.19095703125000002 min, max\n",
            "0.18989257812500004 3 [-1  0  1] mids\n",
            "0.18989257812500004 0.19095703125000002 min, max\n",
            "0.19042480468750003 2 [-1  0] mids\n",
            "0.18989257812500004 0.19042480468750003 min, max\n",
            "Oversampling for group pair (4, 5): Added 35 synthetic samples in 4.\n",
            "0.555 1 [0] mids\n",
            "0.01 0.555 min, max\n",
            "0.28250000000000003 2 [-1  0] mids\n",
            "0.01 0.28250000000000003 min, max\n",
            "0.14625000000000002 1 [-1] mids\n",
            "0.14625000000000002 0.28250000000000003 min, max\n",
            "0.21437500000000004 2 [-1  0] mids\n",
            "0.14625000000000002 0.21437500000000004 min, max\n",
            "0.18031250000000004 3 [-1  0  1] mids\n",
            "0.18031250000000004 0.21437500000000004 min, max\n",
            "0.19734375000000004 3 [-1  0  1] mids\n",
            "0.19734375000000004 0.21437500000000004 min, max\n",
            "0.20585937500000004 3 [-1  0  1] mids\n",
            "0.20585937500000004 0.21437500000000004 min, max\n",
            "0.21011718750000002 3 [-1  0  1] mids\n",
            "0.21011718750000002 0.21437500000000004 min, max\n",
            "0.21224609375000003 3 [-1  0  1] mids\n",
            "0.21224609375000003 0.21437500000000004 min, max\n",
            "0.21331054687500003 2 [-1  0] mids\n",
            "0.21224609375000003 0.21331054687500003 min, max\n",
            "0.21277832031250005 2 [-1  0] mids\n",
            "0.21224609375000003 0.21277832031250005 min, max\n",
            "Oversampling for group pair (6, 7): Added 36 synthetic samples in 6.\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "Maximum count: 321\n",
            "one_one_one is maximum\n",
            "Counts to be increased for each group:\n",
            "zero_zero_zero: 296\n",
            "zero_zero_one: 270\n",
            "zero_one_zero: 303\n",
            "zero_one_one: 205\n",
            "one_zero_zero: 287\n",
            "one_zero_one: 214\n",
            "one_one_zero: 293\n",
            "one_one_one: 0\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "['personal_status', 'age', 'credit']\n",
            "[] [] ['personal_status', 'age'] {}\n",
            "['personal_status', 'age', 'credit']\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "1.9565217391304348 34 25 14.9130434782609\n",
            "Adding 15 positive records\n",
            "names  ['personal_status', 'age'] [0, 0]\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "2.517730496453901 107 51 21.4042553191489\n",
            "Adding 21 positive records\n",
            "names  ['personal_status', 'age'] [0, 1]\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "2.517730496453901 28 18 17.3191489361702\n",
            "Adding 17 positive records\n",
            "names  ['personal_status', 'age'] [1, 0]\n",
            "1.9565217391304348 321 116 48.0666666666667\n",
            "Adding 48 negative records\n",
            "names  ['personal_status', 'age'] [1, 1]\n",
            "['age', 'credit']\n",
            "['personal_status', 'credit']\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Male Adult', 'attributes': {'personal_status': 1, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} gruppi\n",
            "{'name': 'Female Adult', 'attributes': {'personal_status': 0, 'age': 1}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "{'name': 'Male Young', 'attributes': {'personal_status': 1, 'age': 0}} {'name': 'Female Young', 'attributes': {'personal_status': 0, 'age': 0}} gruppi\n",
            "Results for none method:\n",
            "                              Balanced Accuracy  Accuracy  F1 Score  \\\n",
            "Comparison                                                            \n",
            "Female Adult vs Female Young           0.677222  0.762333  0.839821   \n",
            "Female Adult vs Male Young             0.677222  0.762333  0.839821   \n",
            "Male Adult vs Female Adult             0.677222  0.762333  0.839821   \n",
            "Male Adult vs Female Young             0.677222  0.762333  0.839821   \n",
            "Male Adult vs Male Young               0.677222  0.762333  0.839821   \n",
            "Male Young vs Female Young             0.677222  0.762333  0.839821   \n",
            "\n",
            "                              Disparate Impact Ratio  Average Odds Difference  \\\n",
            "Comparison                                                                      \n",
            "Female Adult vs Female Young                0.884570                -0.043803   \n",
            "Female Adult vs Male Young                  1.013323                 0.053113   \n",
            "Male Adult vs Female Adult                  0.840649                -0.134207   \n",
            "Male Adult vs Female Young                  0.736460                -0.178010   \n",
            "Male Adult vs Male Young                    0.845813                -0.081094   \n",
            "Male Young vs Female Young                  0.883595                -0.096916   \n",
            "\n",
            "                              Equal Opportunity Difference  \\\n",
            "Comparison                                                   \n",
            "Female Adult vs Female Young                     -0.001242   \n",
            "Female Adult vs Male Young                       -0.061957   \n",
            "Male Adult vs Female Adult                       -0.086232   \n",
            "Male Adult vs Female Young                       -0.087474   \n",
            "Male Adult vs Male Young                         -0.148188   \n",
            "Male Young vs Female Young                        0.060714   \n",
            "\n",
            "                                       Consistency  \n",
            "Comparison                                          \n",
            "Female Adult vs Female Young  [0.8610666666666666]  \n",
            "Female Adult vs Male Young    [0.8610666666666666]  \n",
            "Male Adult vs Female Adult    [0.8610666666666666]  \n",
            "Male Adult vs Female Young    [0.8610666666666666]  \n",
            "Male Adult vs Male Young      [0.8610666666666666]  \n",
            "Male Young vs Female Young    [0.8610666666666666]  \n",
            "Results for custom_smote_dbscan method:\n",
            "                              Balanced Accuracy  Accuracy  F1 Score  \\\n",
            "Comparison                                                            \n",
            "Female Adult vs Female Young           0.640873     0.751  0.837452   \n",
            "Female Adult vs Male Young             0.640873     0.751  0.837452   \n",
            "Male Adult vs Female Adult             0.640873     0.751  0.837452   \n",
            "Male Adult vs Female Young             0.640873     0.751  0.837452   \n",
            "Male Adult vs Male Young               0.640873     0.751  0.837452   \n",
            "Male Young vs Female Young             0.640873     0.751  0.837452   \n",
            "\n",
            "                              Disparate Impact Ratio  Average Odds Difference  \\\n",
            "Comparison                                                                      \n",
            "Female Adult vs Female Young                1.139158                 0.146683   \n",
            "Female Adult vs Male Young                  1.155932                 0.145979   \n",
            "Male Adult vs Female Adult                  0.919092                -0.064299   \n",
            "Male Adult vs Female Young                  1.035013                 0.082384   \n",
            "Male Adult vs Male Young                    1.050394                 0.081680   \n",
            "Male Young vs Female Young                  0.993145                 0.000703   \n",
            "\n",
            "                              Equal Opportunity Difference  \\\n",
            "Comparison                                                   \n",
            "Female Adult vs Female Young                      0.088820   \n",
            "Female Adult vs Male Young                        0.075725   \n",
            "Male Adult vs Female Adult                       -0.035507   \n",
            "Male Adult vs Female Young                        0.053313   \n",
            "Male Adult vs Male Young                          0.040217   \n",
            "Male Young vs Female Young                        0.013095   \n",
            "\n",
            "                                       Consistency  \n",
            "Comparison                                          \n",
            "Female Adult vs Female Young  [0.8836666666666668]  \n",
            "Female Adult vs Male Young    [0.8836666666666668]  \n",
            "Male Adult vs Female Adult    [0.8836666666666668]  \n",
            "Male Adult vs Female Young    [0.8836666666666668]  \n",
            "Male Adult vs Male Young      [0.8836666666666668]  \n",
            "Male Young vs Female Young    [0.8836666666666668]  \n",
            "Results for Fair-SMOTE method:\n",
            "                              Balanced Accuracy  Accuracy  F1 Score  \\\n",
            "Comparison                                                            \n",
            "Female Adult vs Female Young           0.658254  0.716667  0.798758   \n",
            "Female Adult vs Male Young             0.658254  0.716667  0.798758   \n",
            "Male Adult vs Female Adult             0.658254  0.716667  0.798758   \n",
            "Male Adult vs Female Young             0.658254  0.716667  0.798758   \n",
            "Male Adult vs Male Young               0.658254  0.716667  0.798758   \n",
            "Male Young vs Female Young             0.658254  0.716667  0.798758   \n",
            "\n",
            "                              Disparate Impact Ratio  Average Odds Difference  \\\n",
            "Comparison                                                                      \n",
            "Female Adult vs Female Young                1.121736                 0.141516   \n",
            "Female Adult vs Male Young                  1.067089                 0.086321   \n",
            "Male Adult vs Female Adult                  0.990504                 0.006863   \n",
            "Male Adult vs Female Young                  1.109462                 0.148379   \n",
            "Male Adult vs Male Young                    1.049861                 0.093184   \n",
            "Male Young vs Female Young                  1.091557                 0.055195   \n",
            "\n",
            "                              Equal Opportunity Difference  \\\n",
            "Comparison                                                   \n",
            "Female Adult vs Female Young                      0.037578   \n",
            "Female Adult vs Male Young                       -0.019565   \n",
            "Male Adult vs Female Adult                        0.025362   \n",
            "Male Adult vs Female Young                        0.062940   \n",
            "Male Adult vs Male Young                          0.005797   \n",
            "Male Young vs Female Young                        0.057143   \n",
            "\n",
            "                                       Consistency  \n",
            "Comparison                                          \n",
            "Female Adult vs Female Young  [0.8308666666666665]  \n",
            "Female Adult vs Male Young    [0.8308666666666665]  \n",
            "Male Adult vs Female Adult    [0.8308666666666665]  \n",
            "Male Adult vs Female Young    [0.8308666666666665]  \n",
            "Male Adult vs Male Young      [0.8308666666666665]  \n",
            "Male Young vs Female Young    [0.8308666666666665]  \n",
            "Results for Reweighing method:\n",
            "                              Balanced Accuracy  Accuracy  F1 Score  \\\n",
            "Comparison                                                            \n",
            "Female Adult vs Female Young           0.672381     0.756  0.834933   \n",
            "Female Adult vs Male Young             0.672381     0.756  0.834933   \n",
            "Male Adult vs Female Adult             0.672381     0.756  0.834933   \n",
            "Male Adult vs Female Young             0.672381     0.756  0.834933   \n",
            "Male Adult vs Male Young               0.672381     0.756  0.834933   \n",
            "Male Young vs Female Young             0.672381     0.756  0.834933   \n",
            "\n",
            "                              Disparate Impact Ratio  Average Odds Difference  \\\n",
            "Comparison                                                                      \n",
            "Female Adult vs Female Young                1.071759                 0.094382   \n",
            "Female Adult vs Male Young                  1.090399                 0.106828   \n",
            "Male Adult vs Female Adult                  0.893129                -0.076910   \n",
            "Male Adult vs Female Young                  0.946162                 0.017471   \n",
            "Male Adult vs Male Young                    0.964016                 0.029917   \n",
            "Male Young vs Female Young                  0.990333                -0.012446   \n",
            "\n",
            "                              Equal Opportunity Difference  \\\n",
            "Comparison                                                   \n",
            "Female Adult vs Female Young                      0.061491   \n",
            "Female Adult vs Male Young                       -0.012319   \n",
            "Male Adult vs Female Adult                       -0.049275   \n",
            "Male Adult vs Female Young                        0.012215   \n",
            "Male Adult vs Male Young                         -0.061594   \n",
            "Male Young vs Female Young                        0.073810   \n",
            "\n",
            "                                       Consistency  \n",
            "Comparison                                          \n",
            "Female Adult vs Female Young  [0.8644666666666667]  \n",
            "Female Adult vs Male Young    [0.8644666666666667]  \n",
            "Male Adult vs Female Adult    [0.8644666666666667]  \n",
            "Male Adult vs Female Young    [0.8644666666666667]  \n",
            "Male Adult vs Male Young      [0.8644666666666667]  \n",
            "Male Young vs Female Young    [0.8644666666666667]  \n",
            "Results for Remedy method:\n",
            "                              Balanced Accuracy  Accuracy  F1 Score  \\\n",
            "Comparison                                                            \n",
            "Female Adult vs Female Young            0.67381  0.755333  0.833951   \n",
            "Female Adult vs Male Young              0.67381  0.755333  0.833951   \n",
            "Male Adult vs Female Adult              0.67381  0.755333  0.833951   \n",
            "Male Adult vs Female Young              0.67381  0.755333  0.833951   \n",
            "Male Adult vs Male Young                0.67381  0.755333  0.833951   \n",
            "Male Young vs Female Young              0.67381  0.755333  0.833951   \n",
            "\n",
            "                              Disparate Impact Ratio  Average Odds Difference  \\\n",
            "Comparison                                                                      \n",
            "Female Adult vs Female Young                1.122083                 0.134077   \n",
            "Female Adult vs Male Young                  1.098363                 0.117897   \n",
            "Male Adult vs Female Adult                  0.934428                -0.034501   \n",
            "Male Adult vs Female Young                  1.038361                 0.099576   \n",
            "Male Adult vs Male Young                    1.016848                 0.083396   \n",
            "Male Young vs Female Young                  1.039393                 0.016180   \n",
            "\n",
            "                              Equal Opportunity Difference  \\\n",
            "Comparison                                                   \n",
            "Female Adult vs Female Young                      0.086335   \n",
            "Female Adult vs Male Young                       -0.014855   \n",
            "Male Adult vs Female Adult                       -0.024638   \n",
            "Male Adult vs Female Young                        0.061698   \n",
            "Male Adult vs Male Young                         -0.039493   \n",
            "Male Young vs Female Young                        0.101190   \n",
            "\n",
            "                                       Consistency  \n",
            "Comparison                                          \n",
            "Female Adult vs Female Young  [0.8608666666666668]  \n",
            "Female Adult vs Male Young    [0.8608666666666668]  \n",
            "Male Adult vs Female Adult    [0.8608666666666668]  \n",
            "Male Adult vs Female Young    [0.8608666666666668]  \n",
            "Male Adult vs Male Young      [0.8608666666666668]  \n",
            "Male Young vs Female Young    [0.8608666666666668]  \n"
          ]
        }
      ],
      "source": [
        "evaluators = {\n",
        "    'ModelEvaluator': ModelEvaluator(df, sensitive_attributes, label, privileged, unprivileged, favorable_label, unfavorable_label, groups, num_iterations=10, oversampling_methods=['none', 'custom_smote_dbscan', 'Fair-SMOTE', 'Reweighing', 'Remedy'])\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "# Evaluate all models and store results\n",
        "for key, evaluator in evaluators.items():\n",
        "    results[key] = evaluator.evaluate_model_performance_mean()\n",
        "\n",
        "# Display the results\n",
        "for method, result in results['ModelEvaluator'].items():\n",
        "    print(f\"Results for {method} method:\")\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3ipIwyD9WYy",
        "outputId": "9d02d1c6-33ae-4efb-9dae-fad6721df4c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for ModelEvaluator:\n",
            "{'none':                               Balanced Accuracy  Accuracy  F1 Score  \\\n",
            "Comparison                                                            \n",
            "Female Adult vs Female Young           0.677222  0.762333  0.839821   \n",
            "Female Adult vs Male Young             0.677222  0.762333  0.839821   \n",
            "Male Adult vs Female Adult             0.677222  0.762333  0.839821   \n",
            "Male Adult vs Female Young             0.677222  0.762333  0.839821   \n",
            "Male Adult vs Male Young               0.677222  0.762333  0.839821   \n",
            "Male Young vs Female Young             0.677222  0.762333  0.839821   \n",
            "\n",
            "                              Disparate Impact Ratio  Average Odds Difference  \\\n",
            "Comparison                                                                      \n",
            "Female Adult vs Female Young                0.884570                -0.043803   \n",
            "Female Adult vs Male Young                  1.013323                 0.053113   \n",
            "Male Adult vs Female Adult                  0.840649                -0.134207   \n",
            "Male Adult vs Female Young                  0.736460                -0.178010   \n",
            "Male Adult vs Male Young                    0.845813                -0.081094   \n",
            "Male Young vs Female Young                  0.883595                -0.096916   \n",
            "\n",
            "                              Equal Opportunity Difference  \\\n",
            "Comparison                                                   \n",
            "Female Adult vs Female Young                     -0.001242   \n",
            "Female Adult vs Male Young                       -0.061957   \n",
            "Male Adult vs Female Adult                       -0.086232   \n",
            "Male Adult vs Female Young                       -0.087474   \n",
            "Male Adult vs Male Young                         -0.148188   \n",
            "Male Young vs Female Young                        0.060714   \n",
            "\n",
            "                                       Consistency  \n",
            "Comparison                                          \n",
            "Female Adult vs Female Young  [0.8610666666666666]  \n",
            "Female Adult vs Male Young    [0.8610666666666666]  \n",
            "Male Adult vs Female Adult    [0.8610666666666666]  \n",
            "Male Adult vs Female Young    [0.8610666666666666]  \n",
            "Male Adult vs Male Young      [0.8610666666666666]  \n",
            "Male Young vs Female Young    [0.8610666666666666]  , 'custom_smote_dbscan':                               Balanced Accuracy  Accuracy  F1 Score  \\\n",
            "Comparison                                                            \n",
            "Female Adult vs Female Young           0.640873     0.751  0.837452   \n",
            "Female Adult vs Male Young             0.640873     0.751  0.837452   \n",
            "Male Adult vs Female Adult             0.640873     0.751  0.837452   \n",
            "Male Adult vs Female Young             0.640873     0.751  0.837452   \n",
            "Male Adult vs Male Young               0.640873     0.751  0.837452   \n",
            "Male Young vs Female Young             0.640873     0.751  0.837452   \n",
            "\n",
            "                              Disparate Impact Ratio  Average Odds Difference  \\\n",
            "Comparison                                                                      \n",
            "Female Adult vs Female Young                1.139158                 0.146683   \n",
            "Female Adult vs Male Young                  1.155932                 0.145979   \n",
            "Male Adult vs Female Adult                  0.919092                -0.064299   \n",
            "Male Adult vs Female Young                  1.035013                 0.082384   \n",
            "Male Adult vs Male Young                    1.050394                 0.081680   \n",
            "Male Young vs Female Young                  0.993145                 0.000703   \n",
            "\n",
            "                              Equal Opportunity Difference  \\\n",
            "Comparison                                                   \n",
            "Female Adult vs Female Young                      0.088820   \n",
            "Female Adult vs Male Young                        0.075725   \n",
            "Male Adult vs Female Adult                       -0.035507   \n",
            "Male Adult vs Female Young                        0.053313   \n",
            "Male Adult vs Male Young                          0.040217   \n",
            "Male Young vs Female Young                        0.013095   \n",
            "\n",
            "                                       Consistency  \n",
            "Comparison                                          \n",
            "Female Adult vs Female Young  [0.8836666666666668]  \n",
            "Female Adult vs Male Young    [0.8836666666666668]  \n",
            "Male Adult vs Female Adult    [0.8836666666666668]  \n",
            "Male Adult vs Female Young    [0.8836666666666668]  \n",
            "Male Adult vs Male Young      [0.8836666666666668]  \n",
            "Male Young vs Female Young    [0.8836666666666668]  , 'Fair-SMOTE':                               Balanced Accuracy  Accuracy  F1 Score  \\\n",
            "Comparison                                                            \n",
            "Female Adult vs Female Young           0.658254  0.716667  0.798758   \n",
            "Female Adult vs Male Young             0.658254  0.716667  0.798758   \n",
            "Male Adult vs Female Adult             0.658254  0.716667  0.798758   \n",
            "Male Adult vs Female Young             0.658254  0.716667  0.798758   \n",
            "Male Adult vs Male Young               0.658254  0.716667  0.798758   \n",
            "Male Young vs Female Young             0.658254  0.716667  0.798758   \n",
            "\n",
            "                              Disparate Impact Ratio  Average Odds Difference  \\\n",
            "Comparison                                                                      \n",
            "Female Adult vs Female Young                1.121736                 0.141516   \n",
            "Female Adult vs Male Young                  1.067089                 0.086321   \n",
            "Male Adult vs Female Adult                  0.990504                 0.006863   \n",
            "Male Adult vs Female Young                  1.109462                 0.148379   \n",
            "Male Adult vs Male Young                    1.049861                 0.093184   \n",
            "Male Young vs Female Young                  1.091557                 0.055195   \n",
            "\n",
            "                              Equal Opportunity Difference  \\\n",
            "Comparison                                                   \n",
            "Female Adult vs Female Young                      0.037578   \n",
            "Female Adult vs Male Young                       -0.019565   \n",
            "Male Adult vs Female Adult                        0.025362   \n",
            "Male Adult vs Female Young                        0.062940   \n",
            "Male Adult vs Male Young                          0.005797   \n",
            "Male Young vs Female Young                        0.057143   \n",
            "\n",
            "                                       Consistency  \n",
            "Comparison                                          \n",
            "Female Adult vs Female Young  [0.8308666666666665]  \n",
            "Female Adult vs Male Young    [0.8308666666666665]  \n",
            "Male Adult vs Female Adult    [0.8308666666666665]  \n",
            "Male Adult vs Female Young    [0.8308666666666665]  \n",
            "Male Adult vs Male Young      [0.8308666666666665]  \n",
            "Male Young vs Female Young    [0.8308666666666665]  , 'Reweighing':                               Balanced Accuracy  Accuracy  F1 Score  \\\n",
            "Comparison                                                            \n",
            "Female Adult vs Female Young           0.672381     0.756  0.834933   \n",
            "Female Adult vs Male Young             0.672381     0.756  0.834933   \n",
            "Male Adult vs Female Adult             0.672381     0.756  0.834933   \n",
            "Male Adult vs Female Young             0.672381     0.756  0.834933   \n",
            "Male Adult vs Male Young               0.672381     0.756  0.834933   \n",
            "Male Young vs Female Young             0.672381     0.756  0.834933   \n",
            "\n",
            "                              Disparate Impact Ratio  Average Odds Difference  \\\n",
            "Comparison                                                                      \n",
            "Female Adult vs Female Young                1.071759                 0.094382   \n",
            "Female Adult vs Male Young                  1.090399                 0.106828   \n",
            "Male Adult vs Female Adult                  0.893129                -0.076910   \n",
            "Male Adult vs Female Young                  0.946162                 0.017471   \n",
            "Male Adult vs Male Young                    0.964016                 0.029917   \n",
            "Male Young vs Female Young                  0.990333                -0.012446   \n",
            "\n",
            "                              Equal Opportunity Difference  \\\n",
            "Comparison                                                   \n",
            "Female Adult vs Female Young                      0.061491   \n",
            "Female Adult vs Male Young                       -0.012319   \n",
            "Male Adult vs Female Adult                       -0.049275   \n",
            "Male Adult vs Female Young                        0.012215   \n",
            "Male Adult vs Male Young                         -0.061594   \n",
            "Male Young vs Female Young                        0.073810   \n",
            "\n",
            "                                       Consistency  \n",
            "Comparison                                          \n",
            "Female Adult vs Female Young  [0.8644666666666667]  \n",
            "Female Adult vs Male Young    [0.8644666666666667]  \n",
            "Male Adult vs Female Adult    [0.8644666666666667]  \n",
            "Male Adult vs Female Young    [0.8644666666666667]  \n",
            "Male Adult vs Male Young      [0.8644666666666667]  \n",
            "Male Young vs Female Young    [0.8644666666666667]  , 'Remedy':                               Balanced Accuracy  Accuracy  F1 Score  \\\n",
            "Comparison                                                            \n",
            "Female Adult vs Female Young            0.67381  0.755333  0.833951   \n",
            "Female Adult vs Male Young              0.67381  0.755333  0.833951   \n",
            "Male Adult vs Female Adult              0.67381  0.755333  0.833951   \n",
            "Male Adult vs Female Young              0.67381  0.755333  0.833951   \n",
            "Male Adult vs Male Young                0.67381  0.755333  0.833951   \n",
            "Male Young vs Female Young              0.67381  0.755333  0.833951   \n",
            "\n",
            "                              Disparate Impact Ratio  Average Odds Difference  \\\n",
            "Comparison                                                                      \n",
            "Female Adult vs Female Young                1.122083                 0.134077   \n",
            "Female Adult vs Male Young                  1.098363                 0.117897   \n",
            "Male Adult vs Female Adult                  0.934428                -0.034501   \n",
            "Male Adult vs Female Young                  1.038361                 0.099576   \n",
            "Male Adult vs Male Young                    1.016848                 0.083396   \n",
            "Male Young vs Female Young                  1.039393                 0.016180   \n",
            "\n",
            "                              Equal Opportunity Difference  \\\n",
            "Comparison                                                   \n",
            "Female Adult vs Female Young                      0.086335   \n",
            "Female Adult vs Male Young                       -0.014855   \n",
            "Male Adult vs Female Adult                       -0.024638   \n",
            "Male Adult vs Female Young                        0.061698   \n",
            "Male Adult vs Male Young                         -0.039493   \n",
            "Male Young vs Female Young                        0.101190   \n",
            "\n",
            "                                       Consistency  \n",
            "Comparison                                          \n",
            "Female Adult vs Female Young  [0.8608666666666668]  \n",
            "Female Adult vs Male Young    [0.8608666666666668]  \n",
            "Male Adult vs Female Adult    [0.8608666666666668]  \n",
            "Male Adult vs Female Young    [0.8608666666666668]  \n",
            "Male Adult vs Male Young      [0.8608666666666668]  \n",
            "Male Young vs Female Young    [0.8608666666666668]  }\n",
            "\n",
            "----------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print all results in a formatted way\n",
        "for key, result in results.items():\n",
        "    print(f\"Results for {key}:\")\n",
        "    print(result)\n",
        "    print(\"\\n\" + \"-\"*40 + \"\\n\")  # Print a separator for better readability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPtmOCifA3C-",
        "outputId": "03b0a17d-2c8f-4c51-f260-b5434e4fe234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Classifier           Technique  DI Ratio  AEO Diff.  Equal Opportunity Difference              Consis.     Acc.  Bal. Acc.  F1 Score\n",
            "Logistic Regression                none  0.736460  -0.178010                     -0.087474 [0.8610666666666666] 0.762333   0.677222  0.839821\n",
            "Logistic Regression custom_smote_dbscan  1.035013   0.082384                      0.053313 [0.8836666666666668] 0.751000   0.640873  0.837452\n",
            "Logistic Regression          Fair-SMOTE  1.109462   0.148379                      0.062940 [0.8308666666666665] 0.716667   0.658254  0.798758\n",
            "Logistic Regression          Reweighing  0.946162   0.017471                      0.012215 [0.8644666666666667] 0.756000   0.672381  0.834933\n",
            "Logistic Regression              Remedy  1.038361   0.099576                      0.061698 [0.8608666666666668] 0.755333   0.673810  0.833951\n"
          ]
        }
      ],
      "source": [
        "\n",
        "comparison_key = 'Male Adult vs Female Young'\n",
        "#comparison_key = 'Caucasian Female vs Black Male'\n",
        "#comparison_key = 'White Male vs Black Female'\n",
        "\n",
        "# Create an empty list to store the extracted data\n",
        "data = []\n",
        "\n",
        "# Iterate over the results dictionary and extract the relevant data\n",
        "for method, result_dict in results['ModelEvaluator'].items():\n",
        "    if comparison_key in result_dict.index:\n",
        "        metrics = result_dict.loc[comparison_key]\n",
        "        row = {\n",
        "            'Classifier': model,\n",
        "            'Technique': method,\n",
        "            'DI Ratio': metrics['Disparate Impact Ratio'],\n",
        "            'AEO Diff.': metrics['Average Odds Difference'],\n",
        "            'Equal Opportunity Difference': metrics['Equal Opportunity Difference'],\n",
        "            'Consis.': metrics['Consistency'],\n",
        "            'Acc.': metrics['Accuracy'],\n",
        "            'Bal. Acc.': metrics['Balanced Accuracy'],\n",
        "            'F1 Score': metrics['F1 Score']\n",
        "        }\n",
        "        data.append(row)\n",
        "\n",
        "# Convert the extracted data into a DataFrame\n",
        "df_results = pd.DataFrame(data)\n",
        "\n",
        "# Print the DataFrame as a formatted table\n",
        "print(df_results.to_string(index=False))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOE4zjY+V5nlmGd4jnRU54e",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}