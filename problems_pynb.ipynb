{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcIOL6v/Fch3dH7kwu+shj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qahtanaa/OnSubGroupFairness/blob/main/problems_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJfnDNA7_SKT",
        "outputId": "caaa911a-5fd4-4812-b650-54d0ebe63299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aif360\n",
            "  Downloading aif360-0.5.0-py3-none-any.whl (214 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/214.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m204.8/214.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.1/214.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.11.4)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from aif360) (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360) (2023.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360) (3.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.24.0->aif360) (1.16.0)\n",
            "Installing collected packages: aif360\n",
            "Successfully installed aif360-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install aif360"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from aif360.metrics import utils\n",
        "from scipy.sparse import issparse\n",
        "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bdy2iJa_bs3",
        "outputId": "488b5071-ced1-4849-9102-6b50c353f41c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
            "pip install 'aif360[LawSchoolGPA]'\n",
            "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
            "pip install 'aif360[Reductions]'\n",
            "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
            "pip install 'aif360[Reductions]'\n",
            "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
            "pip install 'aif360[Reductions]'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataPreparation():\n",
        "  \"\"\"\n",
        "  ........\n",
        "  \"\"\"\n",
        "  def __init__(self, df, sensitive, label, priv, unpriv, fav, unfav, categorical):\n",
        "    \"\"\"\n",
        "    Construct all necessary attributes for the data preparation.\n",
        "\n",
        "    df : (pandas DataFrame) containing the data\n",
        "    sensitive : (list(str)) specifying the column names of all sensitive features\n",
        "    label : (str) specifying the label column\n",
        "    priv : (list(dicts)) representation of the privileged groups\n",
        "    unpriv : (list(dicts)) representation of the unprivileged groups\n",
        "    fav : (str/int/..) value representing the favorable label\n",
        "    unfav : (str/int/..) value representing the unfavorable label\n",
        "    categorical : (list(str)) (optional) specifying column names of categorical features\n",
        "    \"\"\"\n",
        "    self.df = df\n",
        "    self.sensitive = sensitive\n",
        "    self.label = label\n",
        "    self.priv = priv\n",
        "    self.unpriv = unpriv\n",
        "    self.fav = fav\n",
        "    self.unfav = unfav\n",
        "    self.categorical = categorical\n",
        "\n",
        "\n",
        "  def detect_missing_values(self):\n",
        "      \"\"\"\n",
        "      Detect rows with missing values and remove them from the DataFrame.\n",
        "      \"\"\"\n",
        "      initial_rows = len(self.df)\n",
        "      self.df = self.df.dropna()\n",
        "      removed_rows = initial_rows - len(self.df)\n",
        "\n",
        "      if removed_rows > 0:\n",
        "          print(f\"Detected {removed_rows} rows with missing values. Removed them.\")\n",
        "      else:\n",
        "          print(\"No missing values detected.\") #pass\n",
        "\n",
        "  def binary_label(self):\n",
        "    \"\"\"\n",
        "    Check that the decision label is made of two values, change it as a binary representation\n",
        "    where favorable label = 1, unfavorable label = 0.\n",
        "    \"\"\"\n",
        "    number_label_values = self.df[self.label].nunique()\n",
        "    if number_label_values == 2:\n",
        "      print(f\"The '{self.label}' column has only two unique values.\")\n",
        "      self.df[self.label].replace([self.unfav, self.fav], [0, 1], inplace=True)\n",
        "    else:\n",
        "      print(f\"The '{self.label}' column does not have exactly two unique values, as it should.\")\n",
        "\n",
        "  def find_categorical_attributes(self):\n",
        "    \"\"\"\n",
        "    find the categorical attributes\n",
        "    \"\"\"\n",
        "    attribute_types = {}\n",
        "\n",
        "    for column in self.df.columns:\n",
        "        # Skip the 'Group' column\n",
        "        if column == 'Group':\n",
        "            continue\n",
        "        # if the column has already been classified as categorical by the user, leave it cat\n",
        "        elif column in self.categorical:\n",
        "            attribute_types[column] = 'Categorical'\n",
        "            continue\n",
        "        # if the column has only two distinguished values, consider it categorical\n",
        "        elif self.df[column].nunique() == 2:\n",
        "          attribute_types[column] = 'Categorical'\n",
        "          continue\n",
        "        else: #if it's not the group column, or if it's not been classified as categorical by the user, check every value of the column\n",
        "          num_float = 0\n",
        "          num_text = 0\n",
        "          thresh = 0.99\n",
        "          num_att_in_column = len(self.df[column])\n",
        "\n",
        "          for value in self.df[column]:  # Accessing all values in the column\n",
        "            # Attempt to convert the value to a float\n",
        "            try:\n",
        "              float(value)\n",
        "              num_float += 1\n",
        "              continue  # Move to the next value\n",
        "            except ValueError:\n",
        "              pass  # If it's not a float, continue to the next check\n",
        "            # If it's not an integer or a float, consider it as text\n",
        "            num_text += 1\n",
        "\n",
        "          # now see if it's categorical or numerical\n",
        "          if num_float / num_att_in_column > thresh:\n",
        "            attribute_types[column] = 'Numerical'\n",
        "            continue\n",
        "          else:\n",
        "            attribute_types[column] = 'Categorical'\n",
        "    return attribute_types\n",
        "\n",
        "\n",
        "  def create_group_column(self):\n",
        "    \"\"\"\n",
        "    Create a 'Group' column in the DataFrame based on protected attributes, privileged/unprivileged conditions, and label. Then drop\n",
        "    the protected attributes and label columns because those informations are already present in the Group column\n",
        "    \"\"\"\n",
        "    group_combinations = pd.MultiIndex.from_product([self.df[sensitive].unique() for sensitive in self.sensitive] + [self.df[self.label].unique()], names=self.sensitive + [self.label])\n",
        "    #print(group_combinations)\n",
        "    print(list(enumerate(group_combinations)))\n",
        "    # Create a mapping between group combinations and their corresponding numbers\n",
        "    group_mapping = {group: idx for idx, group in enumerate(group_combinations)}\n",
        "    reverse_group_mapping = {idx: group for group, idx in group_mapping.items()}  # Create reverse mapping\n",
        "    # Apply the mapping to create a new column in the DataFrame\n",
        "    self.df['Group'] = pd.MultiIndex.from_frame(self.df[self.sensitive + [self.label]]).map(group_mapping)\n",
        "\n",
        "    return reverse_group_mapping #enumerate(group_combinations)\n",
        "\n",
        "  def prepare(self):\n",
        "    \"\"\"\n",
        "    Perform all preprocessing steps.\n",
        "    \"\"\"\n",
        "    self.detect_missing_values()\n",
        "    self.binary_label()\n",
        "    self.create_group_column()\n",
        "    self.find_categorical_attributes()\n",
        "    #self.normalization()\n",
        "    #self.make_numerical()\n",
        "    return self"
      ],
      "metadata": {
        "id": "0xxB461F_du3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########### CODE TO TRY DATAPREPARATION CLASS WITH A SMALL DATAFAME\n",
        "\n",
        "# Create a small DataFrame\n",
        "np.random.seed(42)\n",
        "n = 200\n",
        "data = {\n",
        "    'Gender': np.random.choice(['F', 'M'], size=n),\n",
        "    'Race': np.random.choice(['B', 'W'], size=n),\n",
        "    'NumKids': np.random.choice(range(5), size=n),\n",
        "    'Height': np.random.uniform(150, 190, size=n),\n",
        "    'ShirtColor': np.random.choice(['Red', 'Blue', 'Green'], size=n),\n",
        "    'Age': np.random.randint(18, 65, size=n),\n",
        "    'Accepted': np.random.choice([1, 2], size=n)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Introduce missing values randomly\n",
        "missing_fraction = 0.05  # Adjust this fraction based on the desired percentage of missing values\n",
        "\n",
        "# Randomly select cells and set their values to NaN\n",
        "mask = np.random.rand(*df.shape) < missing_fraction\n",
        "df[mask] = np.nan\n",
        "print(df)\n",
        "\n",
        "del mask\n",
        "del missing_fraction\n",
        "\n",
        "#count the number of columns in the dataframe\n",
        "num_of_columns = len(df.columns)\n",
        "print(\"Number of columns:\", num_of_columns)\n",
        "\n",
        "#use the DataPreparation class to preprocess the dataframe\n",
        "data_prep = DataPreparation(df, ['Gender','Race'], 'Accepted', ['M','W'], ['F', 'B'], 2, 1, ['NumKids'])\n",
        "data_prep.prepare()\n",
        "\n",
        "# use this reset index to have indices from 0 to len(df)\n",
        "data_prep.df = data_prep.df.reset_index(drop=True)\n",
        "print(data_prep.df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iDL8vh9_gUf",
        "outputId": "add0b035-8ffd-4bdd-ea34-122dbfedf893"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gender Race  NumKids      Height ShirtColor   Age  Accepted\n",
            "0        F    B      3.0  188.447623       Blue  43.0       2.0\n",
            "1        M    W      2.0         NaN      Green  31.0       1.0\n",
            "2        F    B      0.0  157.831645      Green   NaN       2.0\n",
            "3        F    B      3.0  152.774452      Green  54.0       1.0\n",
            "4        F    W      3.0         NaN      Green  28.0       2.0\n",
            "..     ...  ...      ...         ...        ...   ...       ...\n",
            "195      M    W      2.0         NaN        NaN  52.0       NaN\n",
            "196      M    W      4.0  155.454859        Red  42.0       1.0\n",
            "197      M    W      3.0  150.581787        Red  43.0       2.0\n",
            "198      F    W      2.0  164.023502      Green  28.0       1.0\n",
            "199      F    B      0.0  173.596707        Red  55.0       1.0\n",
            "\n",
            "[200 rows x 7 columns]\n",
            "Number of columns: 7\n",
            "Detected 60 rows with missing values. Removed them.\n",
            "The 'Accepted' column has only two unique values.\n",
            "[(0, ('F', 'B', 1.0)), (1, ('F', 'B', 0.0)), (2, ('F', 'W', 1.0)), (3, ('F', 'W', 0.0)), (4, ('M', 'B', 1.0)), (5, ('M', 'B', 0.0)), (6, ('M', 'W', 1.0)), (7, ('M', 'W', 0.0))]\n",
            "    Gender Race  NumKids      Height ShirtColor   Age  Accepted  Group\n",
            "0        F    B      3.0  188.447623       Blue  43.0       1.0      0\n",
            "1        F    B      3.0  152.774452      Green  54.0       0.0      1\n",
            "2        M    B      2.0  150.728873       Blue  53.0       0.0      5\n",
            "3        F    W      2.0  177.320271       Blue  60.0       1.0      2\n",
            "4        F    W      0.0  152.847546        Red  20.0       0.0      3\n",
            "..     ...  ...      ...         ...        ...   ...       ...    ...\n",
            "135      F    B      2.0  178.163191       Blue  58.0       1.0      0\n",
            "136      M    W      4.0  155.454859        Red  42.0       0.0      7\n",
            "137      M    W      3.0  150.581787        Red  43.0       1.0      6\n",
            "138      F    W      2.0  164.023502      Green  28.0       0.0      3\n",
            "139      F    B      0.0  173.596707        Red  55.0       0.0      1\n",
            "\n",
            "[140 rows x 8 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-adc97bf773ce>:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.df[self.label].replace([self.unfav, self.fav], [0, 1], inplace=True)\n",
            "<ipython-input-3-adc97bf773ce>:109: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.df['Group'] = pd.MultiIndex.from_frame(self.df[self.sensitive + [self.label]]).map(group_mapping)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the method to find categorical indices\n",
        "attribute_types = data_prep.find_categorical_attributes()\n",
        "\n",
        "# Print the result\n",
        "print(\"dictionary 'Attribute' : 'Numerical/Categorical' \\n \", attribute_types)\n",
        "\n",
        "# Initialize cat_features list\n",
        "cat_features = []\n",
        "\n",
        "# Iterate over attribute names and determine whether they are categorical or numerical\n",
        "for attr in attribute_types:\n",
        "    cat_features.append(attribute_types[attr] == 'Categorical')\n",
        "\n",
        "del attr\n",
        "\n",
        "print('boolean categorical features vector:\\n', cat_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6AfHiBS_mFJ",
        "outputId": "c0bf58a8-f009-4dee-fda4-554ac45c45d7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dictionary 'Attribute' : 'Numerical/Categorical' \n",
            "  {'Gender': 'Categorical', 'Race': 'Categorical', 'NumKids': 'Categorical', 'Height': 'Numerical', 'ShirtColor': 'Categorical', 'Age': 'Numerical', 'Accepted': 'Categorical'}\n",
            "boolean categorical features vector:\n",
            " [True, True, True, False, True, False, True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "heom di distyton, using Nearest Neighbors to find the kNN\n"
      ],
      "metadata": {
        "id": "ibjwhg8O_rVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install distython\n",
        "from distython import HEOM\n",
        "from distython import HVDM\n",
        "from sklearn.neighbors import NearestNeighbors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrQ_CJ-Y_rAp",
        "outputId": "a6710fd1-8f67-468c-c193-c0309465e4d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting distython\n",
            "  Downloading distython-0.0.3-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: distython\n",
            "Successfully installed distython-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def heom_distance1(ndary, cat_features_boolean, n=5):\n",
        "  \"\"\"\n",
        "  later\n",
        "  \"\"\"\n",
        "  X = ndary\n",
        "  n = n+1\n",
        "\n",
        "  # array of categorical indices\n",
        "  cat_attr_ix = [i for i, value in enumerate(cat_features_boolean) if value]\n",
        "\n",
        "  nan_eqv = 12345\n",
        "\n",
        "  #compute the matrix of the distances using HEOM\n",
        "  matrix_dist_HEOM = HEOM(X, cat_attr_ix, nan_equivalents = [nan_eqv])\n",
        "\n",
        "  # Declare NearestNeighbor and link the metric\n",
        "  neighbor = NearestNeighbors(metric = matrix_dist_HEOM.heom)\n",
        "\n",
        "  # Fit the model which uses the custom distance metric\n",
        "  neighbor.fit(X)\n",
        "\n",
        "  # Initialize empty matrices to store indices and distances\n",
        "  nearest_indices_heom = np.zeros((len(X), 6), dtype=int)\n",
        "  nearest_distances_heom = np.zeros((len(X), 6))\n",
        "\n",
        "  # Loop through each instance in the data\n",
        "  for i in range(len(X)):\n",
        "      # Find the 5 nearest neighbors to the current instance\n",
        "      result = neighbor.kneighbors(X[i].reshape(1, -1), n_neighbors=6)\n",
        "\n",
        "      # Store the indices and distances of the nearest neighbors in the matrices\n",
        "      nearest_indices_heom[i] = result[1][0]\n",
        "      nearest_distances_heom[i] = result[0][0]\n",
        "\n",
        "  return nearest_indices_heom, nearest_distances_heom"
      ],
      "metadata": {
        "id": "O_wjFFr8_1ET"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FIRST OF ALL, Encode the dataframe so that the categorical attributes are converted to numbers, but still treated like categorical.\n",
        "X = data_prep.df.drop(columns=['Group'], axis=1).copy()\n",
        "#print(X)\n",
        "encoder_dict = dict()\n",
        "columns_categorical = X.columns[cat_features]\n",
        "\n",
        "# for each categorical column, encode it\n",
        "for column in columns_categorical:\n",
        "  le = LabelEncoder()\n",
        "  X[column] = le.fit_transform(X[column].values)\n",
        "  mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
        "  encoder_dict[column] = mapping\n",
        "#print(X)\n",
        "\n",
        "# convert it to numpy so that distython doesn't cry\n",
        "X = X.to_numpy()\n",
        "#print(X)\n",
        "\n",
        "#call the method defined above\n",
        "closest_index_heom1, closest_values_heom1 = heom_distance1(X, cat_features,5)"
      ],
      "metadata": {
        "id": "tzA55_BAjdtI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(closest_index_heom1[0:15,:])\n",
        "print('...')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PwFwZcqkGB6",
        "outputId": "444534c6-6cb3-4bbb-9acc-193e956f2c37"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0  83 130  78 135  91]\n",
            " [  1  27 111  75 114  78]\n",
            " [  2  36  29  97 109  12]\n",
            " [  3 135 126  26  83  91]\n",
            " [  4  38 133  32 105 102]\n",
            " [  5  67 106  68  18  75]\n",
            " [  6 130  42 103 125 122]\n",
            " [  7 117  55  48  27  53]\n",
            " [  8 139  34 133 104  38]\n",
            " [  9  84  15  32  14 102]\n",
            " [ 10 137 115  52  37  77]\n",
            " [ 11  34 125  92  29 133]\n",
            " [ 12  72  62  43  61  17]\n",
            " [ 13  43 113  72  14  24]\n",
            " [ 14  13  84   9  24 115]]\n",
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def heom_distance2(ndary, cat_features_boolean, n=5):\n",
        "  \"\"\"\n",
        "  later\n",
        "  \"\"\"\n",
        "  X = ndary\n",
        "  n = n+1\n",
        "\n",
        "  cat_attr_ix = [i for i, value in enumerate(cat_features_boolean) if value]\n",
        "\n",
        "  nan_eqv = 12345\n",
        "\n",
        "  #compute the matrix of the distances using HEOM\n",
        "  matrix_dist_HEOM = HEOM(X, cat_attr_ix, nan_equivalents = [nan_eqv])\n",
        "\n",
        "  matrix_distances = np.zeros((len(X), len(X)))\n",
        "  distances = []\n",
        "  k = 0\n",
        "\n",
        "  #compute the distances using HEOM metric\n",
        "  for i in X:\n",
        "      for j in X:\n",
        "          i = np.asarray(i)\n",
        "          i = i.astype(np.float64)\n",
        "          j = np.asarray(j)\n",
        "          j = j.astype(np.float64)\n",
        "          dist = matrix_dist_HEOM.heom(i, j)\n",
        "          distances.append(dist)\n",
        "\n",
        "      matrix_distances[k, :] = distances\n",
        "      k += 1\n",
        "      distances = []\n",
        "\n",
        "  #compute the matrices with n-NN indices and values\n",
        "  matrix_ind_val = []\n",
        "  for i in range(len(X)):\n",
        "    dm = matrix_distances[i,:]\n",
        "    top_n = smallest_indices(np.nan_to_num(dm, nan=1),6)\n",
        "    matrix_ind_val.append(top_n)\n",
        "\n",
        "  matrix_neighbors_heom_index = np.array([item['index'] for item in matrix_ind_val])\n",
        "  matrix_neighbors_heom_values = np.array([item['values'] for item in matrix_ind_val])\n",
        "\n",
        "  return matrix_neighbors_heom_index, matrix_neighbors_heom_values\n",
        "\n",
        "def smallest_indices(ary, n):\n",
        "    \"\"\"Returns the n largest indices from a numpy array.\"\"\"\n",
        "    #n += 1\n",
        "    flat = np.nan_to_num(ary.flatten(), nan=999)\n",
        "    indices = np.argpartition(-flat, -n)[-n:]\n",
        "    indices = indices[np.argsort(flat[indices])]\n",
        "    #indices = np.delete(indices,0,0)\n",
        "    values = flat[indices]\n",
        "    return {'index': indices, 'values': values}"
      ],
      "metadata": {
        "id": "yR78kOIZkrMy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "closest_index_heom2, closest_values_heom2 = heom_distance2(X, cat_features,5)"
      ],
      "metadata": {
        "id": "sgGwGi__lm3F"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(closest_index_heom2[0:15,:])\n",
        "print('...')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg97wp-Ulzuh",
        "outputId": "a14a26ee-48f8-4f51-96ac-15f30cbb5bc6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0  83 130  78 135  91]\n",
            " [  1  27 111  75 114  78]\n",
            " [  2  36  29  97 109  12]\n",
            " [  3 135 126  26  83  91]\n",
            " [  4  38 133  32 105 102]\n",
            " [  5  67 106  68  18  75]\n",
            " [  6 130  42 103 125 122]\n",
            " [  7 117  55  48  27  53]\n",
            " [  8 139  34 133 104  38]\n",
            " [  9  84  15  32  14 102]\n",
            " [ 10 137 115  52  37  77]\n",
            " [ 11  34 125  92  29 133]\n",
            " [ 12  72  62  43  61  17]\n",
            " [ 13  43 113  72  14  24]\n",
            " [ 14  13  84   9  24 115]]\n",
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "hvdm di distyton, using Nearest Neighbors to find the kNN\n"
      ],
      "metadata": {
        "id": "N4JwVycckd8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hvdm_distance1(ndary, y_ix, cat_features_boolean, n=5):\n",
        "  \"\"\"\n",
        "  y_ix = [n] is a 1-element array what represent the index of the target variable/laber\n",
        "  \"\"\"\n",
        "  X = ndary\n",
        "  n = n+1\n",
        "\n",
        "  # convert the values of the cat_features from boolean to binary: 1 if categorical, 0 if numerical\n",
        "  cat_attr_ix = [i for i, value in enumerate(cat_features_boolean) if value]\n",
        "  nan_eqv = 12345\n",
        "\n",
        "  #compute the matrix of the distances using HEOM\n",
        "  matrix_dist_HVDM = HVDM(X,y_ix, cat_attr_ix, nan_equivalents = [nan_eqv], normalised=\"std\")\n",
        "\n",
        "  # Declare NearestNeighbor and link the metric\n",
        "  neighbor = NearestNeighbors(metric = matrix_dist_HVDM.hvdm)\n",
        "\n",
        "  # Fit the model which uses the custom distance metric\n",
        "  neighbor.fit(X)\n",
        "\n",
        "  # Initialize empty matrices to store indices and distances\n",
        "  nearest_indices_hvdm = np.zeros((len(X), 6), dtype=int)\n",
        "  nearest_distances_hvdm = np.zeros((len(X), 6))\n",
        "\n",
        "  # Loop through each instance in the data\n",
        "  for i in range(len(X)):\n",
        "      # Find the 5 nearest neighbors to the current instance\n",
        "      result = neighbor.kneighbors(X[i].reshape(1, -1), n_neighbors=6)\n",
        "\n",
        "      # Store the indices and distances of the nearest neighbors in the matrices\n",
        "      nearest_indices_hvdm[i] = result[1][0]\n",
        "      nearest_distances_hvdm[i] = result[0][0]\n",
        "\n",
        "  return nearest_indices_hvdm, nearest_distances_hvdm"
      ],
      "metadata": {
        "id": "GWZVWJSZkbrO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_ix = [6]\n",
        "closest_index_hvdm1, closest_values_hvdm1 = hvdm_distance1(X, y_ix, cat_features,5, )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mhz3L96NmRTe",
        "outputId": "c11097ab-d154-488c-a962-b818ad3e67a6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Division by zero is not allowed!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "local variable 'temp_result' referenced before assignment",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-48911979d1ad>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclosest_index_hvdm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosest_values_hvdm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhvdm_distance1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-737a3f43cba6>\u001b[0m in \u001b[0;36mhvdm_distance1\u001b[0;34m(ndary, y_ix, cat_features_boolean, n)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;31m# Fit the model which uses the custom distance metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mneighbor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;31m# Initialize empty matrices to store indices and distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_unsupervised.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \"\"\"\n\u001b[1;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ball_tree\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m             self._tree = BallTree(\n\u001b[0m\u001b[1;32m    647\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaf_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msklearn/neighbors/_binary_tree.pxi\u001b[0m in \u001b[0;36msklearn.neighbors._ball_tree.BinaryTree.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msklearn/neighbors/_binary_tree.pxi\u001b[0m in \u001b[0;36msklearn.neighbors._ball_tree.BinaryTree._recursive_build\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msklearn/neighbors/_ball_tree.pyx\u001b[0m in \u001b[0;36msklearn.neighbors._ball_tree.init_node\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msklearn/neighbors/_binary_tree.pxi\u001b[0m in \u001b[0;36msklearn.neighbors._ball_tree.BinaryTree.rdist\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msklearn/metrics/_dist_metrics.pyx\u001b[0m in \u001b[0;36msklearn.metrics._dist_metrics.DistanceMetric.rdist\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msklearn/metrics/_dist_metrics.pyx\u001b[0m in \u001b[0;36msklearn.metrics._dist_metrics.PyFuncDistance.dist\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msklearn/metrics/_dist_metrics.pyx\u001b[0m in \u001b[0;36msklearn.metrics._dist_metrics.PyFuncDistance._dist\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distython/HVDM.py\u001b[0m in \u001b[0;36mhvdm\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mcat_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# Calculate the distance for categorical elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mresults_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat_ix\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat_ix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;31m# Get numerical indices without missing values elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mnum_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distython/VDM.py\u001b[0m in \u001b[0;36mvdm\u001b[0;34m(self, x, y, nan_ix)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Division by zero is not allowed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'temp_result' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/usr/local/lib/python3.10/dist-packages/distython/VDM.py let's see this error, it doesn't enter in the if in line 96, as if N_ax or N_ay are equal zero, but they're not!\n",
        "\n",
        "The problem is in the fit() method of Nearest Neighbors, I don't know why. The code is essentially the same as the one for HEOM distance."
      ],
      "metadata": {
        "id": "zAQt-K_Qm0Bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hvdm_distance2(ndary, y_ix, cat_features_boolean, n=5):\n",
        "  \"\"\"\n",
        "  y_ix = [n] is a 1-element array what represent the index of the target variable/laber\n",
        "  \"\"\"\n",
        "  X = ndary\n",
        "  n = n+1\n",
        "\n",
        "  # convert the values of the cat_features from boolean to binary: 1 if categorical, 0 if numerical\n",
        "  cat_attr_ix = [i for i, value in enumerate(cat_features_boolean) if value]\n",
        "  nan_eqv = 12345\n",
        "\n",
        "  #compute the matrix of the distances using HEOM\n",
        "  matrix_dist_HVDM = HVDM(X,y_ix, cat_attr_ix, nan_equivalents = [nan_eqv], normalised=\"std\")\n",
        "\n",
        "  matrix_distances = np.zeros((len(X), len(X)))\n",
        "  distances = []\n",
        "  k = 0\n",
        "\n",
        "  #compute the distances using HVDM metric\n",
        "  for i in X:\n",
        "      for j in X:\n",
        "          i = np.asarray(i)\n",
        "          i = i.astype(np.float64)\n",
        "          j = np.asarray(j)\n",
        "          j = j.astype(np.float64)\n",
        "          dist = matrix_dist_HVDM.hvdm(i, j)\n",
        "          distances.append(dist)\n",
        "\n",
        "      matrix_distances[k, :] = distances\n",
        "      k += 1\n",
        "      distances = []\n",
        "\n",
        "  #compute the matrices with n-NN indices and values\n",
        "  matrix_ind_val = []\n",
        "  for i in range(len(X)):\n",
        "    dm = matrix_distances[i,:]\n",
        "    top_n = smallest_indices(np.nan_to_num(dm, nan=1),6)\n",
        "    matrix_ind_val.append(top_n)\n",
        "\n",
        "  matrix_neighbors_hvdm_index = np.array([item['index'] for item in matrix_ind_val])\n",
        "  matrix_neighbors_hvdm_values = np.array([item['values'] for item in matrix_ind_val])\n",
        "\n",
        "  return matrix_neighbors_hvdm_index, matrix_neighbors_hvdm_values\n"
      ],
      "metadata": {
        "id": "wehy0-jdngV_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_ix = [6]\n",
        "closest_index_hvdm2, closest_values_hvdm2 = hvdm_distance2(X, y_ix, cat_features,5, )"
      ],
      "metadata": {
        "id": "Rrbd_upQoEo1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(closest_index_hvdm2[0:15,:])\n",
        "print('...')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDByea8koNrX",
        "outputId": "0e0627b1-1ef8-4f06-d1fe-2a83771fb2f0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0 122 130  90  83 103]\n",
            " [  1  27  68  45   5  69]\n",
            " [  2  27   1  68 111 121]\n",
            " [  3 135  10  50 107  26]\n",
            " [  4 133  92 105  32  15]\n",
            " [  5  68  75 111 106   1]\n",
            " [  6  35 103  96  52 134]\n",
            " [  7 133  92   4 105  54]\n",
            " [  8 139  34  94  79  43]\n",
            " [  9  93 125 113  13  15]\n",
            " [ 10 107 126  83 115   3]\n",
            " [ 11 125  30  13 113  55]\n",
            " [ 12  20  62  95 104  89]\n",
            " [ 13 113  93  74  14   9]\n",
            " [ 14  13  74  23  30 113]]\n",
            "...\n"
          ]
        }
      ]
    }
  ]
}